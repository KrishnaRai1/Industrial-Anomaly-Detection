{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiQbLiJI7q7Y"
      },
      "source": [
        "# DRAEM:\n",
        "## A Discriminatively Trained Reconstruction Embedding for Surface Anomaly Detection\n",
        "### Authors: Vitjan Zavrtanik, Matej Kristan, Danijel Skocaj\n",
        "\n",
        "### Conference: ICCV 2021 (International Conference on Computer Vision)\n",
        "\n",
        "### Publication Date: October 2021\n",
        "\n",
        "### Research Paper Link: https://openaccess.thecvf.com/content/ICCV2021/papers/Zavrtanik_DRAEM_-_A_Discriminatively_Trained_Reconstruction_Embedding_for_Surface_Anomaly_ICCV_2021_paper.pdf\n",
        "\n",
        "### GitHub Repository: https://github.com/VitjanZ/DRAEM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LYJodilv3D7",
        "outputId": "e3df0774-6fe4-4200-8a57-4ffbe757d7d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting kornia\n",
            "  Downloading kornia-0.8.0-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.14.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.2.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Collecting kornia_rs>=0.1.0 (from kornia)\n",
            "  Downloading kornia_rs-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.8.0-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, kornia_rs, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, kornia\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed kornia-0.8.0 kornia_rs-0.1.8 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "/content/DRAEM_implementation\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required packages\n",
        "!pip install torch torchvision scikit-image scikit-learn matplotlib opencv-python kornia tqdm\n",
        "\n",
        "# Create project directory\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Set up project directory - modify this path to match your Drive structure\n",
        "PROJECT_DIR = '/content/DRAEM_implementation'\n",
        "!mkdir -p {PROJECT_DIR}\n",
        "%cd {PROJECT_DIR}\n",
        "\n",
        "# Create directory structure\n",
        "!mkdir -p checkpoints/bottle\n",
        "!mkdir -p visualizations/bottle\n",
        "\n",
        "# Add current directory to path\n",
        "sys.path.append(PROJECT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Architecture"
      ],
      "metadata": {
        "id": "0tjOFsHaie5P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUHowpmwvhMh",
        "outputId": "f3dfc444-ecda-4459-aafc-f83713f61cd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DiscriminativeSubNetwork(nn.Module):\n",
        "    def __init__(self, in_channels=6, out_channels=1):\n",
        "        super(DiscriminativeSubNetwork, self).__init__()\n",
        "        # Encoder (downsampling)\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, 4, stride=2, padding=1, bias=False)  # 128x128\n",
        "        self.conv2 = nn.Conv2d(64, 128, 4, stride=2, padding=1, bias=False)         # 64x64\n",
        "        self.conv3 = nn.Conv2d(128, 256, 4, stride=2, padding=1, bias=False)        # 32x32\n",
        "        self.conv4 = nn.Conv2d(256, 512, 4, stride=2, padding=1, bias=False)        # 16x16\n",
        "\n",
        "        # Decoder (upsampling)\n",
        "        self.upconv1 = nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1, bias=False)  # 32x32\n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1, bias=False)  # 64x64\n",
        "        self.upconv3 = nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1, bias=False)   # 128x128\n",
        "        self.upconv4 = nn.ConvTranspose2d(64, out_channels, 4, stride=2, padding=1, bias=False)  # 256x256\n",
        "\n",
        "        # Batch normalization\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(256)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(256)\n",
        "        self.batchnorm6 = nn.BatchNorm2d(128)\n",
        "        self.batchnorm7 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.ReLU = nn.ReLU(True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder path\n",
        "        x1 = self.ReLU(self.batchnorm1(self.conv1(x)))    # 128x128\n",
        "        x2 = self.ReLU(self.batchnorm2(self.conv2(x1)))   # 64x64\n",
        "        x3 = self.ReLU(self.batchnorm3(self.conv3(x2)))   # 32x32\n",
        "        x4 = self.ReLU(self.batchnorm4(self.conv4(x3)))   # 16x16\n",
        "\n",
        "        # Decoder path with skip connections\n",
        "        x = self.ReLU(self.batchnorm5(self.upconv1(x4)))  # 32x32\n",
        "        x = self.ReLU(self.batchnorm6(self.upconv2(x)))   # 64x64\n",
        "        x = self.ReLU(self.batchnorm7(self.upconv3(x)))   # 128x128\n",
        "        x = self.upconv4(x)                               # 256x256\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class ReconstructiveSubNetwork(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, base_width=128):\n",
        "        super(ReconstructiveSubNetwork, self).__init__()\n",
        "        self.encoder = EncoderBlock(in_channels, base_width)\n",
        "        self.decoder = DecoderBlock(base_width, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b5 = self.encoder(x)\n",
        "        output = self.decoder(b5)\n",
        "\n",
        "        return output\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.deconv1 = nn.ConvTranspose2d(in_channels, in_channels//2, 4, stride=2, padding=1, bias=False)\n",
        "        self.deconv2 = nn.ConvTranspose2d(in_channels//2, in_channels//4, 4, stride=2, padding=1, bias=False)\n",
        "        self.deconv3 = nn.ConvTranspose2d(in_channels//4, in_channels//8, 4, stride=2, padding=1, bias=False)\n",
        "        self.deconv4 = nn.ConvTranspose2d(in_channels//8, in_channels//16, 4, stride=2, padding=1, bias=False)\n",
        "        self.deconv5 = nn.ConvTranspose2d(in_channels//16, out_channels, 4, stride=2, padding=1, bias=False)\n",
        "\n",
        "        self.batchnorm1 = nn.BatchNorm2d(in_channels//2)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(in_channels//4)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(in_channels//8)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(in_channels//16)\n",
        "\n",
        "        self.ReLU = nn.ReLU(True)\n",
        "        self.Sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ReLU(self.batchnorm1(self.deconv1(x)))\n",
        "        x = self.ReLU(self.batchnorm2(self.deconv2(x)))\n",
        "        x = self.ReLU(self.batchnorm3(self.deconv3(x)))\n",
        "        x = self.ReLU(self.batchnorm4(self.deconv4(x)))\n",
        "\n",
        "        x = self.Sigmoid(self.deconv5(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels//16, 4, stride=2, padding=1, bias=False)\n",
        "        self.conv2 = nn.Conv2d(out_channels//16, out_channels//8, 4, stride=2, padding=1, bias=False)\n",
        "        self.conv3 = nn.Conv2d(out_channels//8, out_channels//4, 4, stride=2, padding=1, bias=False)\n",
        "        self.conv4 = nn.Conv2d(out_channels//4, out_channels//2, 4, stride=2, padding=1, bias=False)\n",
        "        self.conv5 = nn.Conv2d(out_channels//2, out_channels, 4, stride=2, padding=1, bias=False)\n",
        "\n",
        "        self.batchnorm1 = nn.BatchNorm2d(out_channels//16)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(out_channels//8)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(out_channels//4)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(out_channels//2)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.ReLU = nn.ReLU(True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ReLU(self.batchnorm1(self.conv1(x)))\n",
        "        x = self.ReLU(self.batchnorm2(self.conv2(x)))\n",
        "        x = self.ReLU(self.batchnorm3(self.conv3(x)))\n",
        "        x = self.ReLU(self.batchnorm4(self.conv4(x)))\n",
        "        x = self.ReLU(self.batchnorm5(self.conv5(x)))\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsibzDgbv7QZ",
        "outputId": "9bd4064e-755d-4923-e97a-376806af964c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing draem_model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile draem_model.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from model import ReconstructiveSubNetwork, DiscriminativeSubNetwork\n",
        "\n",
        "class DRAEM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DRAEM, self).__init__()\n",
        "        self.reconstructive_subnetwork = ReconstructiveSubNetwork()\n",
        "        self.discriminative_subnetwork = DiscriminativeSubNetwork(in_channels=6)\n",
        "\n",
        "    def forward(self, x, gt=None, mask=None, mode=\"train\"):\n",
        "        reconstructed_x = self.reconstructive_subnetwork(x)\n",
        "\n",
        "        if mode == \"train\":\n",
        "            output = self.discriminative_subnetwork(torch.cat((reconstructed_x, gt), dim=1))\n",
        "            return reconstructed_x, output\n",
        "\n",
        "        if mode == \"test\":\n",
        "            output = self.discriminative_subnetwork(torch.cat((reconstructed_x, x), dim=1))\n",
        "            return reconstructed_x, output\n",
        "\n",
        "        raise ValueError(f\"Invalid mode {mode}. Must be 'train' or 'test'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Modification"
      ],
      "metadata": {
        "id": "EKZJBR8riydj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piBLF-xav9Q7",
        "outputId": "8b144d7b-0860-4b00-dd5d-d3d3aff6a8dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing dataset.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile dataset.py\n",
        "import random\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "def get_data_transforms(size, isize):\n",
        "    data_transforms = transforms.Compose([\n",
        "        transforms.Resize((size, size)),\n",
        "        transforms.ToTensor(),\n",
        "        ])\n",
        "    gt_transforms = transforms.Compose([\n",
        "        transforms.Resize((size, size)),\n",
        "        transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "    return data_transforms, gt_transforms\n",
        "\n",
        "def add_gaussian_noise(image, mean=0, std=1):\n",
        "    noise = torch.randn(image.size()) * std + mean\n",
        "    noisy_image = image + noise\n",
        "    return torch.clamp(noisy_image, 0., 1.)\n",
        "\n",
        "class MVTecDataset(Dataset):\n",
        "    def __init__(self, root, transform, gt_transform, phase, args):\n",
        "        if phase=='train':\n",
        "            self.img_path = os.path.join(root, args.obj_name, 'train', 'good')\n",
        "        else:\n",
        "            self.img_path = os.path.join(root, args.obj_name, 'test')\n",
        "            self.gt_path = os.path.join(root, args.obj_name, 'ground_truth')\n",
        "\n",
        "        self.transform = transform\n",
        "        self.gt_transform = gt_transform\n",
        "        self.img_paths, self.gt_paths, self.labels, self.types = self.load_dataset() # self.labels => good : 0, anomaly : 1\n",
        "        self.args = args\n",
        "\n",
        "    def load_dataset(self):\n",
        "        img_tot_paths = []\n",
        "        gt_tot_paths = []\n",
        "        tot_labels = []\n",
        "        tot_types = []\n",
        "\n",
        "        defect_types = os.listdir(self.img_path)\n",
        "\n",
        "        for defect_type in defect_types:\n",
        "            if defect_type == 'good':\n",
        "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*.png\")\n",
        "                img_paths.extend(glob.glob(os.path.join(self.img_path, defect_type) + \"/*.jpg\"))\n",
        "                img_tot_paths.extend(img_paths)\n",
        "                gt_tot_paths.extend([0]*len(img_paths))\n",
        "                tot_labels.extend([0]*len(img_paths))\n",
        "                tot_types.extend(['good']*len(img_paths))\n",
        "            else:\n",
        "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*.png\")\n",
        "                img_paths.extend(glob.glob(os.path.join(self.img_path, defect_type) + \"/*.jpg\"))\n",
        "                gt_paths = []\n",
        "                for img_path in img_paths:\n",
        "                    gt_path = os.path.join(self.gt_path, defect_type, os.path.splitext(os.path.basename(img_path))[0] + '_mask.png')\n",
        "                    gt_paths.append(gt_path)\n",
        "                img_tot_paths.extend(img_paths)\n",
        "                gt_tot_paths.extend(gt_paths)\n",
        "                tot_labels.extend([1]*len(img_paths))\n",
        "                tot_types.extend([defect_type]*len(img_paths))\n",
        "\n",
        "        return img_tot_paths, gt_tot_paths, tot_labels, tot_types\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, gt, label, img_type = self.img_paths[idx], self.gt_paths[idx], self.labels[idx], self.types[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "\n",
        "        if gt == 0:\n",
        "            gt = torch.zeros([1, img.size()[-2], img.size()[-1]])\n",
        "        else:\n",
        "            gt = Image.open(gt)\n",
        "            gt = self.gt_transform(gt)\n",
        "\n",
        "        return img, gt, label, os.path.basename(img_path[:-4]), img_type\n",
        "\n",
        "class CutPasteDataset(Dataset):\n",
        "    def __init__(self, root, transform, perturbed_transform, phase, args):\n",
        "        self.img_path = os.path.join(root, args.obj_name, 'train', 'good')\n",
        "        self.transform = transform\n",
        "        self.perturbed_transform = perturbed_transform\n",
        "        self.img_paths = sorted(glob.glob(self.img_path + \"/*.png\"))\n",
        "        self.img_paths.extend(sorted(glob.glob(self.img_path + \"/*.jpg\")))\n",
        "\n",
        "        # Check if anomaly source path exists and contains files\n",
        "        if os.path.exists(args.anomaly_source_path):\n",
        "            categories = [f for f in os.listdir(args.anomaly_source_path)\n",
        "                         if os.path.isdir(os.path.join(args.anomaly_source_path, f))]\n",
        "            self.anomaly_source_paths = []\n",
        "            for category in categories:\n",
        "                category_path = os.path.join(args.anomaly_source_path, category)\n",
        "                self.anomaly_source_paths.extend(\n",
        "                    [os.path.join(category_path, f) for f in os.listdir(category_path)\n",
        "                     if f.endswith(('.jpg', '.png'))]\n",
        "                )\n",
        "        else:\n",
        "            print(f\"Warning: Anomaly source path {args.anomaly_source_path} not found!\")\n",
        "            self.anomaly_source_paths = []\n",
        "\n",
        "        if len(self.anomaly_source_paths) == 0:\n",
        "            print(\"No anomaly source images found! Creating synthetic textures...\")\n",
        "            self.create_synthetic_textures(args.anomaly_source_path)\n",
        "\n",
        "            # Reload anomaly source paths\n",
        "            categories = [f for f in os.listdir(args.anomaly_source_path)\n",
        "                         if os.path.isdir(os.path.join(args.anomaly_source_path, f))]\n",
        "            self.anomaly_source_paths = []\n",
        "            for category in categories:\n",
        "                category_path = os.path.join(args.anomaly_source_path, category)\n",
        "                self.anomaly_source_paths.extend(\n",
        "                    [os.path.join(category_path, f) for f in os.listdir(category_path)\n",
        "                     if f.endswith(('.jpg', '.png'))]\n",
        "                )\n",
        "\n",
        "        print(f\"Found {len(self.img_paths)} training images and {len(self.anomaly_source_paths)} anomaly source images\")\n",
        "        self.resize_transform = transforms.Resize((args.img_size, args.img_size))\n",
        "\n",
        "    def create_synthetic_textures(self, output_path):\n",
        "        \"\"\"Create synthetic texture images for anomaly generation\"\"\"\n",
        "        from PIL import Image\n",
        "        import numpy as np\n",
        "\n",
        "        print(\"Creating synthetic texture images...\")\n",
        "        os.makedirs(os.path.join(output_path, 'grid'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(output_path, 'dots'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(output_path, 'lines'), exist_ok=True)\n",
        "\n",
        "        # Create 10 random textures of each type\n",
        "        for i in range(10):\n",
        "            # Grid texture\n",
        "            grid = np.zeros((256, 256, 3), dtype=np.uint8)\n",
        "            for x in range(0, 256, 16):\n",
        "                for y in range(0, 256, 16):\n",
        "                    grid[x:x+14, y:y+14] = np.random.randint(100, 256, size=3)\n",
        "            Image.fromarray(grid).save(os.path.join(output_path, 'grid', f'{i:02d}.jpg'))\n",
        "\n",
        "            # Dots texture\n",
        "            dots = np.zeros((256, 256, 3), dtype=np.uint8)\n",
        "            for _ in range(100):\n",
        "                x, y = np.random.randint(0, 256, 2)\n",
        "                r = np.random.randint(5, 15)\n",
        "                color = np.random.randint(100, 256, size=3)\n",
        "                for dx in range(-r, r+1):\n",
        "                    for dy in range(-r, r+1):\n",
        "                        if dx*dx + dy*dy <= r*r:\n",
        "                            nx, ny = x+dx, y+dy\n",
        "                            if 0 <= nx < 256 and 0 <= ny < 256:\n",
        "                                dots[nx, ny] = color\n",
        "            Image.fromarray(dots).save(os.path.join(output_path, 'dots', f'{i:02d}.jpg'))\n",
        "\n",
        "            # Lines texture\n",
        "            lines = np.zeros((256, 256, 3), dtype=np.uint8)\n",
        "            for _ in range(20):\n",
        "                x1, y1 = np.random.randint(0, 256, 2)\n",
        "                x2, y2 = np.random.randint(0, 256, 2)\n",
        "                thickness = np.random.randint(1, 8)\n",
        "                color = np.random.randint(100, 256, size=3)\n",
        "\n",
        "                # Draw line\n",
        "                points = np.linspace(0, 1, 100)\n",
        "                for t in points:\n",
        "                    x = int(x1 + t * (x2 - x1))\n",
        "                    y = int(y1 + t * (y2 - y1))\n",
        "                    if 0 <= x < 256 and 0 <= y < 256:\n",
        "                        for dx in range(-thickness//2, thickness//2+1):\n",
        "                            for dy in range(-thickness//2, thickness//2+1):\n",
        "                                if dx*dx + dy*dy <= thickness*thickness//4:\n",
        "                                    nx, ny = x+dx, y+dy\n",
        "                                    if 0 <= nx < 256 and 0 <= ny < 256:\n",
        "                                        lines[nx, ny] = color\n",
        "\n",
        "            Image.fromarray(lines).save(os.path.join(output_path, 'lines', f'{i:02d}.jpg'))\n",
        "\n",
        "        print(\"Created synthetic textures successfully\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        idx = idx % len(self.img_paths)\n",
        "        img_path = self.img_paths[idx]\n",
        "\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "\n",
        "        if len(self.anomaly_source_paths) > 0:\n",
        "            anomaly_source_idx = random.randint(0, len(self.anomaly_source_paths) - 1)\n",
        "            anomaly_source_path = self.anomaly_source_paths[anomaly_source_idx]\n",
        "\n",
        "            try:\n",
        "                anomaly_source_img = Image.open(anomaly_source_path).convert('RGB')\n",
        "                anomaly_source_img = self.perturbed_transform(anomaly_source_img)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading anomaly source image {anomaly_source_path}: {e}\")\n",
        "                # Create random noise as fallback\n",
        "                anomaly_source_img = torch.rand(3, self.args.img_size, self.args.img_size)\n",
        "        else:\n",
        "            # No anomaly sources available - create random noise\n",
        "            anomaly_source_img = torch.rand(3, self.args.img_size, self.args.img_size)\n",
        "\n",
        "        anomaly_img = img.clone()\n",
        "\n",
        "        beta = torch.distributions.beta.Beta(2, 2).sample((1,)).item()\n",
        "\n",
        "        anomaly_source_img = self.resize_transform(anomaly_source_img)\n",
        "\n",
        "        anomaly_source_img = torch.rot90(anomaly_source_img, random.randint(0,3), [1, 2])\n",
        "\n",
        "        if random.random() > 0.5:\n",
        "            anomaly_source_img = torch.flip(anomaly_source_img, dims=[random.randint(1,2)])\n",
        "\n",
        "        anomaly_img_h, anomaly_img_w = anomaly_img.size(1), anomaly_img.size(2)\n",
        "        mask_size_h = random.randint(int(anomaly_img_h * 0.05), int(anomaly_img_h * 0.2))\n",
        "        mask_size_w = random.randint(int(anomaly_img_w * 0.05), int(anomaly_img_w * 0.2))\n",
        "\n",
        "        mask_location_h = random.randint(1, anomaly_img_h - mask_size_h - 1)\n",
        "        mask_location_w = random.randint(1, anomaly_img_w - mask_size_w - 1)\n",
        "\n",
        "        anomaly_img[:, mask_location_h:mask_location_h + mask_size_h, mask_location_w:mask_location_w + mask_size_w] = anomaly_source_img[:, mask_location_h:mask_location_h + mask_size_h, mask_location_w:mask_location_w + mask_size_w]\n",
        "\n",
        "        # for Discriminator\n",
        "        mask = torch.zeros((1, anomaly_img.size(1), anomaly_img.size(2)))\n",
        "        mask[:, mask_location_h:mask_location_h + mask_size_h, mask_location_w:mask_location_w + mask_size_w] = 1\n",
        "\n",
        "        return img, anomaly_img, mask, img_path\n",
        "\n",
        "def show_cam_on_image(img, anomaly_map):\n",
        "    heatmap = cv2.applyColorMap(np.uint8(anomaly_map), cv2.COLORMAP_JET)\n",
        "    cam = np.float32(heatmap) + np.float32(img)\n",
        "    cam = cam / np.max(cam)\n",
        "    return np.uint8(255 * cam)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train_Draem"
      ],
      "metadata": {
        "id": "Qx-IsZIKi3ti"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBhipfWFwBrv",
        "outputId": "d60cfa4a-45f6-4a0b-9d31-5aece472861c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting train_DRAEM.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile train_DRAEM.py\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from dataset import CutPasteDataset, get_data_transforms\n",
        "from draem_model import DRAEM\n",
        "import time\n",
        "\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def loss_function(a, b):\n",
        "    return torch.mean(torch.abs(a-b))\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='DRAEM Implementation')\n",
        "    parser.add_argument('--obj_name', default='bottle', type=str, help='Name of MVTec object to train on')\n",
        "    parser.add_argument('--anomaly_source_path', default='/content/DRAEM_implementation/dtd/images', type=str, help='Directory for anomaly source images')\n",
        "    parser.add_argument('--checkpoint_path', default='checkpoints', type=str, help='Directory to save models')\n",
        "    parser.add_argument('--data_path', default='/content/drive/MyDrive', type=str, help='Path to parent directory containing bottle folder')\n",
        "    parser.add_argument('--epochs', default=30, type=int, help='Number of training epochs')\n",
        "    parser.add_argument('--lr', default=0.0001, type=float, help='Learning rate')\n",
        "    parser.add_argument('--img_size', default=256, type=int, help='Image size')\n",
        "    parser.add_argument('--bs', default=4, type=int, help='Batch size')\n",
        "    parser.add_argument('--gpu_id', default=0, type=int, help='GPU ID')\n",
        "    parser.add_argument('--seed', default=111, type=int, help='Random seed')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Verify dataset exists\n",
        "    train_dir = os.path.join(args.data_path, args.obj_name, 'train', 'good')\n",
        "    if not os.path.exists(train_dir):\n",
        "        raise RuntimeError(f\"Training directory not found: {train_dir}\")\n",
        "\n",
        "    train_files = [f for f in os.listdir(train_dir) if f.endswith(('.png', '.jpg'))]\n",
        "    if len(train_files) == 0:\n",
        "        raise RuntimeError(f\"No training images found in {train_dir}\")\n",
        "    print(f\"Found {len(train_files)} training images\")\n",
        "\n",
        "    setup_seed(args.seed)\n",
        "\n",
        "    device = torch.device('cuda:' + str(args.gpu_id) if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    data_transform, gt_transform = get_data_transforms(args.img_size, args.img_size)\n",
        "\n",
        "    cutpaste_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    train_dataset = CutPasteDataset(args.data_path, data_transform, cutpaste_transform, \"train\", args)\n",
        "\n",
        "    if len(train_dataset) == 0:\n",
        "        raise RuntimeError(f\"Dataset loaded but contains 0 samples. Check dataset structure.\")\n",
        "\n",
        "    print(f\"Dataset size: {len(train_dataset)} samples\")\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=args.bs, shuffle=True, num_workers=0)\n",
        "\n",
        "    # Create model\n",
        "    model = DRAEM().to(device)\n",
        "\n",
        "    # Optimizers\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
        "\n",
        "    # Create directory for checkpoints\n",
        "    os.makedirs(args.checkpoint_path, exist_ok=True)\n",
        "    os.makedirs(os.path.join(args.checkpoint_path, args.obj_name), exist_ok=True)\n",
        "\n",
        "    # Metrics for logging\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(args.epochs):\n",
        "        model.train()\n",
        "        loss_list = []\n",
        "\n",
        "        for sample_batched in tqdm(train_dataloader):\n",
        "            # Get the inputs\n",
        "            original_img, perturbed_img, mask, _ = sample_batched\n",
        "\n",
        "            original_img = original_img.to(device)\n",
        "            perturbed_img = perturbed_img.to(device)\n",
        "            mask = mask.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward + backward + optimize\n",
        "            reconstructed, output = model(perturbed_img, original_img, mask, mode=\"train\")\n",
        "\n",
        "            l1_loss = loss_function(reconstructed, original_img)\n",
        "\n",
        "            segment_loss = torch.nn.functional.mse_loss(output, mask)\n",
        "\n",
        "            loss = l1_loss + segment_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_list.append(loss.item())\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print statistics\n",
        "        epoch_loss = np.mean(loss_list)\n",
        "        print(f'Epoch: {epoch + 1}/{args.epochs}, Loss: {epoch_loss:.4f}, LR: {get_lr(optimizer):.6f}')\n",
        "\n",
        "        # Save checkpoint\n",
        "        if epoch_loss < best_loss:\n",
        "            best_loss = epoch_loss\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': epoch_loss,\n",
        "            }, os.path.join(args.checkpoint_path, args.obj_name, f'model_best.pth'))\n",
        "\n",
        "        # Save periodic checkpoint\n",
        "        if (epoch + 1) % 10 == 0 or (epoch + 1) == args.epochs:\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': epoch_loss,\n",
        "            }, os.path.join(args.checkpoint_path, args.obj_name, f'model_{epoch + 1}.pth'))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        main()\n",
        "    except Exception as e:\n",
        "        print(f\"Error in training: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test_Draem"
      ],
      "metadata": {
        "id": "GN9aIrd3i7ZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwaLitk6wDQo",
        "outputId": "9184a936-6f15-45af-c40e-71b2c22b03cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing test_DRAEM.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_DRAEM.py\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import argparse\n",
        "import numpy as np\n",
        "import os\n",
        "from dataset import MVTecDataset, get_data_transforms\n",
        "from draem_model import DRAEM\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset import show_cam_on_image\n",
        "import cv2\n",
        "import torch.serialization\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser('DRAEM Testing')\n",
        "    parser.add_argument('--gpu_id', type=int, default=0)\n",
        "    parser.add_argument('--obj_name', type=str, default='bottle')\n",
        "    parser.add_argument('--checkpoint_path', type=str, default='checkpoints')\n",
        "    parser.add_argument('--data_path', type=str, default='/content/drive/MyDrive')\n",
        "    parser.add_argument('--img_size', type=int, default=256)\n",
        "    parser.add_argument('--save_path', type=str, default='visualizations')\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "\n",
        "    # Verify data exists\n",
        "    test_dir = os.path.join(args.data_path, args.obj_name, 'test')\n",
        "    if not os.path.exists(test_dir):\n",
        "        raise RuntimeError(f\"Test directory not found: {test_dir}\")\n",
        "\n",
        "    test_types = [d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))]\n",
        "    if len(test_types) == 0:\n",
        "        raise RuntimeError(f\"No test categories found in {test_dir}\")\n",
        "\n",
        "    test_count = 0\n",
        "    for d in test_types:\n",
        "        test_count += len([f for f in os.listdir(os.path.join(test_dir, d)) if f.endswith(('.png', '.jpg'))])\n",
        "\n",
        "    if test_count == 0:\n",
        "        raise RuntimeError(f\"No test images found in {test_dir}\")\n",
        "\n",
        "    print(f\"Found {test_count} test images across {len(test_types)} categories\")\n",
        "\n",
        "    device = torch.device('cuda:' + str(args.gpu_id) if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Setup data transformations\n",
        "    data_transform, gt_transform = get_data_transforms(args.img_size, args.img_size)\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    test_dataset = MVTecDataset(args.data_path, data_transform, gt_transform, \"test\", args)\n",
        "    if len(test_dataset) == 0:\n",
        "        raise RuntimeError(f\"Test dataset loaded but contains 0 samples\")\n",
        "\n",
        "    print(f\"Test dataset size: {len(test_dataset)} samples\")\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
        "\n",
        "    # Create saving directory if it doesn't exist\n",
        "    os.makedirs(os.path.join(args.save_path, args.obj_name), exist_ok=True)\n",
        "\n",
        "   # Create model and load checkpoint\n",
        "    model = DRAEM().to(device)\n",
        "    checkpoint_path = os.path.join(args.checkpoint_path, args.obj_name, 'model_best.pth')\n",
        "\n",
        "    if os.path.exists(checkpoint_path):\n",
        "      try:\n",
        "          # Explicitly disable weights_only for compatibility\n",
        "          checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "          model.load_state_dict(checkpoint['model_state_dict'])\n",
        "          print(f\"Model loaded from {checkpoint_path}\")\n",
        "      except Exception as e:\n",
        "          print(f\"Error loading checkpoint: {e}\")\n",
        "          # Fallback to random weights\n",
        "          print(f\"Testing with random weights\")\n",
        "    else:\n",
        "      print(f\"No checkpoint found at {checkpoint_path}, testing with random weights\")\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "\n",
        "    gt_list_px = []\n",
        "    pred_list_px = []\n",
        "    gt_list_sp = []\n",
        "    pred_list_sp = []\n",
        "    img_paths = []\n",
        "    img_types = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sample_batched in test_dataloader:\n",
        "            img, gt, label, img_path, img_type = sample_batched\n",
        "\n",
        "            img = img.to(device)\n",
        "            gt = gt.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            reconstructed, output = model(img, mode=\"test\")\n",
        "\n",
        "            # Move results to CPU\n",
        "            reconstructed = reconstructed.cpu().numpy()\n",
        "            output = output.cpu().numpy()\n",
        "            img = img.cpu().numpy()\n",
        "            gt = gt.cpu().numpy()\n",
        "\n",
        "            # For pixel-level detection\n",
        "            for i in range(output.shape[0]):\n",
        "                anomaly_map = output[i, 0]\n",
        "                gt_map = gt[i, 0]\n",
        "\n",
        "                # Ensure ground truth is binary (0 or 1)\n",
        "                gt_map_binary = (gt_map > 0.5).astype(float)  # Binarize the ground truth mask\n",
        "\n",
        "                gt_list_px.extend(gt_map_binary.ravel())\n",
        "                pred_list_px.extend(anomaly_map.ravel())\n",
        "\n",
        "                # Image-level detection\n",
        "                gt_list_sp.append(label[i].item())\n",
        "                pred_list_sp.append(np.max(anomaly_map))\n",
        "\n",
        "\n",
        "                img_paths.append(img_path[i])\n",
        "                img_types.append(img_type[i])\n",
        "\n",
        "                # Save visualization\n",
        "                if args.save_path is not None:\n",
        "                    input_img = np.transpose(img[i], (1, 2, 0))\n",
        "                    input_img = input_img * 255\n",
        "                    input_img = input_img.astype(np.uint8)\n",
        "\n",
        "                    # Resize anomaly map to match input image dimensions if needed\n",
        "                    if anomaly_map.shape != input_img.shape[:2]:\n",
        "                        anomaly_map = cv2.resize(anomaly_map,(input_img.shape[1], input_img.shape[0]),interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "                    # Normalize anomaly map to 0-255 range\n",
        "                    anomaly_map_norm = (anomaly_map - anomaly_map.min()) / (anomaly_map.max() - anomaly_map.min() + 1e-7)\n",
        "                    anomaly_map_norm = anomaly_map_norm * 255\n",
        "                    anomaly_map_norm = anomaly_map_norm.astype(np.uint8)\n",
        "\n",
        "                    # Apply heatmap\n",
        "                    heatmap = cv2.applyColorMap(anomaly_map_norm, cv2.COLORMAP_JET)\n",
        "                    cam = np.float32(heatmap) + np.float32(input_img)\n",
        "                    cam = cam / np.max(cam)\n",
        "                    cam = np.uint8(255 * cam)\n",
        "\n",
        "                    # Save original image, reconstructed image, and anomaly map\n",
        "                    save_name = f\"{img_path[i]}_{img_type[i]}\"\n",
        "                    cv2.imwrite(os.path.join(args.save_path, args.obj_name, f\"{save_name}_original.png\"),\n",
        "                               cv2.cvtColor(input_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "                    recon_img = np.transpose(reconstructed[i], (1, 2, 0)) * 255\n",
        "                    recon_img = recon_img.astype(np.uint8)\n",
        "                    cv2.imwrite(os.path.join(args.save_path, args.obj_name, f\"{save_name}_reconstructed.png\"),\n",
        "                               cv2.cvtColor(recon_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "                    cv2.imwrite(os.path.join(args.save_path, args.obj_name, f\"{save_name}_anomaly_map.png\"),\n",
        "                               anomaly_map_norm)\n",
        "\n",
        "                    cv2.imwrite(os.path.join(args.save_path, args.obj_name, f\"{save_name}_heatmap.png\"),\n",
        "                               cam)\n",
        "\n",
        "    # Calculate metrics\n",
        "    pixel_auc = roc_auc_score(gt_list_px, pred_list_px)\n",
        "    image_auc = roc_auc_score(gt_list_sp, pred_list_sp)\n",
        "\n",
        "    # Calculate precision-recall AUC\n",
        "    precision, recall, _ = precision_recall_curve(gt_list_px, pred_list_px)\n",
        "    pixel_auprc = auc(recall, precision)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Object: {args.obj_name}\")\n",
        "    print(f\"Pixel-level AUROC: {pixel_auc:.4f}\")\n",
        "    print(f\"Image-level AUROC: {image_auc:.4f}\")\n",
        "    print(f\"Pixel-level AUPRC: {pixel_auprc:.4f}\")\n",
        "\n",
        "    # Save summary of results\n",
        "    with open(os.path.join(args.save_path, args.obj_name, 'results.txt'), 'w') as f:\n",
        "        f.write(f\"Object: {args.obj_name}\\n\")\n",
        "        f.write(f\"Pixel-level AUROC: {pixel_auc:.4f}\\n\")\n",
        "        f.write(f\"Image-level AUROC: {image_auc:.4f}\\n\")\n",
        "        f.write(f\"Pixel-level AUPRC: {pixel_auprc:.4f}\\n\")\n",
        "\n",
        "    # Create per-category results\n",
        "    category_results = {}\n",
        "    for i, img_type in enumerate(img_types):\n",
        "        if img_type not in category_results:\n",
        "            category_results[img_type] = {\"gt\": [], \"pred\": []}\n",
        "        category_results[img_type][\"gt\"].append(gt_list_sp[i])\n",
        "        category_results[img_type][\"pred\"].append(pred_list_sp[i])\n",
        "\n",
        "    print(\"\\nPer-category image-level AUROC:\")\n",
        "    for category, values in category_results.items():\n",
        "        if len(set(values[\"gt\"])) > 1:  # Need both positive and negative samples\n",
        "            cat_auc = roc_auc_score(values[\"gt\"], values[\"pred\"])\n",
        "            print(f\"{category}: {cat_auc:.4f}\")\n",
        "\n",
        "    # Save ROC curve\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(f'Pixel-level ROC Curve (AUC={pixel_auc:.4f})')\n",
        "    from sklearn.metrics import roc_curve\n",
        "    fpr, tpr, _ = roc_curve(gt_list_px, pred_list_px)\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(f'Image-level ROC Curve (AUC={image_auc:.4f})')\n",
        "    fpr, tpr, _ = roc_curve(gt_list_sp, pred_list_sp)\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(args.save_path, args.obj_name, 'roc_curve.png'))\n",
        "\n",
        "    return pixel_auc, image_auc, pixel_auprc\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        main()\n",
        "    except Exception as e:\n",
        "        print(f\"Error in testing: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run_Reproduction"
      ],
      "metadata": {
        "id": "lrH6ILq_i-7o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzKA73ARwFhv",
        "outputId": "9d4809e8-4717-49b3-f6c2-518d245c1606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing run_reproduction.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile run_reproduction.py\n",
        "import argparse\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_command(command):\n",
        "    print(f\"Running: {command}\")\n",
        "    process = subprocess.run(command, shell=True)\n",
        "    return process.returncode == 0\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='DRAEM Reproduction Pipeline')\n",
        "    parser.add_argument('--mvtec_path', default='/content/drive/MyDrive',\n",
        "                        help='Path to parent directory containing bottle folder')\n",
        "    parser.add_argument('--dtd_path', default='/content/drive/MyDrive/dtd/images',\n",
        "                        help='Path to DTD dataset on Google Drive')\n",
        "    parser.add_argument('--epochs', type=int, default=30,\n",
        "                        help='Number of training epochs')\n",
        "    parser.add_argument('--batch_size', type=int, default=4,\n",
        "                        help='Batch size for training')\n",
        "    parser.add_argument('--test_only', action='store_true',\n",
        "                        help='Run only testing without training')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Verify paths\n",
        "    print(\"=== Verifying dataset paths ===\")\n",
        "    if not os.path.exists(args.mvtec_path):\n",
        "        print(f\"Error: MVTec path {args.mvtec_path} not found!\")\n",
        "        return False\n",
        "\n",
        "    bottle_path = os.path.join(args.mvtec_path, 'bottle')\n",
        "    if not os.path.exists(bottle_path):\n",
        "        print(f\"Error: Bottle category {bottle_path} not found!\")\n",
        "        return False\n",
        "\n",
        "    # Print dataset information\n",
        "    train_good = os.path.join(bottle_path, 'train', 'good')\n",
        "    test_path = os.path.join(bottle_path, 'test')\n",
        "\n",
        "    if os.path.exists(train_good):\n",
        "        train_images = len([f for f in os.listdir(train_good) if f.endswith(('.png', '.jpg'))])\n",
        "        print(f\"Found {train_images} training images\")\n",
        "    else:\n",
        "        print(f\"Error: Training path {train_good} not found!\")\n",
        "        return False\n",
        "\n",
        "    if os.path.exists(test_path):\n",
        "        test_categories = [d for d in os.listdir(test_path) if os.path.isdir(os.path.join(test_path, d))]\n",
        "        test_count = 0\n",
        "        for cat in test_categories:\n",
        "            cat_path = os.path.join(test_path, cat)\n",
        "            cat_images = len([f for f in os.listdir(cat_path) if f.endswith(('.png', '.jpg'))])\n",
        "            test_count += cat_images\n",
        "            print(f\"  - {cat}: {cat_images} images\")\n",
        "        print(f\"Found {test_count} test images across {len(test_categories)} categories\")\n",
        "    else:\n",
        "        print(f\"Error: Test path {test_path} not found!\")\n",
        "        return False\n",
        "\n",
        "    # Check DTD path\n",
        "    dtd_exists = os.path.exists(args.dtd_path)\n",
        "    if not dtd_exists:\n",
        "        print(f\"Warning: DTD path {args.dtd_path} not found. Synthetic textures will be created.\")\n",
        "\n",
        "    # Create necessary directories\n",
        "    os.makedirs('checkpoints/bottle', exist_ok=True)\n",
        "    os.makedirs('visualizations/bottle', exist_ok=True)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the model\n",
        "    if not args.test_only:\n",
        "        print(\"\\n=== Training DRAEM model ===\")\n",
        "        if not run_command(f\"python train_DRAEM.py --obj_name bottle --data_path {args.mvtec_path} --anomaly_source_path {args.dtd_path} --epochs {args.epochs} --bs {args.batch_size}\"):\n",
        "            print(\"Training failed!\")\n",
        "            return False\n",
        "\n",
        "    # Test the model\n",
        "    print(\"\\n=== Testing DRAEM model ===\")\n",
        "    if not run_command(f\"python test_DRAEM.py --obj_name bottle --data_path {args.mvtec_path}\"):\n",
        "        print(\"Testing failed!\")\n",
        "        return False\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\n=== Reproduction completed in {total_time:.2f} seconds ===\")\n",
        "    return True\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on Bottle Category"
      ],
      "metadata": {
        "id": "-w1qhSN0jGrK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZiyK5o0wKgq",
        "outputId": "0a482b43-0a05-4084-ca5c-8089a9f349dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-15 12:45:49--  https://www.robots.ox.ac.uk/~vgg/data/dtd/download/dtd-r1.0.1.tar.gz\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://thor.robots.ox.ac.uk/dtd/dtd-r1.0.1.tar.gz [following]\n",
            "--2025-03-15 12:45:51--  https://thor.robots.ox.ac.uk/dtd/dtd-r1.0.1.tar.gz\n",
            "Resolving thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)... 129.67.95.98\n",
            "Connecting to thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)|129.67.95.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 625239812 (596M) [application/octet-stream]\n",
            "Saving to: ‘dtd-r1.0.1.tar.gz’\n",
            "\n",
            "dtd-r1.0.1.tar.gz   100%[===================>] 596.27M  7.74MB/s    in 61s     \n",
            "\n",
            "2025-03-15 12:46:53 (9.79 MB/s) - ‘dtd-r1.0.1.tar.gz’ saved [625239812/625239812]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.robots.ox.ac.uk/~vgg/data/dtd/download/dtd-r1.0.1.tar.gz\n",
        "!mkdir -p dtd\n",
        "!tar -xf dtd-r1.0.1.tar.gz -C dtd\n",
        "!mv dtd/dtd/* dtd/\n",
        "!rm -rf dtd/dtd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0eN0oHi0nOH",
        "outputId": "4a688240-8ed6-4b5a-a655-56f15447148d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images in DTD dataset: 5673\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "dtd_path = \"/content/DRAEM_implementation/dtd\"\n",
        "num_images = sum([len(files) for _, _, files in os.walk(dtd_path)])\n",
        "\n",
        "print(f\"Total images in DTD dataset: {num_images}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6DLVXKA4HYq",
        "outputId": "e47aad96-3fae-4432-c1f3-b18a63dd5608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Verifying dataset paths ===\n",
            "Found 222 training images\n",
            "  - contamination: 21 images\n",
            "  - broken_large: 20 images\n",
            "  - broken_small: 22 images\n",
            "  - good: 20 images\n",
            "Found 83 test images across 4 categories\n",
            "\n",
            "=== Training DRAEM model ===\n",
            "Running: python train_DRAEM.py --obj_name bottle --data_path /content/drive/MyDrive --anomaly_source_path /content/DRAEM_implementation/dtd/images --epochs 40 --bs 4\n",
            "Found 222 training images\n",
            "Using device: cuda:0\n",
            "Found 222 training images and 5640 anomaly source images\n",
            "Dataset size: 222 samples\n",
            "100% 56/56 [00:15<00:00,  3.69it/s]\n",
            "Epoch: 1/40, Loss: 0.6087, LR: 0.000100\n",
            "100% 56/56 [00:14<00:00,  3.91it/s]\n",
            "Epoch: 2/40, Loss: 0.3385, LR: 0.000099\n",
            "100% 56/56 [00:14<00:00,  3.88it/s]\n",
            "Epoch: 3/40, Loss: 0.3076, LR: 0.000099\n",
            "100% 56/56 [00:14<00:00,  3.88it/s]\n",
            "Epoch: 4/40, Loss: 0.2691, LR: 0.000098\n",
            "100% 56/56 [00:15<00:00,  3.62it/s]\n",
            "Epoch: 5/40, Loss: 0.2334, LR: 0.000096\n",
            "100% 56/56 [00:14<00:00,  3.96it/s]\n",
            "Epoch: 6/40, Loss: 0.2022, LR: 0.000095\n",
            "100% 56/56 [00:14<00:00,  3.91it/s]\n",
            "Epoch: 7/40, Loss: 0.1778, LR: 0.000093\n",
            "100% 56/56 [00:14<00:00,  3.97it/s]\n",
            "Epoch: 8/40, Loss: 0.1566, LR: 0.000090\n",
            "100% 56/56 [00:14<00:00,  3.96it/s]\n",
            "Epoch: 9/40, Loss: 0.1381, LR: 0.000088\n",
            "100% 56/56 [00:14<00:00,  3.91it/s]\n",
            "Epoch: 10/40, Loss: 0.1237, LR: 0.000085\n",
            "100% 56/56 [00:14<00:00,  3.82it/s]\n",
            "Epoch: 11/40, Loss: 0.1093, LR: 0.000082\n",
            "100% 56/56 [00:14<00:00,  3.88it/s]\n",
            "Epoch: 12/40, Loss: 0.0999, LR: 0.000079\n",
            "100% 56/56 [00:14<00:00,  3.87it/s]\n",
            "Epoch: 13/40, Loss: 0.0902, LR: 0.000076\n",
            "100% 56/56 [00:14<00:00,  3.87it/s]\n",
            "Epoch: 14/40, Loss: 0.0835, LR: 0.000073\n",
            "100% 56/56 [00:14<00:00,  3.89it/s]\n",
            "Epoch: 15/40, Loss: 0.0774, LR: 0.000069\n",
            "100% 56/56 [00:14<00:00,  3.92it/s]\n",
            "Epoch: 16/40, Loss: 0.0725, LR: 0.000065\n",
            "100% 56/56 [00:14<00:00,  3.90it/s]\n",
            "Epoch: 17/40, Loss: 0.0686, LR: 0.000062\n",
            "100% 56/56 [00:14<00:00,  3.94it/s]\n",
            "Epoch: 18/40, Loss: 0.0647, LR: 0.000058\n",
            "100% 56/56 [00:14<00:00,  3.95it/s]\n",
            "Epoch: 19/40, Loss: 0.0615, LR: 0.000054\n",
            "100% 56/56 [00:14<00:00,  3.89it/s]\n",
            "Epoch: 20/40, Loss: 0.0591, LR: 0.000050\n",
            "100% 56/56 [00:14<00:00,  3.96it/s]\n",
            "Epoch: 21/40, Loss: 0.0574, LR: 0.000046\n",
            "100% 56/56 [00:14<00:00,  3.94it/s]\n",
            "Epoch: 22/40, Loss: 0.0556, LR: 0.000042\n",
            "100% 56/56 [00:14<00:00,  3.85it/s]\n",
            "Epoch: 23/40, Loss: 0.0538, LR: 0.000038\n",
            "100% 56/56 [00:14<00:00,  3.87it/s]\n",
            "Epoch: 24/40, Loss: 0.0516, LR: 0.000035\n",
            "100% 56/56 [00:14<00:00,  3.82it/s]\n",
            "Epoch: 25/40, Loss: 0.0513, LR: 0.000031\n",
            "100% 56/56 [00:14<00:00,  3.86it/s]\n",
            "Epoch: 26/40, Loss: 0.0494, LR: 0.000027\n",
            "100% 56/56 [00:14<00:00,  3.92it/s]\n",
            "Epoch: 27/40, Loss: 0.0495, LR: 0.000024\n",
            "100% 56/56 [00:14<00:00,  3.95it/s]\n",
            "Epoch: 28/40, Loss: 0.0487, LR: 0.000021\n",
            "100% 56/56 [00:14<00:00,  3.98it/s]\n",
            "Epoch: 29/40, Loss: 0.0470, LR: 0.000018\n",
            "100% 56/56 [00:13<00:00,  4.01it/s]\n",
            "Epoch: 30/40, Loss: 0.0466, LR: 0.000015\n",
            "100% 56/56 [00:15<00:00,  3.70it/s]\n",
            "Epoch: 31/40, Loss: 0.0466, LR: 0.000012\n",
            "100% 56/56 [00:17<00:00,  3.16it/s]\n",
            "Epoch: 32/40, Loss: 0.0458, LR: 0.000010\n",
            "100% 56/56 [00:14<00:00,  3.89it/s]\n",
            "Epoch: 33/40, Loss: 0.0462, LR: 0.000007\n",
            "100% 56/56 [00:17<00:00,  3.11it/s]\n",
            "Epoch: 34/40, Loss: 0.0458, LR: 0.000005\n",
            "100% 56/56 [00:14<00:00,  3.94it/s]\n",
            "Epoch: 35/40, Loss: 0.0450, LR: 0.000004\n",
            "100% 56/56 [00:14<00:00,  3.97it/s]\n",
            "Epoch: 36/40, Loss: 0.0453, LR: 0.000002\n",
            "100% 56/56 [00:14<00:00,  3.98it/s]\n",
            "Epoch: 37/40, Loss: 0.0447, LR: 0.000001\n",
            "100% 56/56 [00:14<00:00,  3.73it/s]\n",
            "Epoch: 38/40, Loss: 0.0447, LR: 0.000001\n",
            "100% 56/56 [00:14<00:00,  3.90it/s]\n",
            "Epoch: 39/40, Loss: 0.0449, LR: 0.000000\n",
            "100% 56/56 [00:14<00:00,  3.92it/s]\n",
            "Epoch: 40/40, Loss: 0.0451, LR: 0.000000\n",
            "\n",
            "=== Testing DRAEM model ===\n",
            "Running: python test_DRAEM.py --obj_name bottle --data_path /content/drive/MyDrive\n",
            "Found 83 test images across 4 categories\n",
            "Using device: cuda:0\n",
            "Test dataset size: 83 samples\n",
            "Model loaded from checkpoints/bottle/model_best.pth\n",
            "Object: bottle\n",
            "Pixel-level AUROC: 0.8365\n",
            "Image-level AUROC: 0.9389\n",
            "Pixel-level AUPRC: 0.4731\n",
            "\n",
            "Per-category image-level AUROC:\n",
            "\n",
            "=== Reproduction completed in 623.82 seconds ===\n"
          ]
        }
      ],
      "source": [
        "!python run_reproduction.py --mvtec_path /content/drive/MyDrive --dtd_path /content/DRAEM_implementation/dtd/images --epochs 40 --batch_size 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtgMhJ_R5MNO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Path to your visualizations\n",
        "viz_path = '/content/DRAEM_implementation/visualizations/bottle'\n",
        "\n",
        "# Get all visualization files\n",
        "files = os.listdir(viz_path)\n",
        "\n",
        "# Group files by sample name\n",
        "sample_groups = {}\n",
        "for file in files:\n",
        "    if file.endswith('.png') and not file == 'roc_curve.png':\n",
        "        # Extract sample name (before the underscore and visualization type)\n",
        "        parts = file.split('_')\n",
        "        if len(parts) >= 3:\n",
        "            sample_name = '_'.join(parts[:-1])  # Everything except the last part\n",
        "            if sample_name not in sample_groups:\n",
        "                sample_groups[sample_name] = []\n",
        "            sample_groups[sample_name].append(file)\n",
        "\n",
        "# Display visualizations for each sample\n",
        "for sample_name, image_files in sample_groups.items():\n",
        "    print(f\"\\n=== Visualization for {sample_name} ===\")\n",
        "\n",
        "    # Sort files to display in consistent order\n",
        "    image_files.sort()\n",
        "\n",
        "    # Create a figure with subplots\n",
        "    plt.figure(figsize=(20, 5))\n",
        "\n",
        "    for i, img_file in enumerate(image_files):\n",
        "        img = cv2.imread(os.path.join(viz_path, img_file))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        plt.subplot(1, 4, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(img_file.split('_')[-1].replace('.png', ''))\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on Sub-Categories of Bottle"
      ],
      "metadata": {
        "id": "WU3bL-TxjYcM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_XFnOjn7FPA",
        "outputId": "01399818-ca95-4e19-886d-75544d4ee085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting test_DRAEM_2.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_DRAEM_2.py\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import argparse\n",
        "import cv2\n",
        "from torch.utils.data import DataLoader\n",
        "from dataset import MVTecDataset, get_data_transforms\n",
        "from draem_model import DRAEM\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser('DRAEM Testing')\n",
        "    parser.add_argument('--gpu_id', type=int, default=0)\n",
        "    parser.add_argument('--obj_name', type=str, default='bottle')\n",
        "    parser.add_argument('--checkpoint_path', type=str, default='checkpoints')\n",
        "    parser.add_argument('--data_path', type=str, default='/content/drive/MyDrive')\n",
        "    parser.add_argument('--img_size', type=int, default=256)\n",
        "    parser.add_argument('--save_path', type=str, default='visualizations')\n",
        "\n",
        "    args, _ = parser.parse_known_args()  # ✅ Ignore unrecognized arguments from Jupyter\n",
        "    return args\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "\n",
        "    # Verify dataset paths\n",
        "    test_dir = os.path.join(args.data_path, args.obj_name, 'test')\n",
        "    if not os.path.exists(test_dir):\n",
        "        raise RuntimeError(f\"Test directory not found: {test_dir}\")\n",
        "\n",
        "    # Initialize metrics storage\n",
        "    metrics = {\n",
        "        'pixel': defaultdict(lambda: {'gt': [], 'pred': []}),\n",
        "        'image': defaultdict(lambda: {'gt': [], 'pred': []})\n",
        "    }\n",
        "\n",
        "    device = torch.device(f'cuda:{args.gpu_id}' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load model\n",
        "    model = DRAEM().to(device)\n",
        "    checkpoint_path = os.path.join(args.checkpoint_path, args.obj_name, 'model_best.pth')\n",
        "\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        print(f\"Model loaded from {checkpoint_path}\")\n",
        "    else:\n",
        "        print(f\"No checkpoint found at {checkpoint_path}\")\n",
        "        return\n",
        "\n",
        "    # Data loading\n",
        "    data_transform, gt_transform = get_data_transforms(args.img_size, args.img_size)\n",
        "    test_dataset = MVTecDataset(args.data_path, data_transform, gt_transform, \"test\", args)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for sample in test_dataloader:\n",
        "            img, gt, label, img_path, defect_type = sample\n",
        "            img = img.to(device)\n",
        "            gt = gt.to(device)\n",
        "\n",
        "            # Get predictions\n",
        "            reconstruction, prediction = model(img, mode=\"test\")\n",
        "            prediction = prediction.cpu().numpy()\n",
        "            gt = gt.cpu().numpy()\n",
        "\n",
        "            # Get texture category from defect type\n",
        "            texture_category = defect_type[0] if defect_type[0] != 'good' else 'natural'\n",
        "\n",
        "            # Store metrics\n",
        "            for i in range(prediction.shape[0]):\n",
        "                # Pixel-level\n",
        "                gt_flat = (gt[i,0] > 0.5).astype(float).ravel()\n",
        "                pred_flat = prediction[i,0].ravel()\n",
        "                metrics['pixel'][texture_category]['gt'].extend(gt_flat)\n",
        "                metrics['pixel'][texture_category]['pred'].extend(pred_flat)\n",
        "\n",
        "                # Image-level\n",
        "                metrics['image'][texture_category]['gt'].append(label[i].item())\n",
        "                metrics['image'][texture_category]['pred'].append(prediction[i,0].max())\n",
        "\n",
        "    # Calculate and print metrics\n",
        "    print(\"\\n=== Detailed Texture Category Metrics ===\")\n",
        "    for category in sorted(metrics['pixel'].keys()):\n",
        "        pixel_gt = np.array(metrics['pixel'][category]['gt'])\n",
        "        pixel_pred = np.array(metrics['pixel'][category]['pred'])\n",
        "        image_gt = np.array(metrics['image'][category]['gt'])\n",
        "        image_pred = np.array(metrics['image'][category]['pred'])\n",
        "\n",
        "        # Pixel-level\n",
        "        if len(np.unique(pixel_gt)) > 1:\n",
        "            pixel_auc = roc_auc_score(pixel_gt, pixel_pred)\n",
        "            precision, recall, _ = precision_recall_curve(pixel_gt, pixel_pred)\n",
        "            pixel_auprc = auc(recall, precision)\n",
        "        else:\n",
        "            pixel_auc = pixel_auprc = np.nan\n",
        "\n",
        "        # Image-level\n",
        "        if len(np.unique(image_gt)) > 1:\n",
        "            image_auc = roc_auc_score(image_gt, image_pred)\n",
        "        else:\n",
        "            image_auc = np.nan\n",
        "\n",
        "        print(f\"\\nCategory: {category}\")\n",
        "        print(f\"  Pixel AUROC: {pixel_auc:.4f}\")\n",
        "        print(f\"  Pixel AUPRC: {pixel_auprc:.4f}\")\n",
        "        print(f\"  Image AUROC: {image_auc:.4f}\")\n",
        "\n",
        "    # Calculate global metrics\n",
        "    all_pixel_gt = np.concatenate([np.array(v['gt']) for v in metrics['pixel'].values()])\n",
        "    all_pixel_pred = np.concatenate([np.array(v['pred']) for v in metrics['pixel'].values()])\n",
        "    all_image_gt = np.concatenate([np.array(v['gt']) for v in metrics['image'].values()])\n",
        "    all_image_pred = np.concatenate([np.array(v['pred']) for v in metrics['image'].values()])\n",
        "\n",
        "    print(\"\\n=== Global Metrics ===\")\n",
        "    print(f\"Total Pixel AUROC: {roc_auc_score(all_pixel_gt, all_pixel_pred):.4f}\")\n",
        "    print(f\"Total Image AUROC: {roc_auc_score(all_image_gt, all_image_pred):.4f}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV5YJost7Kg_",
        "outputId": "832ef8f4-b638-4b1b-ba59-31ec623548f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded from checkpoints/bottle/model_best.pth\n",
            "\n",
            "=== Detailed Texture Category Metrics ===\n",
            "\n",
            "Category: broken_large\n",
            "  Pixel AUROC: 0.8443\n",
            "  Pixel AUPRC: 0.5555\n",
            "  Image AUROC: nan\n",
            "\n",
            "Category: broken_small\n",
            "  Pixel AUROC: 0.9261\n",
            "  Pixel AUPRC: 0.5963\n",
            "  Image AUROC: nan\n",
            "\n",
            "Category: contamination\n",
            "  Pixel AUROC: 0.7572\n",
            "  Pixel AUPRC: 0.4096\n",
            "  Image AUROC: nan\n",
            "\n",
            "Category: natural\n",
            "  Pixel AUROC: nan\n",
            "  Pixel AUPRC: nan\n",
            "  Image AUROC: nan\n",
            "\n",
            "=== Global Metrics ===\n",
            "Total Pixel AUROC: 0.8365\n",
            "Total Image AUROC: 0.9389\n"
          ]
        }
      ],
      "source": [
        "!python test_DRAEM_2.py --obj_name bottle --data_path /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMDSzjK-BL83",
        "outputId": "2bce0c16-36ad-469a-c119-747f21ea1633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting test_DRAEM.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_DRAEM.py\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import argparse\n",
        "import numpy as np\n",
        "import os\n",
        "from dataset import MVTecDataset, get_data_transforms\n",
        "from draem_model import DRAEM\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset import show_cam_on_image\n",
        "import cv2\n",
        "import torch.serialization\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser('DRAEM Testing')\n",
        "    parser.add_argument('--gpu_id', type=int, default=0)\n",
        "    parser.add_argument('--obj_name', type=str, default='bottle')\n",
        "    parser.add_argument('--checkpoint_path', type=str, default='checkpoints')\n",
        "    parser.add_argument('--data_path', type=str, default='/content/drive/MyDrive')\n",
        "    parser.add_argument('--img_size', type=int, default=256)\n",
        "    parser.add_argument('--save_path', type=str, default='visualizations')\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "\n",
        "    # Verify data exists\n",
        "    test_dir = os.path.join(args.data_path, args.obj_name, 'test')\n",
        "    if not os.path.exists(test_dir):\n",
        "        raise RuntimeError(f\"Test directory not found: {test_dir}\")\n",
        "\n",
        "    test_types = [d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))]\n",
        "    if len(test_types) == 0:\n",
        "        raise RuntimeError(f\"No test categories found in {test_dir}\")\n",
        "\n",
        "    test_count = 0\n",
        "    for d in test_types:\n",
        "        test_count += len([f for f in os.listdir(os.path.join(test_dir, d)) if f.endswith(('.png', '.jpg'))])\n",
        "\n",
        "    if test_count == 0:\n",
        "        raise RuntimeError(f\"No test images found in {test_dir}\")\n",
        "\n",
        "    print(f\"Found {test_count} test images across {len(test_types)} categories\")\n",
        "\n",
        "    device = torch.device('cuda:' + str(args.gpu_id) if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Setup data transformations\n",
        "    data_transform, gt_transform = get_data_transforms(args.img_size, args.img_size)\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    test_dataset = MVTecDataset(args.data_path, data_transform, gt_transform, \"test\", args)\n",
        "    if len(test_dataset) == 0:\n",
        "        raise RuntimeError(f\"Test dataset loaded but contains 0 samples\")\n",
        "\n",
        "    print(f\"Test dataset size: {len(test_dataset)} samples\")\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
        "\n",
        "    # Create saving directory if it doesn't exist\n",
        "    os.makedirs(os.path.join(args.save_path, args.obj_name), exist_ok=True)\n",
        "\n",
        "   # Create model and load checkpoint\n",
        "    model = DRAEM().to(device)\n",
        "    checkpoint_path = os.path.join(args.checkpoint_path, args.obj_name, 'model_best.pth')\n",
        "\n",
        "    if os.path.exists(checkpoint_path):\n",
        "      try:\n",
        "          # Explicitly disable weights_only for compatibility\n",
        "          checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "          model.load_state_dict(checkpoint['model_state_dict'])\n",
        "          print(f\"Model loaded from {checkpoint_path}\")\n",
        "      except Exception as e:\n",
        "          print(f\"Error loading checkpoint: {e}\")\n",
        "          # Fallback to random weights\n",
        "          print(f\"Testing with random weights\")\n",
        "    else:\n",
        "      print(f\"No checkpoint found at {checkpoint_path}, testing with random weights\")\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "\n",
        "    gt_list_px = []\n",
        "    pred_list_px = []\n",
        "    gt_list_sp = []\n",
        "    pred_list_sp = []\n",
        "    img_paths = []\n",
        "    img_types = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sample_batched in test_dataloader:\n",
        "            img, gt, label, img_path, img_type = sample_batched\n",
        "\n",
        "            img = img.to(device)\n",
        "            gt = gt.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            reconstructed, output = model(img, mode=\"test\")\n",
        "\n",
        "            # Move results to CPU\n",
        "            reconstructed = reconstructed.cpu().numpy()\n",
        "            output = output.cpu().numpy()\n",
        "            img = img.cpu().numpy()\n",
        "            gt = gt.cpu().numpy()\n",
        "\n",
        "            # For pixel-level detection\n",
        "            for i in range(output.shape[0]):\n",
        "                anomaly_map = output[i, 0]\n",
        "                gt_map = gt[i, 0]\n",
        "\n",
        "                # Ensure ground truth is binary (0 or 1)\n",
        "                gt_map_binary = (gt_map > 0.5).astype(float)  # Binarize the ground truth mask\n",
        "\n",
        "                gt_list_px.extend(gt_map_binary.ravel())\n",
        "                pred_list_px.extend(anomaly_map.ravel())\n",
        "\n",
        "                # Image-level detection\n",
        "                gt_list_sp.append(label[i].item())\n",
        "                pred_list_sp.append(np.max(anomaly_map))\n",
        "\n",
        "\n",
        "                img_paths.append(img_path[i])\n",
        "                img_types.append(img_type[i])\n",
        "\n",
        "                # Save visualization\n",
        "                if args.save_path is not None:\n",
        "                    input_img = np.transpose(img[i], (1, 2, 0))\n",
        "                    input_img = input_img * 255\n",
        "                    input_img = input_img.astype(np.uint8)\n",
        "\n",
        "                    # Resize anomaly map to match input image dimensions if needed\n",
        "                    if anomaly_map.shape != input_img.shape[:2]:\n",
        "                        anomaly_map = cv2.resize(anomaly_map,(input_img.shape[1], input_img.shape[0]),interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "                    # Normalize anomaly map to 0-255 range\n",
        "                    anomaly_map_norm = (anomaly_map - anomaly_map.min()) / (anomaly_map.max() - anomaly_map.min() + 1e-7)\n",
        "                    anomaly_map_norm = anomaly_map_norm * 255\n",
        "                    anomaly_map_norm = anomaly_map_norm.astype(np.uint8)\n",
        "\n",
        "                    # Apply heatmap\n",
        "                    heatmap = cv2.applyColorMap(anomaly_map_norm, cv2.COLORMAP_JET)\n",
        "                    cam = np.float32(heatmap) + np.float32(input_img)\n",
        "                    cam = cam / np.max(cam)\n",
        "                    cam = np.uint8(255 * cam)\n",
        "\n",
        "                    # Save original image, reconstructed image, and anomaly map\n",
        "                    save_name = f\"{img_path[i]}_{img_type[i]}\"\n",
        "                    cv2.imwrite(os.path.join(args.save_path, args.obj_name, f\"{save_name}_original.png\"),\n",
        "                               cv2.cvtColor(input_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "                    recon_img = np.transpose(reconstructed[i], (1, 2, 0)) * 255\n",
        "                    recon_img = recon_img.astype(np.uint8)\n",
        "                    cv2.imwrite(os.path.join(args.save_path, args.obj_name, f\"{save_name}_reconstructed.png\"),\n",
        "                               cv2.cvtColor(recon_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "                    cv2.imwrite(os.path.join(args.save_path, args.obj_name, f\"{save_name}_anomaly_map.png\"),\n",
        "                               anomaly_map_norm)\n",
        "\n",
        "                    cv2.imwrite(os.path.join(args.save_path, args.obj_name, f\"{save_name}_heatmap.png\"),\n",
        "                               cam)\n",
        "\n",
        "    # Calculate metrics\n",
        "    pixel_auc = roc_auc_score(gt_list_px, pred_list_px)\n",
        "    image_auc = roc_auc_score(gt_list_sp, pred_list_sp)\n",
        "\n",
        "    # Calculate precision-recall AUC\n",
        "    precision, recall, _ = precision_recall_curve(gt_list_px, pred_list_px)\n",
        "    pixel_auprc = auc(recall, precision)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Object: {args.obj_name}\")\n",
        "    print(f\"Pixel-level AUROC: {pixel_auc:.4f}\")\n",
        "    print(f\"Image-level AUROC: {image_auc:.4f}\")\n",
        "    print(f\"Pixel-level AUPRC: {pixel_auprc:.4f}\")\n",
        "\n",
        "    # Save summary of results\n",
        "    with open(os.path.join(args.save_path, args.obj_name, 'results.txt'), 'w') as f:\n",
        "        f.write(f\"Object: {args.obj_name}\\n\")\n",
        "        f.write(f\"Pixel-level AUROC: {pixel_auc:.4f}\\n\")\n",
        "        f.write(f\"Image-level AUROC: {image_auc:.4f}\\n\")\n",
        "        f.write(f\"Pixel-level AUPRC: {pixel_auprc:.4f}\\n\")\n",
        "\n",
        "    # Create per-category results\n",
        "    category_results = {}\n",
        "    for i, img_type in enumerate(img_types):\n",
        "        if img_type not in category_results:\n",
        "            category_results[img_type] = {\"gt\": [], \"pred\": []}\n",
        "        category_results[img_type][\"gt\"].append(gt_list_sp[i])\n",
        "        category_results[img_type][\"pred\"].append(pred_list_sp[i])\n",
        "\n",
        "    print(\"\\nPer-category image-level AUROC:\")\n",
        "    for category, values in category_results.items():\n",
        "        if len(set(values[\"gt\"])) > 1:  # Need both positive and negative samples\n",
        "            cat_auc = roc_auc_score(values[\"gt\"], values[\"pred\"])\n",
        "            print(f\"{category}: {cat_auc:.4f}\")\n",
        "\n",
        "    # Save ROC curve\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(f'Pixel-level ROC Curve (AUC={pixel_auc:.4f})')\n",
        "    from sklearn.metrics import roc_curve\n",
        "    fpr, tpr, _ = roc_curve(gt_list_px, pred_list_px)\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(f'Image-level ROC Curve (AUC={image_auc:.4f})')\n",
        "    fpr, tpr, _ = roc_curve(gt_list_sp, pred_list_sp)\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(args.save_path, args.obj_name, 'roc_curve.png'))\n",
        "\n",
        "    # Save evaluation data for visualization\n",
        "    np.savez('results.npz',\n",
        "            gt_list_px=gt_list_px,\n",
        "            pred_list_px=pred_list_px,\n",
        "            gt_list_sp=gt_list_sp,\n",
        "            pred_list_sp=pred_list_sp)\n",
        "\n",
        "    print(\"Results saved to results.npz\")\n",
        "\n",
        "    return pixel_auc, image_auc, pixel_auprc\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        main()\n",
        "    except Exception as e:\n",
        "        print(f\"Error in testing: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pULQDcQ4BUdE",
        "outputId": "2368e458-19cf-4b1e-8d37-81b79f232beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 83 test images across 4 categories\n",
            "Using device: cuda:0\n",
            "Test dataset size: 83 samples\n",
            "Model loaded from checkpoints/bottle/model_best.pth\n",
            "Object: bottle\n",
            "Pixel-level AUROC: 0.8365\n",
            "Image-level AUROC: 0.9389\n",
            "Pixel-level AUPRC: 0.4731\n",
            "\n",
            "Per-category image-level AUROC:\n",
            "Results saved to results.npz\n"
          ]
        }
      ],
      "source": [
        "!python test_DRAEM.py --obj_name bottle --data_path /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization"
      ],
      "metadata": {
        "id": "gO7xYeNUjimk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lBmInBzS_Hnn",
        "outputId": "4bf9ae10-3d1e-42ee-a034-7dace1fdf4f5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, roc_auc_score, auc\n",
        "\n",
        "# Load saved data\n",
        "data = np.load('results.npz')\n",
        "gt_list_px = data['gt_list_px']\n",
        "pred_list_px = data['pred_list_px']\n",
        "gt_list_sp = data['gt_list_sp']\n",
        "pred_list_sp = data['pred_list_sp']\n",
        "\n",
        "# ==================== 1. Histogram of Anomaly Scores ====================\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(pred_list_sp, bins=30, edgecolor='black')\n",
        "plt.title('Distribution of Anomaly Scores')\n",
        "plt.xlabel('Anomaly Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True, alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "# ==================== 2. ROC Curve for Pixel-Level Detection ====================\n",
        "fpr_px, tpr_px, _ = roc_curve(gt_list_px, pred_list_px)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_px, tpr_px, label=f'Pixel-Level ROC (AUC = {roc_auc_score(gt_list_px, pred_list_px):.4f})', linewidth=2)\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Random classifier line\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Pixel-Level ROC Curve')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "# ==================== 3. Precision-Recall Curve for Pixel-Level ====================\n",
        "precision_px, recall_px, _ = precision_recall_curve(gt_list_px, pred_list_px)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall_px, precision_px, label=f'Pixel-Level PR Curve (AUC = {auc(recall_px, precision_px):.4f})', linewidth=2)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Pixel-Level Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "# ==================== 4. Image-Level ROC Curve ====================\n",
        "fpr_img, tpr_img, _ = roc_curve(gt_list_sp, pred_list_sp)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_img, tpr_img, label=f'Image-Level ROC (AUC = {roc_auc_score(gt_list_sp, pred_list_sp):.4f})', linewidth=2)\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Random classifier line\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Image-Level ROC Curve')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "# ==================== 5. Image-Level Precision-Recall Curve ====================\n",
        "precision_img, recall_img, _ = precision_recall_curve(gt_list_sp, pred_list_sp)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall_img, precision_img, label=f'Image-Level PR Curve (AUC = {auc(recall_img, precision_img):.4f})', linewidth=2)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Image-Level Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.5)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTgW2j4yotFS"
      },
      "source": [
        "# Applying Draem Paper Model Architecture to Severstal Steel Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlxRI3U0Rk_7",
        "outputId": "8b747db1-cd54-4307-945b-a6a7d07d0201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting kornia\n",
            "  Downloading kornia-0.8.0-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.14.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Collecting kornia_rs>=0.1.0 (from kornia)\n",
            "  Downloading kornia_rs-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.8.0-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, kornia_rs, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, kornia\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed kornia-0.8.0 kornia_rs-0.1.8 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "/content/Severstal_Steel_DRAEM_implementation\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required packages\n",
        "!pip install torch torchvision scikit-image scikit-learn matplotlib opencv-python kornia tqdm\n",
        "\n",
        "# Create project directory\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Set up project directory - modify this path to match your Drive structure\n",
        "PROJECT_DIR = '/content/Severstal_Steel_DRAEM_implementation'\n",
        "!mkdir -p {PROJECT_DIR}\n",
        "%cd {PROJECT_DIR}\n",
        "\n",
        "# Create directory structure\n",
        "!mkdir -p checkpoints/Severstal\n",
        "!mkdir -p visualizations/Severstal\n",
        "\n",
        "# Add current directory to path\n",
        "sys.path.append(PROJECT_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gikgeru1Rnr0",
        "outputId": "7aa31ae5-cc3d-4ff8-e7be-5f23a56b49ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DiscriminativeSubNetwork(nn.Module):\n",
        "    def __init__(self, in_channels=6, out_channels=4):\n",
        "        super(DiscriminativeSubNetwork, self).__init__()\n",
        "        # Encoder (downsampling)\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, 4, stride=2, padding=1, bias=False)  # 128x128\n",
        "        self.conv2 = nn.Conv2d(64, 128, 4, stride=2, padding=1, bias=False)         # 64x64\n",
        "        self.conv3 = nn.Conv2d(128, 256, 4, stride=2, padding=1, bias=False)        # 32x32\n",
        "        self.conv4 = nn.Conv2d(256, 512, 4, stride=2, padding=1, bias=False)        # 16x16\n",
        "\n",
        "        # Decoder (upsampling)\n",
        "        self.upconv1 = nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1, bias=False)  # 32x32\n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1, bias=False)  # 64x64\n",
        "        self.upconv3 = nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1, bias=False)   # 128x128\n",
        "        self.upconv4 = nn.ConvTranspose2d(64, out_channels, 4, stride=2, padding=1, bias=False,output_padding=0)  # 256x256\n",
        "\n",
        "        # Batch normalization\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(256)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(256)\n",
        "        self.batchnorm6 = nn.BatchNorm2d(128)\n",
        "        self.batchnorm7 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.ReLU = nn.ReLU(True)\n",
        "        self.Dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder path with dropout\n",
        "        x1 = self.ReLU(self.batchnorm1(self.conv1(x)))\n",
        "        x1 = self.Dropout(x1)\n",
        "        x2 = self.ReLU(self.batchnorm2(self.conv2(x1)))\n",
        "        x2 = self.Dropout(x2)\n",
        "        x3 = self.ReLU(self.batchnorm3(self.conv3(x2)))\n",
        "        x3 = self.Dropout(x3)\n",
        "        x4 = self.ReLU(self.batchnorm4(self.conv4(x3)))\n",
        "        x4 = self.Dropout(x4)\n",
        "\n",
        "        # Decoder path with skip connections\n",
        "        x = self.ReLU(self.batchnorm5(self.upconv1(x4)))\n",
        "        x = x + x3  # Skip connection\n",
        "        x = self.ReLU(self.batchnorm6(self.upconv2(x)))\n",
        "        x = x + x2  # Skip connection\n",
        "        x = self.ReLU(self.batchnorm7(self.upconv3(x)))\n",
        "        x = x + x1  # Skip connection\n",
        "        x = self.upconv4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class ReconstructiveSubNetwork(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, base_width=128):\n",
        "        super(ReconstructiveSubNetwork, self).__init__()\n",
        "        self.encoder = EncoderBlock(in_channels, base_width)\n",
        "        self.decoder = DecoderBlock(base_width, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b5 = self.encoder(x)\n",
        "        output = self.decoder(b5)\n",
        "\n",
        "        return output\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.deconv1 = nn.ConvTranspose2d(in_channels, in_channels//2, 4, stride=2, padding=1, bias=False)\n",
        "        self.deconv2 = nn.ConvTranspose2d(in_channels//2, in_channels//4, 4, stride=2, padding=1, bias=False)\n",
        "        self.deconv3 = nn.ConvTranspose2d(in_channels//4, in_channels//8, 4, stride=2, padding=1, bias=False)\n",
        "        self.deconv4 = nn.ConvTranspose2d(in_channels//8, in_channels//16, 4, stride=2, padding=1, bias=False)\n",
        "        self.deconv5 = nn.ConvTranspose2d(in_channels//16, out_channels, 4, stride=2, padding=1, bias=False)\n",
        "\n",
        "        self.batchnorm1 = nn.BatchNorm2d(in_channels//2)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(in_channels//4)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(in_channels//8)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(in_channels//16)\n",
        "\n",
        "        self.ReLU = nn.ReLU(True)\n",
        "        self.Sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ReLU(self.batchnorm1(self.deconv1(x)))\n",
        "        x = self.ReLU(self.batchnorm2(self.deconv2(x)))\n",
        "        x = self.ReLU(self.batchnorm3(self.deconv3(x)))\n",
        "        x = self.ReLU(self.batchnorm4(self.deconv4(x)))\n",
        "\n",
        "        x = self.Sigmoid(self.deconv5(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels//16, 4, stride=2, padding=1, bias=False)\n",
        "        self.conv2 = nn.Conv2d(out_channels//16, out_channels//8, 4, stride=2, padding=1, bias=False)\n",
        "        self.conv3 = nn.Conv2d(out_channels//8, out_channels//4, 4, stride=2, padding=1, bias=False)\n",
        "        self.conv4 = nn.Conv2d(out_channels//4, out_channels//2, 4, stride=2, padding=1, bias=False)\n",
        "        self.conv5 = nn.Conv2d(out_channels//2, out_channels, 4, stride=2, padding=1, bias=False)\n",
        "\n",
        "        self.batchnorm1 = nn.BatchNorm2d(out_channels//16)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(out_channels//8)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(out_channels//4)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(out_channels//2)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.ReLU = nn.ReLU(True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ReLU(self.batchnorm1(self.conv1(x)))\n",
        "        x = self.ReLU(self.batchnorm2(self.conv2(x)))\n",
        "        x = self.ReLU(self.batchnorm3(self.conv3(x)))\n",
        "        x = self.ReLU(self.batchnorm4(self.conv4(x)))\n",
        "        x = self.ReLU(self.batchnorm5(self.conv5(x)))\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0EYpmHyRqEO",
        "outputId": "1269f772-14a8-43fd-a8c2-d0470d21cf37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing draem_model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile draem_model.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from model import ReconstructiveSubNetwork, DiscriminativeSubNetwork\n",
        "\n",
        "class DRAEM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DRAEM, self).__init__()\n",
        "        self.reconstructive_subnetwork = ReconstructiveSubNetwork()\n",
        "        self.discriminative_subnetwork = DiscriminativeSubNetwork(in_channels=6)\n",
        "\n",
        "    def forward(self, *args, mode=\"train\"):\n",
        "      with torch.amp.autocast(device_type='cuda'):\n",
        "          if mode == \"train\":\n",
        "              # Unpack all 3 required tensors for training\n",
        "              perturbed, original, mask = args\n",
        "              reconstructed = self.reconstructive_subnetwork(perturbed)\n",
        "              combined = torch.cat([reconstructed, original], dim=1)\n",
        "              output = self.discriminative_subnetwork(combined)\n",
        "              return reconstructed, output\n",
        "\n",
        "          elif mode == \"test\":\n",
        "              # Single input for validation/testing\n",
        "              x = args[0]\n",
        "              reconstructed = self.reconstructive_subnetwork(x)\n",
        "              output = self.discriminative_subnetwork(torch.cat([x, reconstructed], dim=1))\n",
        "              return reconstructed, output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQtQzqJqRsu9",
        "outputId": "ced2a7ff-e2b5-4a24-9210-b90d49273064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataset.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile dataset.py\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import glob\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "def get_data_transforms(size, isize):\n",
        "    image_transform = transforms.Compose([\n",
        "        transforms.Resize((size, size)),\n",
        "        transforms.RandomApply([\n",
        "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
        "            transforms.GaussianBlur(3, sigma=(0.1, 2.0)),  # Added\n",
        "            transforms.RandomAdjustSharpness(2)  # Added\n",
        "        ], p=0.5),\n",
        "        transforms.RandomAffine(degrees=15, translate=(0.2, 0.2), scale=(0.8, 1.2)),  # Modified\n",
        "        transforms.ToTensor(),\n",
        "        transforms.RandomErasing(p=0.3, scale=(0.02, 0.25), ratio=(0.3, 3.3)),  # Modified\n",
        "    ])\n",
        "\n",
        "    mask_transform = transforms.Compose([\n",
        "        transforms.Resize((size, size), interpolation=InterpolationMode.NEAREST),\n",
        "    ])\n",
        "    return image_transform, mask_transform\n",
        "\n",
        "class SeverstalDataset(Dataset):\n",
        "    def __init__(self, root_dir, csv_file, image_transform=None, mask_transform=None,\n",
        "                 phase='train', subset_size=None, split_ratio=0.8, random_state=42,\n",
        "                 oversampling=True,img_size=192):  # Added oversampling parameter\n",
        "        self.root_dir = root_dir\n",
        "        self.img_size = img_size\n",
        "        self.image_transform = image_transform\n",
        "        self.mask_transform = mask_transform\n",
        "        self.phase = phase\n",
        "        self.oversampling = oversampling\n",
        "\n",
        "        df = pd.read_csv(os.path.join(root_dir, csv_file))\n",
        "        # Calculate class weights\n",
        "        raw_class_counts = df['ClassId'].value_counts().sort_index()\n",
        "        total_samples = len(df)\n",
        "        self.class_weights = total_samples / (raw_class_counts + 1e-7)\n",
        "        print(f\"True Class Weights: {self.class_weights.to_dict()}\")\n",
        "\n",
        "        # Build image-defect mapping\n",
        "        self.image_defect_map = df.groupby('ImageId')['ClassId'].apply(set).to_dict()\n",
        "\n",
        "        # Stratified split\n",
        "        unique_images = df['ImageId'].unique()\n",
        "        train_ids, val_ids = train_test_split(\n",
        "            unique_images,\n",
        "            test_size=1-split_ratio,\n",
        "            stratify=df.groupby('ImageId')['ClassId'].first(),\n",
        "            random_state=random_state\n",
        "        )\n",
        "\n",
        "        self.img_ids = train_ids if phase == 'train' else val_ids\n",
        "\n",
        "        # Oversampling logic for training\n",
        "        if subset_size and phase == 'train' and self.oversampling:\n",
        "            # Prioritize rare defects (1,3,4)\n",
        "            rare_defect_imgs = [\n",
        "                img_id for img_id in self.img_ids\n",
        "                if any(d in {1,3,4} for d in self.image_defect_map.get(img_id, set()))\n",
        "            ]\n",
        "\n",
        "            # Sample 60% rare defects\n",
        "            rare_size = int(subset_size * 0.6)\n",
        "            if len(rare_defect_imgs) > 0:\n",
        "                rare_samples = np.random.choice(\n",
        "                    rare_defect_imgs,\n",
        "                    size=min(len(rare_defect_imgs), rare_size),\n",
        "                    replace=False\n",
        "                )\n",
        "                remaining = subset_size - len(rare_samples)\n",
        "            else:\n",
        "                rare_samples = []\n",
        "                remaining = subset_size\n",
        "\n",
        "            # Sample remaining from all\n",
        "            regular_samples = np.random.choice(\n",
        "                [img_id for img_id in self.img_ids if img_id not in rare_samples],\n",
        "                size=remaining,\n",
        "                replace=False\n",
        "            )\n",
        "\n",
        "            self.img_ids = list(rare_samples) + list(regular_samples)\n",
        "            np.random.shuffle(self.img_ids)\n",
        "        elif subset_size:\n",
        "            self.img_ids = self.img_ids[:subset_size]\n",
        "\n",
        "        self.df = df[df['ImageId'].isin(self.img_ids)]\n",
        "        print(f\"Class distribution:\\n{self.df['ClassId'].value_counts()}\")\n",
        "        self.img_paths = [os.path.join(root_dir, 'train', img_id) for img_id in self.img_ids]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    @staticmethod\n",
        "    def collate_fn(batch):\n",
        "        images, masks, ids = zip(*batch)\n",
        "        return torch.stack(images), torch.stack(masks), ids\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.df.iloc[idx]['ImageId']\n",
        "        img_path = os.path.join(self.root_dir, \"train\", img_id)  # Corrected path\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        mask = torch.zeros((4, self.img_size, self.img_size), dtype=torch.float32)\n",
        "\n",
        "        defect_rows = self.df[self.df['ImageId'] == img_id]\n",
        "\n",
        "        for _, row in defect_rows.iterrows():\n",
        "            class_id = int(row['ClassId']) - 1  # Now correctly parsed\n",
        "            if pd.notna(row['EncodedPixels']):\n",
        "                mask_img = self.rle2mask(row['EncodedPixels'], (self.img_size, self.img_size))\n",
        "                mask[class_id] = mask_img\n",
        "\n",
        "        # Debug print\n",
        "        print(f\"Image: {img_id} | Classes present: {torch.unique(torch.argmax(mask, dim=0))}\")\n",
        "\n",
        "        if self.image_transform:\n",
        "            image = self.image_transform(image)\n",
        "        if self.mask_transform:\n",
        "            mask = self.mask_transform(mask)\n",
        "\n",
        "        return image, mask, img_id\n",
        "\n",
        "    def rle2mask(self, rle, shape):\n",
        "        mask = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
        "        if pd.isna(rle):  # Handle potential NaN values\n",
        "            return torch.zeros(shape, dtype=torch.float32)\n",
        "\n",
        "        array = np.asarray([int(x) for x in str(rle).split()])\n",
        "        starts, lengths = array[0::2], array[1::2]\n",
        "\n",
        "        for start, length in zip(starts, lengths):\n",
        "            mask[start:start+length] = 1\n",
        "        return torch.from_numpy(mask.reshape(shape, order='F')).float()\n",
        "\n",
        "class CutPasteDataset(Dataset):\n",
        "    def __init__(self, root, transform, perturbed_transform, phase, args):\n",
        "        self.img_path = os.path.join(root, 'train')\n",
        "        self.transform = transform\n",
        "        self.perturbed_transform = perturbed_transform\n",
        "        self.img_paths = sorted(glob.glob(os.path.join(self.img_path, \"*.jpg\")))\n",
        "        self.img_paths += sorted(glob.glob(os.path.join(self.img_path, \"*.png\")))\n",
        "        self.args = args\n",
        "\n",
        "        # Anomaly source handling\n",
        "        self.anomaly_source_paths = []\n",
        "        if os.path.exists(args.anomaly_source_path):\n",
        "            self.anomaly_source_paths = [\n",
        "                os.path.join(args.anomaly_source_path, f)\n",
        "                for f in os.listdir(args.anomaly_source_path)\n",
        "                if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "            ]\n",
        "\n",
        "        if not self.anomaly_source_paths:\n",
        "            self.create_synthetic_textures(args.anomaly_source_path)\n",
        "            self.anomaly_source_paths = [\n",
        "                os.path.join(args.anomaly_source_path, f)\n",
        "                for f in os.listdir(args.anomaly_source_path)\n",
        "                if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "            ]\n",
        "\n",
        "        self.resize_transform = transforms.Resize((args.img_size, args.img_size))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        idx = idx % len(self.img_paths)\n",
        "        img_path = self.img_paths[idx]\n",
        "\n",
        "        # Load base image\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "\n",
        "        # Generate anomaly\n",
        "        anomaly_img, mask = self.generate_anomaly(img)\n",
        "        return img, anomaly_img, mask, img_path\n",
        "\n",
        "    def get_anomaly_source(self, mask_h, mask_w):\n",
        "        source_path = np.random.choice(self.anomaly_source_paths)\n",
        "        source = Image.open(source_path).convert('RGB')\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((mask_h*2, mask_w*2)),  # Oversample\n",
        "            transforms.RandomAffine(degrees=15, shear=10),\n",
        "            transforms.RandomPerspective(distortion_scale=0.3),\n",
        "            transforms.CenterCrop((mask_h, mask_w)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        return transform(source)\n",
        "    def generate_anomaly(self, img):\n",
        "        anomaly_img = img.clone()\n",
        "        h, w = img.shape[1], img.shape[2]\n",
        "\n",
        "        # Realistic defect type distribution\n",
        "        defect_probs = [0.20, 0.05, 0.65, 0.10]  # Matches Severstal class frequencies\n",
        "        defect_type = np.random.choice([1,2,3,4], p=defect_probs)\n",
        "\n",
        "        # Defect-specific sizing with random aspect ratios\n",
        "        if defect_type in [2,3]:\n",
        "            base_size = random.randint(2,15)\n",
        "            mask_h = int(base_size * np.random.uniform(0.8, 1.2))  # 1.6-18px\n",
        "            mask_w = int(base_size * np.random.uniform(0.8, 1.2))\n",
        "        else:\n",
        "            base_size = random.randint(20,50)\n",
        "            mask_h = int(base_size * np.random.uniform(0.7, 1.3))  # 14-65px\n",
        "            mask_w = int(base_size * np.random.uniform(0.7, 1.3))\n",
        "\n",
        "        # Allow border defects (remove -1)\n",
        "        y = np.random.randint(0, h - mask_h)\n",
        "        x = np.random.randint(0, w - mask_w)\n",
        "\n",
        "        # Enhanced anomaly source\n",
        "        anomaly_source = self.get_anomaly_source(mask_h, mask_w)\n",
        "\n",
        "        # Apply with random rotation/affine\n",
        "        angle = random.uniform(-45,45)\n",
        "        anomaly_source = TF.rotate(anomaly_source, angle)\n",
        "\n",
        "        anomaly_img[:, y:y+mask_h, x:x+mask_w] = anomaly_source\n",
        "        mask = torch.zeros((1, h, w))\n",
        "        mask[:, y:y+mask_h, x:x+mask_w] = 1\n",
        "\n",
        "        return anomaly_img, mask\n",
        "\n",
        "    def create_synthetic_textures(self, output_path):\n",
        "        os.makedirs(output_path, exist_ok=True)\n",
        "        for i in range(20):\n",
        "            # Create random texture patterns\n",
        "            texture = np.random.randint(0, 256, (256,256,3), dtype=np.uint8)\n",
        "            cv2.imwrite(os.path.join(output_path, f\"synth_{i}.jpg\"), texture)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esl9Uwe3SMnI",
        "outputId": "a7a2e45e-7984-466f-c6cb-913b6dd9500e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train_DRAEM.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile train_DRAEM.py\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "from dataset import SeverstalDataset, get_data_transforms\n",
        "from draem_model import DRAEM\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "class FocalLoss(torch.nn.Module):\n",
        "    def __init__(self, gamma=2.0, alpha=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha  # Should be tensor of shape [4]\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # inputs: (N,4,H,W), targets: (N,4,H,W)\n",
        "        BCE_loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
        "            inputs, targets, reduction='none', pos_weight=self.alpha.view(1,-1,1,1)\n",
        "        )\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = (1 - pt)**self.gamma * BCE_loss\n",
        "        return F_loss.mean()\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='DRAEM Training')\n",
        "    parser.add_argument('--obj_name', default='severstal', type=str)\n",
        "    parser.add_argument('--checkpoint_path', default='checkpoints/severstal/model_best.pth', type=str)\n",
        "    parser.add_argument('--data_path', required=True, type=str)\n",
        "    parser.add_argument('--epochs', default=10, type=int)\n",
        "    parser.add_argument('--lr', default=5e-4, type=float)\n",
        "    parser.add_argument('--grad_accum', default=4, type=int)\n",
        "    parser.add_argument('--img_size', default=256, type=int)\n",
        "    parser.add_argument('--bs', default=16, type=int)\n",
        "    parser.add_argument('--seed', default=111, type=int)\n",
        "    parser.add_argument('--subset_size', default=4000, type=int)\n",
        "    parser.add_argument('--oversampling', action='store_true', help='Enable class-balanced oversampling')\n",
        "    parser.add_argument('--focal_gamma', type=float, default=2.0)\n",
        "    parser.add_argument('--l1_weight', type=float, default=0.5)\n",
        "    parser.add_argument('--grad_clip', type=float, default=1.0)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    setup_seed(args.seed)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(f\"\\n=== CUDA Status ===\")\n",
        "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "    print(f\"Device: {device}\")\n",
        "\n",
        "    image_transform, mask_transform = get_data_transforms(args.img_size, args.img_size)\n",
        "\n",
        "    train_dataset = SeverstalDataset(\n",
        "        root_dir=args.data_path,\n",
        "        csv_file='train.csv',\n",
        "        image_transform=image_transform,\n",
        "        mask_transform=mask_transform,\n",
        "        phase='train',\n",
        "        subset_size=args.subset_size,\n",
        "        split_ratio=0.8,\n",
        "        random_state=args.seed,\n",
        "        oversampling=args.oversampling,\n",
        "        img_size=args.img_size\n",
        "    )\n",
        "\n",
        "    val_dataset = SeverstalDataset(\n",
        "        root_dir=args.data_path,\n",
        "        csv_file='train.csv',\n",
        "        image_transform=image_transform,\n",
        "        mask_transform=mask_transform,\n",
        "        phase='val',\n",
        "        subset_size=None,\n",
        "        split_ratio=0.8,\n",
        "        random_state=args.seed,\n",
        "        img_size=args.img_size\n",
        "    )\n",
        "\n",
        "    class_weights = torch.tensor(train_dataset.class_weights.values,\n",
        "                               dtype=torch.float32).to(device)\n",
        "    print(f\"Using class weights: {class_weights.cpu().numpy()}\")\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=args.bs, shuffle=True,collate_fn=SeverstalDataset.collate_fn,num_workers=2, pin_memory=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=args.bs, shuffle=False, collate_fn=SeverstalDataset.collate_fn,num_workers=2, pin_memory=True)\n",
        "\n",
        "    print(f\"\\nTraining samples: {len(train_dataset)}\")\n",
        "    print(f\"Validation samples: {len(val_dataset)}\")\n",
        "\n",
        "    model = DRAEM().to(device)\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
        "\n",
        "    def warmup_cosine_schedule(epoch, warmup_epochs=2, total_epochs=args.epochs):\n",
        "        if total_epochs <= warmup_epochs:\n",
        "            return min(epoch/warmup_epochs, 1.0)\n",
        "        return 0.5*(1 + np.cos(np.pi*(epoch - warmup_epochs)/(total_epochs - warmup_epochs)))\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "        optimizer, lr_lambda=lambda epoch: warmup_cosine_schedule(epoch)\n",
        "    )\n",
        "\n",
        "    focal_loss = FocalLoss(gamma=2.0, alpha=class_weights)\n",
        "    best_f1 = 0\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{args.epochs}\")\n",
        "        total_batches = len(train_dataloader)\n",
        "\n",
        "        for batch_idx, batch in enumerate(pbar):\n",
        "            original_img, mask, _ = batch\n",
        "            original_img = original_img.to(device, non_blocking=True)\n",
        "            mask = mask.to(device, non_blocking=True)\n",
        "\n",
        "            # Add debug prints in training loop\n",
        "            print(f\"Mask stats - Min: {mask.min()}, Max: {mask.max()}, Mean: {mask.float().mean().item()}\")\n",
        "            print(f\"Training Batch {batch_idx+1} - Positive pixels per class: {mask.float().sum(dim=[0,2,3]).cpu().numpy()}\")\n",
        "\n",
        "            mask_combined = mask.sum(dim=1, keepdim=True).float().clamp(0, 1)\n",
        "            noise = torch.randn_like(original_img) * mask_combined\n",
        "            perturbed_img = original_img * (1 - mask_combined) + noise\n",
        "            perturbed_img = torch.clamp(perturbed_img, 0, 1)\n",
        "\n",
        "            with torch.amp.autocast(device_type='cuda'):\n",
        "                reconstructed, output = model(perturbed_img, original_img, mask, mode=\"train\")\n",
        "\n",
        "                print(f\"Output stats - Min: {output.min().item()}, Max: {output.max().item()}\")\n",
        "\n",
        "                l1_loss = torch.mean(torch.abs(reconstructed - original_img))\n",
        "                segment_loss = focal_loss(output, mask.float())\n",
        "                loss = l1_loss + segment_loss\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            if (batch_idx + 1) % args.grad_accum == 0 or (batch_idx + 1) == total_batches:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            pbar.set_postfix({\"Loss\": loss.item()})\n",
        "\n",
        "        # Validation with class-aware metrics\n",
        "        optimizer.zero_grad(set_to_none=True)  # Clear any remaining gradients\n",
        "        torch.cuda.empty_cache()\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_targets = []\n",
        "        val_loss = 0\n",
        "\n",
        "        with torch.no_grad(), torch.amp.autocast(device_type='cuda'):\n",
        "            print(\"\\n=== Validation Phase ===\")\n",
        "            val_pbar = tqdm(val_dataloader, desc=f\"Validating Epoch {epoch+1}\")\n",
        "            for val_batch in val_pbar:\n",
        "                val_img, val_mask, _ = val_batch\n",
        "                print(f\"Validation Batch - Image shape: {val_img.shape}, Mask shape: {val_mask.shape}\")\n",
        "                print(f\"Validation Batch - Positive pixels per class: {val_mask.float().sum(dim=[0,2,3]).cpu().numpy()}\")\n",
        "                if val_img.device != device:\n",
        "                    print(f\"Correcting device mismatch: {val_img.device} -> {device}\")\n",
        "                    val_img = val_img.to(device, non_blocking=True)\n",
        "                    val_mask = val_mask.to(device, non_blocking=True)\n",
        "\n",
        "                if torch.isnan(val_img).any():\n",
        "                    print(\"NaN detected in validation images!\")\n",
        "                if torch.isnan(val_mask).any():\n",
        "                    print(\"NaN detected in validation masks!\")\n",
        "\n",
        "                val_reconstructed, val_output = model(val_img, mode=\"test\")\n",
        "\n",
        "                # Calculate losses\n",
        "                l1_val_loss = torch.mean(torch.abs(val_reconstructed - val_img))\n",
        "                segment_val_loss = focal_loss(val_output, val_mask.float())\n",
        "                val_loss += (l1_val_loss + segment_val_loss).item()\n",
        "\n",
        "                # Move to CPU immediately and convert\n",
        "                preds = torch.sigmoid(val_output).cpu().float()\n",
        "                targets = val_mask.cpu().float()\n",
        "                all_preds.append(preds)\n",
        "                all_targets.append(targets)\n",
        "\n",
        "        # Calculate F1 scores\n",
        "        all_preds = torch.cat(all_preds)\n",
        "        all_targets = torch.cat(all_targets)\n",
        "\n",
        "        # Release GPU memory before metrics\n",
        "        del val_reconstructed, val_output, val_img, val_mask\n",
        "        torch.cuda.synchronize()  # Wait for CUDA ops to finish\n",
        "        torch.cuda.empty_cache()\n",
        "        print(f\"GPU Memory After: {torch.cuda.memory_allocated()/1e9:.2f}GB\")\n",
        "\n",
        "        f1_scores = []\n",
        "        for c in range(4):\n",
        "            preds_class = (all_preds[:,c] > 0.1).float()\n",
        "            targets_class = all_targets[:,c].float()\n",
        "            f1 = f1_score(targets_class.numpy().flatten(),\n",
        "                        preds_class.numpy().flatten(),\n",
        "                        zero_division=0)\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "        avg_f1 = np.mean(f1_scores)\n",
        "        print(f\"\\nValidation F1 Scores:\")\n",
        "        print(f\"Class 1: {f1_scores[0]:.4f} | Class 2: {f1_scores[1]:.4f}\")\n",
        "        print(f\"Class 3: {f1_scores[2]:.4f} | Class 4: {f1_scores[3]:.4f}\")\n",
        "        print(f\"Macro Avg F1: {avg_f1:.4f}\")\n",
        "\n",
        "        # Save best model based on F1\n",
        "        if avg_f1 > best_f1:\n",
        "            torch.save(model.state_dict(), args.checkpoint_path)\n",
        "            best_f1 = avg_f1\n",
        "            print(f\"New best model saved with F1: {avg_f1:.4f}\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pDbjsOsTojS",
        "outputId": "8f0aff3a-8dae-423d-bd6b-fe46fc2de5ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_DRAEM.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile test_DRAEM.py\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,Subset\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "from dataset import SeverstalDataset, get_data_transforms\n",
        "from draem_model import DRAEM\n",
        "import cv2\n",
        "import psutil\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description='DRAEM Multi-Class Testing with Visualization')\n",
        "    parser.add_argument('--obj_name', type=str, default='severstal',\n",
        "                        help='Object category name')\n",
        "    parser.add_argument('--data_path', type=str, required=True,\n",
        "                        help='Path to dataset directory containing train.csv and images')\n",
        "    parser.add_argument('--checkpoint_path', type=str,\n",
        "                        default='checkpoints/severstal/model_best.pth',\n",
        "                        help='Path to the trained model checkpoint')\n",
        "    parser.add_argument('--test_samples', type=int, default=0,\n",
        "                       help='Number of test samples (0=use all)')\n",
        "    parser.add_argument('--save_path', type=str,\n",
        "                        default='visualizations/severstal',\n",
        "                        help='Directory to save output visualizations')\n",
        "    parser.add_argument('--img_size', type=int, default=128,\n",
        "                        help='Input image size for the model')\n",
        "    return parser.parse_args()\n",
        "\n",
        "def validate_paths(args):\n",
        "    if not os.path.exists(args.data_path):\n",
        "        raise FileNotFoundError(f\"Data path not found: {args.data_path}\")\n",
        "\n",
        "    train_csv = os.path.join(args.data_path, 'train.csv')\n",
        "    if not os.path.exists(train_csv):\n",
        "        raise FileNotFoundError(f\"train.csv missing in {args.data_path}\")\n",
        "\n",
        "    if not os.path.isfile(args.checkpoint_path):\n",
        "        raise FileNotFoundError(f\"Checkpoint file not found: {args.checkpoint_path}\")\n",
        "\n",
        "    return args.checkpoint_path\n",
        "\n",
        "def optimize_thresholds(outputs, masks, num_classes=4):\n",
        "    # Resize outputs to match mask dimensions\n",
        "    outputs_resized = torch.nn.functional.interpolate(\n",
        "        outputs,\n",
        "        size=masks.shape[-2:],\n",
        "        mode='nearest'\n",
        "    )\n",
        "\n",
        "    outputs_np = outputs_resized.cpu().numpy()\n",
        "    masks_np = masks.cpu().numpy()\n",
        "\n",
        "    best_thresholds = []\n",
        "    for c in range(num_classes):\n",
        "        if np.sum(masks_np[:,c]) == 0:\n",
        "            best_thresholds.append(0.5)\n",
        "            continue\n",
        "\n",
        "        # Ensure equal length\n",
        "        y_true = masks_np[:,c].flatten()\n",
        "        y_score = outputs_np[:,c].flatten()\n",
        "\n",
        "        precisions, recalls, thresholds = precision_recall_curve(y_true, y_score)\n",
        "\n",
        "        f1_scores = 2 * precisions * recalls / (precisions + recalls + 1e-7)\n",
        "        best_idx = np.nanargmax(f1_scores)\n",
        "        best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else 0.5\n",
        "        best_thresholds.append(float(best_threshold))\n",
        "\n",
        "    return best_thresholds\n",
        "\n",
        "def visualize_results(image, anomaly_map, pred_classes, save_dir, base_name):\n",
        "    try:\n",
        "        if isinstance(anomaly_map, torch.Tensor):\n",
        "            anomaly_map = anomaly_map.cpu().numpy()\n",
        "\n",
        "        if anomaly_map.ndim > 2:\n",
        "            anomaly_map = anomaly_map.squeeze()\n",
        "\n",
        "        eps = 1e-7\n",
        "        anomaly_map = anomaly_map.astype(np.float32) + eps\n",
        "\n",
        "        anomaly_norm = np.zeros_like(anomaly_map, dtype=np.uint8)\n",
        "        cv2.normalize(anomaly_map, anomaly_norm, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "        heatmap = cv2.applyColorMap(anomaly_norm, cv2.COLORMAP_JET)\n",
        "        blended = cv2.addWeighted(image, 0.7, heatmap, 0.3, 0)\n",
        "\n",
        "        cv2.imwrite(os.path.join(save_dir, f\"{base_name}_original.png\"),\n",
        "                    cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
        "        cv2.imwrite(os.path.join(save_dir, f\"{base_name}_anomaly.png\"), anomaly_norm)\n",
        "        cv2.imwrite(os.path.join(save_dir, f\"{base_name}_heatmap.png\"), blended)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping visualization for {base_name}: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "    checkpoint_path = validate_paths(args)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    data_transform, _ = get_data_transforms(args.img_size, args.img_size)\n",
        "\n",
        "    # Modified line: Add subset_size parameter\n",
        "    full_dataset = SeverstalDataset(\n",
        "        args.data_path,\n",
        "        'train.csv',\n",
        "        data_transform,\n",
        "        phase='val',\n",
        "        split_ratio=0.8,\n",
        "        # subset_size=args.test_samples if args.test_samples > 0 else None,\n",
        "        subset_size = None,\n",
        "        random_state=42,\n",
        "    )\n",
        "    if args.test_samples > 0:\n",
        "        test_dataset = Subset(full_dataset, indices=range(min(args.test_samples, len(full_dataset))))\n",
        "    else:\n",
        "        test_dataset = full_dataset\n",
        "\n",
        "    print(f\"Loaded {len(test_dataset)} validation samples.\")\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=4,  # Reduced batch size for memory\n",
        "        shuffle=False,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    model = DRAEM().to(device)\n",
        "    print(\"\\nLoading checkpoint...\")\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint)\n",
        "    model.eval()\n",
        "\n",
        "    print(\"\\n=== Calculating Optimal Thresholds ===\")\n",
        "    threshold_outputs = []\n",
        "    threshold_masks = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_dataloader, desc=\"Threshold Optimization\"):\n",
        "            images, masks, _ = batch\n",
        "            images = images.to(device)\n",
        "            _, output = model(images, mode=\"test\")\n",
        "            threshold_outputs.append(output.cpu())\n",
        "            threshold_masks.append(masks.cpu())\n",
        "\n",
        "    threshold_outputs = torch.cat(threshold_outputs)\n",
        "    threshold_masks = torch.cat(threshold_masks)\n",
        "    class_thresholds = optimize_thresholds(threshold_outputs, threshold_masks)\n",
        "    print(f\"Optimal Class Thresholds: {class_thresholds}\")\n",
        "\n",
        "    pred_classes_list = []\n",
        "    true_classes_list = []\n",
        "\n",
        "    print(\"\\nRunning inference...\")\n",
        "    with torch.no_grad():\n",
        "        batch_counter = 0\n",
        "        for batch in tqdm(test_dataloader, desc=\"Processing batches\"):\n",
        "            images, masks, paths = batch\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            _, output = model(images, mode=\"test\")\n",
        "\n",
        "            batch_preds = torch.zeros_like(output)\n",
        "            for c in range(4):\n",
        "                batch_preds[:,c] = (torch.sigmoid(output[:,c]) > class_thresholds[c]).float()\n",
        "\n",
        "            pred_classes = batch_preds.any(dim=2).any(dim=2).cpu().numpy().astype(int)\n",
        "            true_classes = (masks > 0.5).any(dim=3).any(dim=2).cpu().numpy().astype(int)\n",
        "\n",
        "            pred_classes_list.extend(pred_classes.flatten())\n",
        "            true_classes_list.extend(true_classes.flatten())\n",
        "\n",
        "            if batch_counter % 10 == 0:\n",
        "                images_np = images.cpu().numpy().transpose(0, 2, 3, 1) * 255\n",
        "                output_np = output.cpu().numpy()\n",
        "                for i in range(images_np.shape[0]):\n",
        "                    base_name = os.path.basename(paths[i])\n",
        "                    visualize_results(\n",
        "                        image=images_np[i].astype(np.uint8),\n",
        "                        anomaly_map=output_np[i].max(axis=0),\n",
        "                        pred_classes=pred_classes[i],\n",
        "                        save_dir=args.save_path,\n",
        "                        base_name=base_name.split('.')[0]\n",
        "                    )\n",
        "                del images_np, output_np\n",
        "\n",
        "            del images, masks, output\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n",
        "            batch_counter += 1\n",
        "\n",
        "    print(\"\\n=== Evaluation Metrics ===\")\n",
        "    print(classification_report(\n",
        "        true_classes_list,\n",
        "        pred_classes_list,\n",
        "        labels=[0,1,2,3],\n",
        "        target_names=['defect_1', 'defect_2', 'defect_3', 'defect_4'],\n",
        "        zero_division=0\n",
        "    ))\n",
        "    print(\"Balanced Accuracy:\", balanced_accuracy_score(true_classes_list, pred_classes_list))\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        main()\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError during testing: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6Em_vT1SPyF",
        "outputId": "9c4502b6-fd36-42d4-dde1-690734848008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing run_reproduction.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile run_reproduction.py\n",
        "import argparse\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def run_command(command):\n",
        "    print(f\"Running: {command}\")\n",
        "    process = subprocess.run(command, shell=True)\n",
        "    return process.returncode == 0\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='DRAEM Steel Defect Detection Reproduction')\n",
        "    parser.add_argument('--obj_name', default='severstal', type=str)\n",
        "    parser.add_argument('--severstal_path', required=True, type=str)\n",
        "    parser.add_argument('--epochs', default=10, type=int)\n",
        "    parser.add_argument('--bs', default=8, type=int)\n",
        "    parser.add_argument('--lr', default=1e-4, type=float)\n",
        "    parser.add_argument('--img_size', default=128, type=int)\n",
        "    parser.add_argument('--subset_size', default=5000, type=int)\n",
        "    parser.add_argument('--seed', default=42, type=int)\n",
        "    parser.add_argument('--grad_accum', default=4, type=int)\n",
        "    parser.add_argument('--focal_gamma', default=2.0, type=float)\n",
        "    parser.add_argument('--l1_weight', default=0.5, type=float)\n",
        "    parser.add_argument('--grad_clip', default=1.0, type=float)\n",
        "    parser.add_argument('--oversampling', action='store_true')\n",
        "    parser.add_argument('--train_only', action='store_true', help='Only run training, skip testing')\n",
        "    parser.add_argument('--test_only', action='store_true', help='Only run testing, skip training')\n",
        "    parser.add_argument('--test_samples', default=0, type=int,\n",
        "                   help='Number of test samples to evaluate (0=all)')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    setup_seed(args.seed)\n",
        "\n",
        "    # Validate mutually exclusive arguments\n",
        "    if args.train_only and args.test_only:\n",
        "        raise ValueError(\"Cannot specify both --train_only and --test_only\")\n",
        "\n",
        "    # Check for GPU availability\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Verify paths\n",
        "    print(\"=== Verifying dataset paths ===\")\n",
        "    if not os.path.exists(args.severstal_path):\n",
        "        raise FileNotFoundError(f\"Severstal dataset path {args.severstal_path} not found!\")\n",
        "\n",
        "    # Only check training data if not in test-only mode\n",
        "    if not args.test_only:\n",
        "        train_csv = os.path.join(args.severstal_path, 'train.csv')\n",
        "        if not os.path.exists(train_csv):\n",
        "            raise FileNotFoundError(f\"Training CSV file {train_csv} not found!\")\n",
        "\n",
        "    # Always check test data\n",
        "    test_folder = os.path.join(args.severstal_path, 'test')\n",
        "    if not os.path.exists(test_folder):\n",
        "        raise FileNotFoundError(f\"Test folder {test_folder} not found!\")\n",
        "\n",
        "    # Print dataset information\n",
        "    if not args.test_only:\n",
        "        train_df = pd.read_csv(os.path.join(args.severstal_path, 'train.csv'))\n",
        "        print(f\"Found {len(train_df)} training samples\")\n",
        "\n",
        "    test_images = [f for f in os.listdir(test_folder) if f.endswith(('.jpg', '.png'))]\n",
        "    print(f\"Found {len(test_images)} test images\")\n",
        "\n",
        "    # Create necessary directories\n",
        "    os.makedirs('checkpoints/severstal', exist_ok=True)\n",
        "    os.makedirs('visualizations/severstal', exist_ok=True)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Training workflow\n",
        "    if not args.test_only:\n",
        "        print(\"\\n=== Training DRAEM model ===\")\n",
        "        train_cmd = (\n",
        "            f\"python train_DRAEM.py \"\n",
        "            f\"--obj_name {args.obj_name} \"\n",
        "            f\"--data_path {args.severstal_path} \"\n",
        "            f\"--epochs {args.epochs} \"\n",
        "            f\"--bs {args.bs} \"\n",
        "            f\"--lr {args.lr} \"\n",
        "            f\"--img_size {args.img_size} \"\n",
        "            f\"--subset_size {args.subset_size} \"\n",
        "            f\"--seed {args.seed} \"\n",
        "            f\"--grad_accum {args.grad_accum} \"\n",
        "            f\"--focal_gamma {args.focal_gamma} \"\n",
        "            f\"--l1_weight {args.l1_weight} \"\n",
        "            f\"--grad_clip {args.grad_clip} \"\n",
        "            f\"{'--oversampling' if args.oversampling else ''}\"\n",
        "        )\n",
        "        if not run_command(train_cmd):\n",
        "            raise RuntimeError(\"Training failed!\")\n",
        "\n",
        "    # Testing workflow\n",
        "    if not args.train_only:\n",
        "        print(\"\\n=== Testing DRAEM model ===\")\n",
        "        checkpoint_path = '/content/Severstal_Steel_DRAEM_implementation/checkpoints/severstal/model_best.pth'\n",
        "        if not os.path.exists(checkpoint_path):\n",
        "            raise FileNotFoundError(f\"Checkpoint {checkpoint_path} not found! Train first.\")\n",
        "\n",
        "        # Add space after {args.test_samples}\n",
        "        test_cmd = (f\"python test_DRAEM.py \"\n",
        "                    f\"--data_path {args.severstal_path} \"\n",
        "                    f\"--checkpoint_path {checkpoint_path} \"\n",
        "                    f\"--test_samples {args.test_samples} \"  # Space added here\n",
        "                    f\"--img_size {args.img_size}\")\n",
        "\n",
        "        if not run_command(test_cmd):\n",
        "            raise RuntimeError(\"Testing failed!\")\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\n=== Pipeline completed in {total_time:.2f} seconds ===\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main()\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {str(e)}\")\n",
        "        exit(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_reproduction.py \\\n",
        "--obj_name severstal \\\n",
        "--severstal_path /content/drive/MyDrive/severstal-steel-defect-detection \\\n",
        "--train_only \\\n",
        "--epochs 10 \\\n",
        "--bs 10 \\\n",
        "--grad_accum 4 \\\n",
        "--lr 3e-4 \\\n",
        "--img_size 160 \\\n",
        "--subset_size 5000 \\\n",
        "--oversampling \\\n",
        "--focal_gamma 2.5 \\\n",
        "--l1_weight 0.7 \\\n",
        "--grad_clip 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnC5B4s_NUoW",
        "outputId": "7f41575b-218c-4bf0-c0b9-347b2d72f911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Image: 867572f1e.jpg | Classes present: tensor([0])\n",
            "Image: e1db7ee54.jpg | Classes present: tensor([0])\n",
            "Image: 7de00739f.jpg | Classes present: tensor([0])\n",
            "Image: 933e1967c.jpg | Classes present: tensor([0])\n",
            "Image: ac97767a7.jpg | Classes present: tensor([0])\n",
            "Image: bebb35a5e.jpg | Classes present: tensor([0])\n",
            "Image: e5acd8af8.jpg | Classes present: tensor([0])\n",
            "Image: 3eec62abe.jpg | Classes present: tensor([0])\n",
            "Image: 3cfa559c3.jpg | Classes present: tensor([0, 2])\n",
            "Image: e054a983d.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0021298828069120646\n",
            "Training Batch 250 - Positive pixels per class: [   0.    0. 2181.    0.]\n",
            "Output stats - Min: -14.671875, Max: 1.9755859375\n",
            "Epoch 10/10:  50% 250/500 [00:49<00:45,  5.50it/s, Loss=0.0464]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.006922851782292128\n",
            "Training Batch 251 - Positive pixels per class: [   0.    0. 7089.    0.]\n",
            "Image: 8f82d86db.jpg | Classes present: tensor([0])\n",
            "Image: 19c3a9c48.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.28125, Max: 2.291015625\n",
            "Epoch 10/10:  50% 250/500 [00:49<00:45,  5.50it/s, Loss=0.0593]Image: ebcfa79fd.jpg | Classes present: tensor([0, 2])\n",
            "Image: 67e2d14a6.jpg | Classes present: tensor([0])\n",
            "Image: babc99f0c.jpg | Classes present: tensor([0])\n",
            "Image: 3738d1881.jpg | Classes present: tensor([0, 2])\n",
            "Image: d846db3b6.jpg | Classes present: tensor([0])\n",
            "Image: 6bd0ca419.jpg | Classes present: tensor([0])\n",
            "Image: a3c477831.jpg | Classes present: tensor([0])\n",
            "Image: 8b6c404ac.jpg | Classes present: tensor([0])\n",
            "Image: c51fb3d88.jpg | Classes present: tensor([0])\n",
            "Image: 7b08e8584.jpg | Classes present: tensor([0])\n",
            "Image: 84beeb839.jpg | Classes present: tensor([0])\n",
            "Image: db1b35480.jpg | Classes present: tensor([0])\n",
            "Image: 6b92f5221.jpg | Classes present: tensor([0])\n",
            "Image: 873fbc272.jpg | Classes present: tensor([0])\n",
            "Image: 0ebb34d89.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2731f7830.jpg | Classes present: tensor([0])\n",
            "Image: aad06b99e.jpg | Classes present: tensor([0])\n",
            "Image: ce8da6d72.jpg | Classes present: tensor([0])\n",
            "Image: edf12f5f1.jpg | Classes present: tensor([0])\n",
            "Image: 97192a78b.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.025783203542232513\n",
            "Training Batch 252 - Positive pixels per class: [    0.     0. 26402.     0.]\n",
            "Output stats - Min: -13.6171875, Max: 1.9931640625\n",
            "Image: 768eff9be.jpg | Classes present: tensor([0])\n",
            "Image: eef087050.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  50% 252/500 [00:49<00:45,  5.50it/s, Loss=0.0709]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.010271484963595867\n",
            "Training Batch 253 - Positive pixels per class: [ 974.    0. 9544.    0.]\n",
            "Output stats - Min: -16.984375, Max: 2.587890625\n",
            "Epoch 10/10:  50% 252/500 [00:49<00:45,  5.50it/s, Loss=0.0663]Image: b0e0b8842.jpg | Classes present: tensor([0])\n",
            "Image: ebedf35c7.jpg | Classes present: tensor([0, 2])\n",
            "Image: 560a3e98a.jpg | Classes present: tensor([0])\n",
            "Image: a5aa4829b.jpg | Classes present: tensor([0])\n",
            "Image: 539baaeda.jpg | Classes present: tensor([0])\n",
            "Image: 1f7b64701.jpg | Classes present: tensor([0])\n",
            "Image: 3ec7019e2.jpg | Classes present: tensor([0, 2])\n",
            "Image: b1c892c12.jpg | Classes present: tensor([0])\n",
            "Image: ecc0bf094.jpg | Classes present: tensor([0])\n",
            "Image: 41bbe4edd.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9d73bc0ef.jpg | Classes present: tensor([0])\n",
            "Image: 6666f7f16.jpg | Classes present: tensor([0, 2])\n",
            "Image: c22accc84.jpg | Classes present: tensor([0])\n",
            "Image: b4124fe84.jpg | Classes present: tensor([0])\n",
            "Image: 77a545147.jpg | Classes present: tensor([0])\n",
            "Image: 6ebc3df02.jpg | Classes present: tensor([0])\n",
            "Image: 6f405f1e3.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5020df2f8.jpg | Classes present: tensor([0])\n",
            "Image: ec10e45db.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.012239258736371994\n",
            "Training Batch 254 - Positive pixels per class: [    0.     0. 12533.     0.]\n",
            "Output stats - Min: -16.015625, Max: 1.8330078125\n",
            "Image: 9170e3614.jpg | Classes present: tensor([0])\n",
            "Image: bea834c94.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  51% 254/500 [00:50<00:44,  5.54it/s, Loss=0.062]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0062031252309679985\n",
            "Training Batch 255 - Positive pixels per class: [   0.    0. 6352.    0.]\n",
            "Image: 4ad6e9c90.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.9375, Max: 2.412109375\n",
            "Image: 73bf92d94.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8df12e874.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  51% 254/500 [00:50<00:44,  5.54it/s, Loss=0.0701]Image: d10c885f3.jpg | Classes present: tensor([0])\n",
            "Image: bea834c94.jpg | Classes present: tensor([0, 2])\n",
            "Image: ec58aa10d.jpg | Classes present: tensor([0])\n",
            "Image: 9586cb6e3.jpg | Classes present: tensor([0])\n",
            "Image: 5d0b67f94.jpg | Classes present: tensor([0, 3])\n",
            "Image: 9cccdc9c0.jpg | Classes present: tensor([0])\n",
            "Image: 11c481d5e.jpg | Classes present: tensor([0])\n",
            "Image: d8f5a6706.jpg | Classes present: tensor([0])\n",
            "Image: 60d7248a8.jpg | Classes present: tensor([0])\n",
            "Image: c987a8155.jpg | Classes present: tensor([0])\n",
            "Image: c8a9ae149.jpg | Classes present: tensor([0])\n",
            "Image: e6feea803.jpg | Classes present: tensor([0])\n",
            "Image: 2e8489244.jpg | Classes present: tensor([0])\n",
            "Image: a90767710.jpg | Classes present: tensor([0])\n",
            "Image: 8cc1c837b.jpg | Classes present: tensor([0])\n",
            "Image: a33ec265a.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.007364258170127869\n",
            "Training Batch 256 - Positive pixels per class: [ 946.    0. 6595.    0.]\n",
            "Output stats - Min: -15.34375, Max: 1.95703125\n",
            "Image: e6c89d5fd.jpg | Classes present: tensor([0])\n",
            "Image: 55901ac51.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  51% 256/500 [00:50<00:44,  5.49it/s, Loss=0.0885]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.021006837487220764\n",
            "Training Batch 257 - Positive pixels per class: [    0.     0. 16130.  5381.]\n",
            "Image: 83e63937d.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.34375, Max: 2.390625\n",
            "Epoch 10/10:  51% 256/500 [00:50<00:44,  5.49it/s, Loss=0.117] Image: 5e8ca0990.jpg | Classes present: tensor([0])\n",
            "Image: 816a3d605.jpg | Classes present: tensor([0])\n",
            "Image: e9c9ac12d.jpg | Classes present: tensor([0])\n",
            "Image: 20dec6c22.jpg | Classes present: tensor([0])\n",
            "Image: 2c24736d5.jpg | Classes present: tensor([0])\n",
            "Image: da691bc2e.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6ce526a3a.jpg | Classes present: tensor([0])\n",
            "Image: dc67d78bf.jpg | Classes present: tensor([0])\n",
            "Image: 3711ecc93.jpg | Classes present: tensor([0])\n",
            "Image: a70b5d0c5.jpg | Classes present: tensor([0])\n",
            "Image: 29f50b1fd.jpg | Classes present: tensor([0])\n",
            "Image: 6fd820bb6.jpg | Classes present: tensor([0])\n",
            "Image: 20e93e1cb.jpg | Classes present: tensor([0])\n",
            "Image: 6e6f0e760.jpg | Classes present: tensor([0])\n",
            "Image: 599251689.jpg | Classes present: tensor([0])\n",
            "Image: 995ef2622.jpg | Classes present: tensor([0])\n",
            "Image: 4014c79d3.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.00159570318646729\n",
            "Training Batch 258 - Positive pixels per class: [   0.    0. 1634.    0.]\n",
            "Output stats - Min: -13.0859375, Max: 1.8681640625\n",
            "Image: c60f92f8b.jpg | Classes present: tensor([0])\n",
            "Image: 1def10240.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  52% 258/500 [00:50<00:41,  5.77it/s, Loss=0.056]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.005252929870039225\n",
            "Training Batch 259 - Positive pixels per class: [   0.    0. 5379.    0.]\n",
            "Output stats - Min: -14.0234375, Max: 2.521484375\n",
            "Image: 66c272e62.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  52% 258/500 [00:50<00:41,  5.77it/s, Loss=0.0715]Image: 4edc8b817.jpg | Classes present: tensor([0, 3])\n",
            "Image: 312224509.jpg | Classes present: tensor([0, 3])\n",
            "Image: 135a4b191.jpg | Classes present: tensor([0])\n",
            "Image: 4a4f274d1.jpg | Classes present: tensor([0])\n",
            "Image: b657c7ed4.jpg | Classes present: tensor([0])\n",
            "Image: d7c2c6ba8.jpg | Classes present: tensor([0])\n",
            "Image: 7095ad89d.jpg | Classes present: tensor([0])\n",
            "Image: aeaa1deef.jpg | Classes present: tensor([0])\n",
            "Image: ce5f0cec3.jpg | Classes present: tensor([0])\n",
            "Image: 7d58142ba.jpg | Classes present: tensor([0])\n",
            "Image: bc395145e.jpg | Classes present: tensor([0])\n",
            "Image: 55136d7f3.jpg | Classes present: tensor([0])\n",
            "Image: cdd6cac95.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9147356db.jpg | Classes present: tensor([0])\n",
            "Image: 938a15be6.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.004653320647776127\n",
            "Training Batch 260 - Positive pixels per class: [   0.    0. 3028. 1737.]\n",
            "Image: b34e9a47e.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -14.0234375, Max: 1.3525390625\n",
            "Image: ec9f97e66.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  52% 260/500 [00:51<00:40,  5.98it/s, Loss=0.0799]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.00023925781715661287\n",
            "Training Batch 261 - Positive pixels per class: [  0.   0.   0. 245.]\n",
            "Output stats - Min: -15.21875, Max: 1.869140625\n",
            "Image: 0bd6da716.jpg | Classes present: tensor([0])\n",
            "Image: 97892278c.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  52% 260/500 [00:51<00:40,  5.98it/s, Loss=0.0737]Image: b378e4122.jpg | Classes present: tensor([0, 2])\n",
            "Image: d4c0b4c3b.jpg | Classes present: tensor([0])\n",
            "Image: e2512d5f4.jpg | Classes present: tensor([0, 2])\n",
            "Image: ec1ffc4eb.jpg | Classes present: tensor([0])\n",
            "Image: 31cf10f6e.jpg | Classes present: tensor([0, 2])\n",
            "Image: b2148a422.jpg | Classes present: tensor([0])\n",
            "Image: 8cd9ca854.jpg | Classes present: tensor([0])\n",
            "Image: dd3efb748.jpg | Classes present: tensor([0])\n",
            "Image: 800b8c9d1.jpg | Classes present: tensor([0, 2])\n",
            "Image: d95c9d342.jpg | Classes present: tensor([0])\n",
            "Image: e6feea803.jpg | Classes present: tensor([0])\n",
            "Image: 07732248e.jpg | Classes present: tensor([0, 2])\n",
            "Image: c2759d94e.jpg | Classes present: tensor([0])\n",
            "Image: 0929b3d8f.jpg | Classes present: tensor([0])\n",
            "Image: b35a08d7a.jpg | Classes present: tensor([0])\n",
            "Image: accc38459.jpg | Classes present: tensor([0])\n",
            "Image: 7a14789e6.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.003908203449100256\n",
            "Training Batch 262 - Positive pixels per class: [   0.    0. 4002.    0.]\n",
            "Image: a15500c55.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -14.890625, Max: 2.150390625\n",
            "Epoch 10/10:  52% 262/500 [00:51<00:40,  5.85it/s, Loss=0.0563]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.006967773661017418\n",
            "Training Batch 263 - Positive pixels per class: [   0.    0. 7135.    0.]\n",
            "Output stats - Min: -17.1875, Max: 1.7919921875\n",
            "Image: 64fc246e7.jpg | Classes present: tensor([0])\n",
            "Image: a5655b60f.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  52% 262/500 [00:51<00:40,  5.85it/s, Loss=0.0634]Image: ead253ed7.jpg | Classes present: tensor([0])\n",
            "Image: eb81bea67.jpg | Classes present: tensor([0])\n",
            "Image: e9d0de676.jpg | Classes present: tensor([0])\n",
            "Image: 7b08e8584.jpg | Classes present: tensor([0])\n",
            "Image: d8aeec2d5.jpg | Classes present: tensor([0])\n",
            "Image: 27fb17019.jpg | Classes present: tensor([0])\n",
            "Image: 23c9c6cba.jpg | Classes present: tensor([0])\n",
            "Image: 816a3d605.jpg | Classes present: tensor([0])\n",
            "Image: a82b34c33.jpg | Classes present: tensor([0])\n",
            "Image: 1ed75107a.jpg | Classes present: tensor([0])\n",
            "Image: ec8c34113.jpg | Classes present: tensor([0])\n",
            "Image: 6dbd47d4f.jpg | Classes present: tensor([0])\n",
            "Image: 94caf2212.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5a2a644d9.jpg | Classes present: tensor([0])\n",
            "Image: 4c3afd528.jpg | Classes present: tensor([0])\n",
            "Image: 1a17a1f15.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.008203125558793545\n",
            "Training Batch 264 - Positive pixels per class: [   0.    0. 8400.    0.]\n",
            "Image: ae2c96c4e.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.1875, Max: 1.7470703125\n",
            "Image: 91f059953.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  53% 264/500 [00:51<00:40,  5.88it/s, Loss=0.0634]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.001312500098720193\n",
            "Training Batch 265 - Positive pixels per class: [   0.    0. 1344.    0.]\n",
            "Image: 409502827.jpg | Classes present: tensor([0, 2])\n",
            "Output stats - Min: -16.921875, Max: 1.2431640625\n",
            "Image: 7bb25cc94.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  53% 264/500 [00:51<00:40,  5.88it/s, Loss=0.0683]Image: 9b7974523.jpg | Classes present: tensor([0])\n",
            "Image: 2d8cef5f6.jpg | Classes present: tensor([0])\n",
            "Image: 2c8d08d8d.jpg | Classes present: tensor([0])\n",
            "Image: 27e291687.jpg | Classes present: tensor([0])\n",
            "Image: 67a9dd552.jpg | Classes present: tensor([0, 1])\n",
            "Image: a8bc0275d.jpg | Classes present: tensor([0])\n",
            "Image: 398a5b6a9.jpg | Classes present: tensor([0])\n",
            "Image: a71e7121c.jpg | Classes present: tensor([0])\n",
            "Image: 5600ec21b.jpg | Classes present: tensor([0])\n",
            "Image: 277ebde3b.jpg | Classes present: tensor([0])\n",
            "Image: 32fa68bed.jpg | Classes present: tensor([0])\n",
            "Image: ef94ca813.jpg | Classes present: tensor([0])\n",
            "Image: 74472e481.jpg | Classes present: tensor([0])\n",
            "Image: 2c6ee79c9.jpg | Classes present: tensor([0, 2])\n",
            "Image: 55d87ed7a.jpg | Classes present: tensor([0])\n",
            "Image: e8aacce9c.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 266 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -15.1875, Max: 1.2177734375\n",
            "Image: e07f3f1b3.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  53% 266/500 [00:52<00:38,  6.08it/s, Loss=0.0358]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.003644531359896064\n",
            "Training Batch 267 - Positive pixels per class: [   0. 2916.  816.    0.]\n",
            "Image: 13fa1d70d.jpg | Classes present: tensor([0, 3])\n",
            "Output stats - Min: -16.421875, Max: 1.4931640625\n",
            "Epoch 10/10:  53% 266/500 [00:52<00:38,  6.08it/s, Loss=0.158] Image: 8b31c67c8.jpg | Classes present: tensor([0])\n",
            "Image: cbba0f365.jpg | Classes present: tensor([0])\n",
            "Image: b612e5812.jpg | Classes present: tensor([0])\n",
            "Image: b9b07c892.jpg | Classes present: tensor([0])\n",
            "Image: 6fdf2d1be.jpg | Classes present: tensor([0, 2])\n",
            "Image: da8ace073.jpg | Classes present: tensor([0])\n",
            "Image: 86654180d.jpg | Classes present: tensor([0])\n",
            "Image: 2b1f20578.jpg | Classes present: tensor([0])\n",
            "Image: ac681cbde.jpg | Classes present: tensor([0, 2])\n",
            "Image: 17eeca349.jpg | Classes present: tensor([0])\n",
            "Image: 4f77c0179.jpg | Classes present: tensor([0])\n",
            "Image: 86f4141ce.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6fb878fef.jpg | Classes present: tensor([0])\n",
            "Image: 22b459911.jpg | Classes present: tensor([0])\n",
            "Image: e8a40861a.jpg | Classes present: tensor([0])\n",
            "Image: ed3f080c3.jpg | Classes present: tensor([0])\n",
            "Image: 5aff55ed5.jpg | Classes present: tensor([0])\n",
            "Image: 1c8802c08.jpg | Classes present: tensor([0])\n",
            "Image: e622e319f.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.01212890725582838\n",
            "Training Batch 268 - Positive pixels per class: [   0.    0. 9345. 3075.]\n",
            "Output stats - Min: -14.7734375, Max: 2.05078125\n",
            "Image: 4f7972e7c.jpg | Classes present: tensor([0])\n",
            "Image: 1c75c4ebd.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  54% 268/500 [00:52<00:39,  5.81it/s, Loss=0.106]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.015498047694563866\n",
            "Training Batch 269 - Positive pixels per class: [    0.     0. 15870.     0.]\n",
            "Output stats - Min: -16.515625, Max: 1.845703125\n",
            "Image: 9753787e9.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  54% 268/500 [00:52<00:39,  5.81it/s, Loss=0.056]Image: 5013e5c9d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3fcd061fc.jpg | Classes present: tensor([0])\n",
            "Image: 209e34a89.jpg | Classes present: tensor([0])\n",
            "Image: cb4d72e56.jpg | Classes present: tensor([0])\n",
            "Image: 8898932bd.jpg | Classes present: tensor([0, 2])\n",
            "Image: a9a045b71.jpg | Classes present: tensor([0])\n",
            "Image: 77064b126.jpg | Classes present: tensor([0])\n",
            "Image: 999497bb8.jpg | Classes present: tensor([0, 2])\n",
            "Image: 658ad1fc9.jpg | Classes present: tensor([0])\n",
            "Image: a0c6fd992.jpg | Classes present: tensor([0])\n",
            "Image: 510b9c5cc.jpg | Classes present: tensor([0])\n",
            "Image: a697f938a.jpg | Classes present: tensor([0, 2])\n",
            "Image: e19ca4457.jpg | Classes present: tensor([0])\n",
            "Image: 79ccb5e88.jpg | Classes present: tensor([0])\n",
            "Image: 367553727.jpg | Classes present: tensor([0])\n",
            "Image: 12ca2b04b.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0024970704689621925\n",
            "Training Batch 270 - Positive pixels per class: [ 487.    0. 2070.    0.]\n",
            "Image: 9438d5eef.jpg | Classes present: tensor([0, 2])\n",
            "Output stats - Min: -15.1875, Max: 1.3701171875\n",
            "Epoch 10/10:  54% 270/500 [00:52<00:38,  5.92it/s, Loss=0.0785]Image: cd1f8d368.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.00585253955796361\n",
            "Training Batch 271 - Positive pixels per class: [   0.    0. 5993.    0.]\n",
            "Image: d99f9f7ac.jpg | Classes present: tensor([0, 2])\n",
            "Image: bd70c4b99.jpg | Classes present: tensor([0, 2])\n",
            "Output stats - Min: -15.1484375, Max: 2.294921875\n",
            "Epoch 10/10:  54% 270/500 [00:52<00:38,  5.92it/s, Loss=0.0416]Image: 1287c7c74.jpg | Classes present: tensor([0])\n",
            "Image: afc4ca4f0.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2c18ac76d.jpg | Classes present: tensor([0])\n",
            "Image: a1f41023e.jpg | Classes present: tensor([0, 2])\n",
            "Image: a985a9c7c.jpg | Classes present: tensor([0])\n",
            "Image: 12627251e.jpg | Classes present: tensor([0, 2])\n",
            "Image: ac4ba5c1a.jpg | Classes present: tensor([0])\n",
            "Image: 19b4b7cd8.jpg | Classes present: tensor([0])\n",
            "Image: 3b4c8b9a4.jpg | Classes present: tensor([0])\n",
            "Image: b3b1e1046.jpg | Classes present: tensor([0])\n",
            "Image: a93b52e93.jpg | Classes present: tensor([0])\n",
            "Image: d8dbdc59e.jpg | Classes present: tensor([0, 3])\n",
            "Image: 556e12633.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2744b6b26.jpg | Classes present: tensor([0])\n",
            "Image: 09d84ff22.jpg | Classes present: tensor([0])\n",
            "Image: c7a4a7472.jpg | Classes present: tensor([0, 3])\n",
            "Image: 3cff791b3.jpg | Classes present: tensor([0])\n",
            "Image: a78f72e04.jpg | Classes present: tensor([0])\n",
            "Image: 58384cf41.jpg | Classes present: tensor([0, 2])\n",
            "Image: a129732b2.jpg | Classes present: tensor([0])\n",
            "Image: 6826c7bde.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0594794936478138\n",
            "Training Batch 272 - Positive pixels per class: [    0.     0. 51394.  9513.]\n",
            "Output stats - Min: -16.8125, Max: 2.3515625\n",
            "Image: 7dc8d94dc.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  54% 272/500 [00:53<00:39,  5.73it/s, Loss=0.326]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0444951206445694\n",
            "Training Batch 273 - Positive pixels per class: [    0.     0. 45563.     0.]\n",
            "Output stats - Min: -14.1640625, Max: 1.98046875\n",
            "Image: b31d1c693.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  54% 272/500 [00:53<00:39,  5.73it/s, Loss=0.0935]Image: 7fc69d9fd.jpg | Classes present: tensor([0])\n",
            "Image: 1c3a58b06.jpg | Classes present: tensor([0])\n",
            "Image: 3b2b910c7.jpg | Classes present: tensor([0])\n",
            "Image: 77c7c7966.jpg | Classes present: tensor([0])\n",
            "Image: 6f5299561.jpg | Classes present: tensor([0])\n",
            "Image: 47cf3a13c.jpg | Classes present: tensor([0])\n",
            "Image: 9d57d9095.jpg | Classes present: tensor([0])\n",
            "Image: 759075283.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0abfbfc69.jpg | Classes present: tensor([0, 2])\n",
            "Image: 576910e29.jpg | Classes present: tensor([0])\n",
            "Image: 464917fe0.jpg | Classes present: tensor([0])\n",
            "Image: 47d9b630e.jpg | Classes present: tensor([0])\n",
            "Image: 35c80b6f0.jpg | Classes present: tensor([0])\n",
            "Image: 6a8d360f7.jpg | Classes present: tensor([0])\n",
            "Image: 6a64ceedf.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.004602539353072643\n",
            "Training Batch 274 - Positive pixels per class: [   0.    0. 4713.    0.]\n",
            "Image: 261c6d458.jpg | Classes present: tensor([0, 2])\n",
            "Output stats - Min: -12.8984375, Max: 1.9169921875\n",
            "Epoch 10/10:  55% 274/500 [00:53<00:37,  6.01it/s, Loss=0.0865]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.008637695573270321\n",
            "Training Batch 275 - Positive pixels per class: [   0.    0. 8845.    0.]\n",
            "Image: a16672b15.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.5390625, Max: 2.166015625\n",
            "Epoch 10/10:  55% 274/500 [00:53<00:37,  6.01it/s, Loss=0.0551]Image: 75ea4c672.jpg | Classes present: tensor([0])\n",
            "Image: 872b09085.jpg | Classes present: tensor([0])\n",
            "Image: d652c9109.jpg | Classes present: tensor([0])\n",
            "Image: aab6434b3.jpg | Classes present: tensor([0, 3])\n",
            "Image: e3485d08f.jpg | Classes present: tensor([0])\n",
            "Image: 7210ffc2d.jpg | Classes present: tensor([0])\n",
            "Image: 44668f045.jpg | Classes present: tensor([0, 2])\n",
            "Image: 63fde7ae0.jpg | Classes present: tensor([0])\n",
            "Image: 6b513db3b.jpg | Classes present: tensor([0])\n",
            "Image: 6b4308d55.jpg | Classes present: tensor([0])\n",
            "Image: e4645dffc.jpg | Classes present: tensor([0, 2])\n",
            "Image: ca520c90f.jpg | Classes present: tensor([0])\n",
            "Image: 4dfd9c462.jpg | Classes present: tensor([0])\n",
            "Image: aa2db8e29.jpg | Classes present: tensor([0])\n",
            "Image: 9f2f9704e.jpg | Classes present: tensor([0, 2])\n",
            "Image: 031f334ec.jpg | Classes present: tensor([0])\n",
            "Image: c8e4b3a1e.jpg | Classes present: tensor([0])\n",
            "Image: 464a009f9.jpg | Classes present: tensor([0])\n",
            "Image: 1df34bed6.jpg | Classes present: tensor([0])\n",
            "Image: 13169e4cf.jpg | Classes present: tensor([0])\n",
            "Image: 5256faa06.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.006357422098517418\n",
            "Training Batch 276 - Positive pixels per class: [   0.    0. 6510.    0.]\n",
            "Image: 27f830690.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.75, Max: 2.099609375\n",
            "Image: 60fb3a793.jpg | Classes present: tensor([0])\n",
            "Image: 6d291e247.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  55% 276/500 [00:53<00:40,  5.51it/s, Loss=0.0499]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0128935556858778\n",
            "Training Batch 277 - Positive pixels per class: [    0.     0. 11611.  1592.]\n",
            "Output stats - Min: -15.296875, Max: 2.064453125\n",
            "Epoch 10/10:  55% 276/500 [00:53<00:40,  5.51it/s, Loss=0.0766]Image: 0d4eae8de.jpg | Classes present: tensor([0])\n",
            "Image: 9eed4fc7c.jpg | Classes present: tensor([0])\n",
            "Image: 9f2871e90.jpg | Classes present: tensor([0])\n",
            "Image: a2337ccb3.jpg | Classes present: tensor([0])\n",
            "Image: 67fce2600.jpg | Classes present: tensor([0])\n",
            "Image: 58049fca1.jpg | Classes present: tensor([0])\n",
            "Image: ed4db5cf7.jpg | Classes present: tensor([0])\n",
            "Image: dc46cd893.jpg | Classes present: tensor([0])\n",
            "Image: eda5114ee.jpg | Classes present: tensor([0])\n",
            "Image: 3afb8f1bc.jpg | Classes present: tensor([0])\n",
            "Image: b32156d1f.jpg | Classes present: tensor([0])\n",
            "Image: 84eac92fc.jpg | Classes present: tensor([0])\n",
            "Image: 74661f8d7.jpg | Classes present: tensor([0])\n",
            "Image: 55c689cd0.jpg | Classes present: tensor([0])\n",
            "Image: b19fbab56.jpg | Classes present: tensor([0])\n",
            "Image: 45b099b06.jpg | Classes present: tensor([0])\n",
            "Image: 38b921939.jpg | Classes present: tensor([0])\n",
            "Image: cb2dee2dd.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 278 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -14.640625, Max: 0.9580078125\n",
            "Image: 763402396.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  56% 278/500 [00:54<00:38,  5.84it/s, Loss=0.0446]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.000868164119310677\n",
            "Training Batch 279 - Positive pixels per class: [  0.   0. 889.   0.]\n",
            "Output stats - Min: -17.5625, Max: 1.2802734375\n",
            "Image: 20edbd1a8.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  56% 278/500 [00:54<00:38,  5.84it/s, Loss=0.0541]Image: 04594d04e.jpg | Classes present: tensor([0])\n",
            "Image: c15deb6c0.jpg | Classes present: tensor([0])\n",
            "Image: ce3818dfd.jpg | Classes present: tensor([0])\n",
            "Image: 0602f0520.jpg | Classes present: tensor([0])\n",
            "Image: e4da37c1e.jpg | Classes present: tensor([0])\n",
            "Image: 3f39b85b9.jpg | Classes present: tensor([0])\n",
            "Image: 4bfbe85ff.jpg | Classes present: tensor([0])\n",
            "Image: 8aaebf6ec.jpg | Classes present: tensor([0])\n",
            "Image: b3139b9a1.jpg | Classes present: tensor([0])\n",
            "Image: 78ac37759.jpg | Classes present: tensor([0])\n",
            "Image: a6fcd0f71.jpg | Classes present: tensor([0])\n",
            "Image: 15d8b6f02.jpg | Classes present: tensor([0])\n",
            "Image: 6f46868d9.jpg | Classes present: tensor([0])\n",
            "Image: bf740c1e2.jpg | Classes present: tensor([0])\n",
            "Image: 2789df930.jpg | Classes present: tensor([0])\n",
            "Image: 89dcbb574.jpg | Classes present: tensor([0])\n",
            "Image: ba027ff62.jpg | Classes present: tensor([0, 2])\n",
            "Image: ada844648.jpg | Classes present: tensor([0])\n",
            "Image: d18bec611.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0029941408429294825\n",
            "Training Batch 280 - Positive pixels per class: [   0.    0. 3066.    0.]\n",
            "Output stats - Min: -13.921875, Max: 2.431640625\n",
            "Image: 8eb427a2d.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  56% 280/500 [00:54<00:38,  5.69it/s, Loss=0.0541]Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 281 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: 81847fd11.jpg | Classes present: tensor([0])\n",
            "Image: 374493292.jpg | Classes present: tensor([0, 3])\n",
            "Output stats - Min: -14.703125, Max: 1.4296875\n",
            "Epoch 10/10:  56% 280/500 [00:54<00:38,  5.69it/s, Loss=0.0762]Image: 539a9d455.jpg | Classes present: tensor([0])\n",
            "Image: 13c9921d2.jpg | Classes present: tensor([0])\n",
            "Image: 1f4161475.jpg | Classes present: tensor([0])\n",
            "Image: b568146ec.jpg | Classes present: tensor([0])\n",
            "Image: 2d759458e.jpg | Classes present: tensor([0])\n",
            "Image: 128b708e5.jpg | Classes present: tensor([0])\n",
            "Image: 38f4e6d5a.jpg | Classes present: tensor([0])\n",
            "Image: d806c4bd6.jpg | Classes present: tensor([0])\n",
            "Image: 7e7647e70.jpg | Classes present: tensor([0])\n",
            "Image: e4a964382.jpg | Classes present: tensor([0, 2])\n",
            "Image: a9cee6edb.jpg | Classes present: tensor([0])\n",
            "Image: 169baf9bb.jpg | Classes present: tensor([0])\n",
            "Image: a508dd004.jpg | Classes present: tensor([0])\n",
            "Image: 60efe3f90.jpg | Classes present: tensor([0])\n",
            "Image: 1d66a6fb4.jpg | Classes present: tensor([0])\n",
            "Image: 478ff6696.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.02369043044745922\n",
            "Training Batch 282 - Positive pixels per class: [    0.     0. 24259.     0.]\n",
            "Output stats - Min: -16.46875, Max: 2.322265625\n",
            "Epoch 10/10:  56% 282/500 [00:54<00:37,  5.75it/s, Loss=0.0592]Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 283 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -16.046875, Max: 1.23046875\n",
            "Epoch 10/10:  56% 282/500 [00:54<00:37,  5.75it/s, Loss=0.0628]Image: 09552b326.jpg | Classes present: tensor([0, 2])\n",
            "Image: 28f8c53de.jpg | Classes present: tensor([0])\n",
            "Image: dc0c6c0de.jpg | Classes present: tensor([0])\n",
            "Image: 9c19a106d.jpg | Classes present: tensor([0])\n",
            "Image: ad3630cdc.jpg | Classes present: tensor([0])\n",
            "Image: 7549c90b1.jpg | Classes present: tensor([0])\n",
            "Image: 4aa9afc78.jpg | Classes present: tensor([0, 2])\n",
            "Image: ce71311e1.jpg | Classes present: tensor([0])\n",
            "Image: 37e7f9554.jpg | Classes present: tensor([0])\n",
            "Image: 6668e50d0.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5ba141d56.jpg | Classes present: tensor([0])\n",
            "Image: 2283f2183.jpg | Classes present: tensor([0])\n",
            "Image: 7fb0c3636.jpg | Classes present: tensor([0])\n",
            "Image: 9078fb095.jpg | Classes present: tensor([0, 2])\n",
            "Image: e57c6ff76.jpg | Classes present: tensor([0])\n",
            "Image: b5967f1ce.jpg | Classes present: tensor([0])\n",
            "Image: d85f94a97.jpg | Classes present: tensor([0])\n",
            "Image: bd967bd29.jpg | Classes present: tensor([0])\n",
            "Image: 135be73db.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.006375000346451998\n",
            "Training Batch 284 - Positive pixels per class: [   0.    0. 6528.    0.]\n",
            "Output stats - Min: -14.6328125, Max: 1.705078125\n",
            "Image: 8c8e79fa0.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  57% 284/500 [00:55<00:37,  5.74it/s, Loss=0.0531]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.03084082156419754\n",
            "Training Batch 285 - Positive pixels per class: [    0.     0. 25111.  6470.]\n",
            "Image: b1d574c91.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -18.625, Max: 2.138671875\n",
            "Image: dd1683e7b.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  57% 284/500 [00:55<00:37,  5.74it/s, Loss=0.146] Image: 7ff50bb90.jpg | Classes present: tensor([0])\n",
            "Image: 25c8f7153.jpg | Classes present: tensor([0, 2])\n",
            "Image: 24fce7ae0.jpg | Classes present: tensor([0])\n",
            "Image: d71e73d6f.jpg | Classes present: tensor([0])\n",
            "Image: ca4309568.jpg | Classes present: tensor([0, 2])\n",
            "Image: 25e74a78a.jpg | Classes present: tensor([0])\n",
            "Image: 78b8acca7.jpg | Classes present: tensor([0])\n",
            "Image: e0eade7b1.jpg | Classes present: tensor([0])\n",
            "Image: 461fb4927.jpg | Classes present: tensor([0])\n",
            "Image: 8d2e8b456.jpg | Classes present: tensor([0])\n",
            "Image: 163ff3547.jpg | Classes present: tensor([0])\n",
            "Image: b24d691a6.jpg | Classes present: tensor([0])\n",
            "Image: 1ffe887dd.jpg | Classes present: tensor([0])\n",
            "Image: 112b06482.jpg | Classes present: tensor([0])\n",
            "Image: 4d4cb6e78.jpg | Classes present: tensor([0])\n",
            "Image: 39c094b3d.jpg | Classes present: tensor([0])\n",
            "Image: e07f3eb4b.jpg | Classes present: tensor([0])\n",
            "Image: 5c201d9e7.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.005816406570374966\n",
            "Training Batch 286 - Positive pixels per class: [   0.    0. 5956.    0.]\n",
            "Image: cbb659739.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.59375, Max: 2.02734375\n",
            "Image: 0a405b396.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  57% 286/500 [00:55<00:36,  5.83it/s, Loss=0.0568]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.020213868468999863\n",
            "Training Batch 287 - Positive pixels per class: [    0.     0. 20699.     0.]\n",
            "Image: 356e7a71a.jpg | Classes present: tensor([0, 2])\n",
            "Output stats - Min: -15.6171875, Max: 1.923828125\n",
            "Epoch 10/10:  57% 286/500 [00:55<00:36,  5.83it/s, Loss=0.0883]Image: 2ea4ad171.jpg | Classes present: tensor([0])\n",
            "Image: ee65fc6d8.jpg | Classes present: tensor([0])\n",
            "Image: c20989bd4.jpg | Classes present: tensor([0])\n",
            "Image: aac54b46c.jpg | Classes present: tensor([0])\n",
            "Image: 6d5d698e0.jpg | Classes present: tensor([0])\n",
            "Image: 6a4efceac.jpg | Classes present: tensor([0])\n",
            "Image: eb44ad79d.jpg | Classes present: tensor([0])\n",
            "Image: d6c91e8e7.jpg | Classes present: tensor([0])\n",
            "Image: de1f2b234.jpg | Classes present: tensor([0])\n",
            "Image: 46655e050.jpg | Classes present: tensor([0])\n",
            "Image: b68ac5910.jpg | Classes present: tensor([0, 3])\n",
            "Image: 71f2ce9ab.jpg | Classes present: tensor([0])\n",
            "Image: 892321605.jpg | Classes present: tensor([0])\n",
            "Image: 4d9b0f8c6.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.008026367984712124\n",
            "Training Batch 288 - Positive pixels per class: [   0.    0. 2600. 5619.]\n",
            "Output stats - Min: -16.4375, Max: 2.296875\n",
            "Image: c6510fb5a.jpg | Classes present: tensor([0])\n",
            "Image: def2ac19d.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  58% 288/500 [00:55<00:34,  6.17it/s, Loss=0.114]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.016046876087784767\n",
            "Training Batch 289 - Positive pixels per class: [    0.     0. 16432.     0.]\n",
            "Output stats - Min: -16.75, Max: 1.642578125\n",
            "Epoch 10/10:  58% 288/500 [00:55<00:34,  6.17it/s, Loss=0.0586]Image: 9c522d453.jpg | Classes present: tensor([0])\n",
            "Image: 7a0d758f8.jpg | Classes present: tensor([0])\n",
            "Image: 28661fd17.jpg | Classes present: tensor([0])\n",
            "Image: 5f11a4623.jpg | Classes present: tensor([0])\n",
            "Image: 1198f83d2.jpg | Classes present: tensor([0])\n",
            "Image: 87edd91dc.jpg | Classes present: tensor([0])\n",
            "Image: 4072c3bb5.jpg | Classes present: tensor([0])\n",
            "Image: 7b3566fb9.jpg | Classes present: tensor([0])\n",
            "Image: 5af025ad7.jpg | Classes present: tensor([0])\n",
            "Image: 9d77811eb.jpg | Classes present: tensor([0])\n",
            "Image: 2dcff4a4e.jpg | Classes present: tensor([0])\n",
            "Image: 5227eaed2.jpg | Classes present: tensor([0])\n",
            "Image: 07b1a9644.jpg | Classes present: tensor([0])\n",
            "Image: 079054aa2.jpg | Classes present: tensor([0])\n",
            "Image: 4b5490a9f.jpg | Classes present: tensor([0])\n",
            "Image: 3f36e2d85.jpg | Classes present: tensor([0])\n",
            "Image: b8a69919f.jpg | Classes present: tensor([0])\n",
            "Image: 42527400c.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 290 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: 21f89256c.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.921875, Max: 1.3251953125\n",
            "Epoch 10/10:  58% 290/500 [00:56<00:34,  6.10it/s, Loss=0.0508]Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 291 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: 4b09a3911.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.015625, Max: 1.04296875\n",
            "Epoch 10/10:  58% 290/500 [00:56<00:34,  6.10it/s, Loss=0.0365]Image: 614e8523d.jpg | Classes present: tensor([0])\n",
            "Image: 9cd1d622e.jpg | Classes present: tensor([0])\n",
            "Image: 5f459aeb3.jpg | Classes present: tensor([0, 3])\n",
            "Image: 446b75ffb.jpg | Classes present: tensor([0])\n",
            "Image: dfcc8d751.jpg | Classes present: tensor([0])\n",
            "Image: db3ce9c95.jpg | Classes present: tensor([0])\n",
            "Image: 388e36308.jpg | Classes present: tensor([0])\n",
            "Image: 204bcfc88.jpg | Classes present: tensor([0])\n",
            "Image: 1740fcd28.jpg | Classes present: tensor([0])\n",
            "Image: d62c3879c.jpg | Classes present: tensor([0])\n",
            "Image: b2ad335bf.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3a0a9a167.jpg | Classes present: tensor([0])\n",
            "Image: bfb064127.jpg | Classes present: tensor([0])\n",
            "Image: 61a365822.jpg | Classes present: tensor([0])\n",
            "Image: 6ed5cee50.jpg | Classes present: tensor([0])\n",
            "Image: cdbc80c3d.jpg | Classes present: tensor([0])\n",
            "Image: 059327fe3.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0ec130695.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.01581152342259884\n",
            "Training Batch 292 - Positive pixels per class: [    0.     0. 13826.  2365.]\n",
            "Output stats - Min: -14.390625, Max: 2.06640625\n",
            "Image: aa61a5c9f.jpg | Classes present: tensor([0])\n",
            "Image: bca9c5489.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  58% 292/500 [00:56<00:33,  6.12it/s, Loss=0.0891]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0016728516202419996\n",
            "Training Batch 293 - Positive pixels per class: [1713.    0.    0.    0.]\n",
            "Output stats - Min: -17.46875, Max: 1.4990234375\n",
            "Epoch 10/10:  58% 292/500 [00:56<00:33,  6.12it/s, Loss=0.0816]Image: d7a6b31ea.jpg | Classes present: tensor([0, 3])\n",
            "Image: 4edff9648.jpg | Classes present: tensor([0])\n",
            "Image: e3c8b3a70.jpg | Classes present: tensor([0])\n",
            "Image: 4ade4b747.jpg | Classes present: tensor([0])\n",
            "Image: 4d38c353e.jpg | Classes present: tensor([0])\n",
            "Image: 052cc2a0f.jpg | Classes present: tensor([0])\n",
            "Image: 456b9952f.jpg | Classes present: tensor([0])\n",
            "Image: 7c02570e9.jpg | Classes present: tensor([0])\n",
            "Image: 26b980260.jpg | Classes present: tensor([0])\n",
            "Image: 05747b10b.jpg | Classes present: tensor([0])\n",
            "Image: 84a3347e4.jpg | Classes present: tensor([0])\n",
            "Image: 627b98bc7.jpg | Classes present: tensor([0])\n",
            "Image: d2938b2af.jpg | Classes present: tensor([0])\n",
            "Image: 4b628b398.jpg | Classes present: tensor([0, 2])\n",
            "Image: 961e93bde.jpg | Classes present: tensor([0])\n",
            "Image: a42dee222.jpg | Classes present: tensor([0, 3])\n",
            "Image: b98f3f3b7.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.022044923156499863\n",
            "Training Batch 294 - Positive pixels per class: [    0.     0.  6297. 16277.]\n",
            "Output stats - Min: -15.1640625, Max: 1.7421875\n",
            "Image: 42d65967f.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  58% 292/500 [00:56<00:33,  6.12it/s, Loss=0.177] Image: a65a8503a.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  59% 294/500 [00:56<00:33,  6.08it/s, Loss=0.177]Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 295 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: 1dac7069c.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.75, Max: 1.650390625\n",
            "Epoch 10/10:  59% 294/500 [00:56<00:33,  6.08it/s, Loss=0.0429]Image: 86e81413a.jpg | Classes present: tensor([0])\n",
            "Image: 922939d64.jpg | Classes present: tensor([0])\n",
            "Image: bfcffb683.jpg | Classes present: tensor([0])\n",
            "Image: be3b49756.jpg | Classes present: tensor([0, 2])\n",
            "Image: 397bdbbf6.jpg | Classes present: tensor([0])\n",
            "Image: 08808b1a2.jpg | Classes present: tensor([0])\n",
            "Image: 9f2b5e50a.jpg | Classes present: tensor([0])\n",
            "Image: badd96385.jpg | Classes present: tensor([0, 3])\n",
            "Image: 50b285302.jpg | Classes present: tensor([0])\n",
            "Image: cd23a468a.jpg | Classes present: tensor([0])\n",
            "Image: b3bf49ca1.jpg | Classes present: tensor([0])\n",
            "Image: b2f297777.jpg | Classes present: tensor([0])\n",
            "Image: 403a0cb2e.jpg | Classes present: tensor([0])\n",
            "Image: 7a249b737.jpg | Classes present: tensor([0])\n",
            "Image: 054190eb2.jpg | Classes present: tensor([0])\n",
            "Image: 6218cd94a.jpg | Classes present: tensor([0])\n",
            "Image: 3c8b6c978.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 296 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: ca850ca04.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.953125, Max: 1.365234375\n",
            "Image: 72bebf035.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  59% 296/500 [00:57<00:33,  6.09it/s, Loss=0.037]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.006571289151906967\n",
            "Training Batch 297 - Positive pixels per class: [   0.    0. 6729.    0.]\n",
            "Image: 19f00abbf.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.03125, Max: 2.08203125\n",
            "Image: eb10d7ae4.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  59% 296/500 [00:57<00:33,  6.09it/s, Loss=0.0716]Image: 30e863a30.jpg | Classes present: tensor([0])\n",
            "Image: 9c14e3f70.jpg | Classes present: tensor([0])\n",
            "Image: caf49d870.jpg | Classes present: tensor([0])\n",
            "Image: 6bdf447c5.jpg | Classes present: tensor([0])\n",
            "Image: 75ab0593e.jpg | Classes present: tensor([0])\n",
            "Image: 5c86de06f.jpg | Classes present: tensor([0])\n",
            "Image: c63388081.jpg | Classes present: tensor([0])\n",
            "Image: ef21b3e57.jpg | Classes present: tensor([0])\n",
            "Image: 6c62c50e3.jpg | Classes present: tensor([0])\n",
            "Image: c15d5b333.jpg | Classes present: tensor([0])\n",
            "Image: 400eedff4.jpg | Classes present: tensor([0])\n",
            "Image: abab01f92.jpg | Classes present: tensor([0])\n",
            "Image: 8399a4300.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5da78dca1.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.004055664408951998\n",
            "Training Batch 298 - Positive pixels per class: [1455.    0. 2698.    0.]\n",
            "Output stats - Min: -16.109375, Max: 1.978515625\n",
            "Image: 1c32b8c83.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  60% 298/500 [00:57<00:32,  6.15it/s, Loss=0.0762]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.005180664360523224\n",
            "Training Batch 299 - Positive pixels per class: [   0.    0.    0. 5305.]\n",
            "Image: 43c1e8a0b.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.34375, Max: 1.80078125\n",
            "Image: eec244672.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  60% 298/500 [00:57<00:32,  6.15it/s, Loss=0.0804]Image: a6b56df05.jpg | Classes present: tensor([0])\n",
            "Image: b0348d794.jpg | Classes present: tensor([0])\n",
            "Image: 6d08d7ab4.jpg | Classes present: tensor([0, 2])\n",
            "Image: b8d2805f9.jpg | Classes present: tensor([0])\n",
            "Image: 3d25c4bad.jpg | Classes present: tensor([0])\n",
            "Image: 708c66026.jpg | Classes present: tensor([0])\n",
            "Image: 2e35ebe13.jpg | Classes present: tensor([0])\n",
            "Image: c248ca201.jpg | Classes present: tensor([0, 2])\n",
            "Image: a31bad68b.jpg | Classes present: tensor([0])\n",
            "Image: 5e88c8a04.jpg | Classes present: tensor([0])\n",
            "Image: d81f90b35.jpg | Classes present: tensor([0])\n",
            "Image: ab3fed191.jpg | Classes present: tensor([0])\n",
            "Image: 5ff129eb1.jpg | Classes present: tensor([0])\n",
            "Image: af09a0336.jpg | Classes present: tensor([0])\n",
            "Image: 57d157679.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.033378906548023224\n",
            "Training Batch 300 - Positive pixels per class: [    0.     0. 34180.     0.]\n",
            "Output stats - Min: -14.359375, Max: 2.84765625\n",
            "Image: 2d15d9135.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  60% 300/500 [00:57<00:31,  6.35it/s, Loss=0.0861]Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 301 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -16.234375, Max: 1.3173828125\n",
            "Image: a4844715b.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  60% 300/500 [00:57<00:31,  6.35it/s, Loss=0.0369]Image: 7fc8b1ce5.jpg | Classes present: tensor([0, 2])\n",
            "Image: 82b258bf4.jpg | Classes present: tensor([0])\n",
            "Image: 6ecfb9df5.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5ca7fcc19.jpg | Classes present: tensor([0])\n",
            "Image: 7063cb92d.jpg | Classes present: tensor([0])\n",
            "Image: 9622959c1.jpg | Classes present: tensor([0])\n",
            "Image: 85adaa491.jpg | Classes present: tensor([0])\n",
            "Image: 57cc4e2d3.jpg | Classes present: tensor([0])\n",
            "Image: 4b1d2a283.jpg | Classes present: tensor([0])\n",
            "Image: b9888ed87.jpg | Classes present: tensor([0])\n",
            "Image: d58a16a93.jpg | Classes present: tensor([0])\n",
            "Image: 64261b3f7.jpg | Classes present: tensor([0])\n",
            "Image: eabd4acaa.jpg | Classes present: tensor([0])\n",
            "Image: cbc860446.jpg | Classes present: tensor([0, 3])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.014767578803002834\n",
            "Training Batch 302 - Positive pixels per class: [   0.    0. 7427. 7695.]\n",
            "Image: e3143c8d2.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -14.5546875, Max: 2.693359375\n",
            "Image: 4e7f0e825.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  60% 302/500 [00:58<00:33,  5.92it/s, Loss=0.121]Image: 17383bd97.jpg | Classes present: tensor([0])\n",
            "Image: 5db4d2daa.jpg | Classes present: tensor([0])\n",
            "Image: 0d661ca68.jpg | Classes present: tensor([0])\n",
            "Image: 7ba14848e.jpg | Classes present: tensor([0])\n",
            "Image: eb44ad79d.jpg | Classes present: tensor([0])\n",
            "Image: 2f2053eff.jpg | Classes present: tensor([0])\n",
            "Image: 23b787894.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.008940430358052254\n",
            "Training Batch 303 - Positive pixels per class: [   0.    0. 9155.    0.]\n",
            "Output stats - Min: -13.8828125, Max: 1.7763671875\n",
            "Image: da0262fcf.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  61% 303/500 [00:58<00:34,  5.75it/s, Loss=0.0531]Image: 43f6a4177.jpg | Classes present: tensor([0, 3])\n",
            "Image: a0d19387f.jpg | Classes present: tensor([0])\n",
            "Image: 6c1118c1b.jpg | Classes present: tensor([0])\n",
            "Image: 29a023a11.jpg | Classes present: tensor([0])\n",
            "Image: 5b0413b89.jpg | Classes present: tensor([0])\n",
            "Image: b7ec604f7.jpg | Classes present: tensor([0])\n",
            "Image: 2dd290c91.jpg | Classes present: tensor([0])\n",
            "Image: e473f2647.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 304 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -15.03125, Max: 2.013671875\n",
            "Image: 130e11be6.jpg | Classes present: tensor([0])\n",
            "Image: b78629be2.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  61% 304/500 [00:58<00:37,  5.19it/s, Loss=0.0735]Image: 539be6ba4.jpg | Classes present: tensor([0])\n",
            "Image: 53fa72f86.jpg | Classes present: tensor([0])\n",
            "Image: 0bb304645.jpg | Classes present: tensor([0])\n",
            "Image: de79fa864.jpg | Classes present: tensor([0])\n",
            "Image: 6aadb8486.jpg | Classes present: tensor([0])\n",
            "Image: 9270f72ac.jpg | Classes present: tensor([0])\n",
            "Image: 90b51d4f7.jpg | Classes present: tensor([0, 2])\n",
            "Image: c7b41dbf4.jpg | Classes present: tensor([0])\n",
            "Image: 9f34c4775.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.009959961287677288\n",
            "Training Batch 305 - Positive pixels per class: [    0.     0.     0. 10199.]\n",
            "Output stats - Min: -15.15625, Max: 2.322265625\n",
            "Epoch 10/10:  61% 305/500 [00:58<00:42,  4.54it/s, Loss=0.0976]Image: a689f4047.jpg | Classes present: tensor([0])\n",
            "Image: 4dcb6f67a.jpg | Classes present: tensor([0])\n",
            "Image: db3ce9c95.jpg | Classes present: tensor([0])\n",
            "Image: bfd93cc8c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 927be944d.jpg | Classes present: tensor([0])\n",
            "Image: 9bfcca020.jpg | Classes present: tensor([0, 2])\n",
            "Image: 713f8ef91.jpg | Classes present: tensor([0])\n",
            "Image: 990d967ad.jpg | Classes present: tensor([0])\n",
            "Image: e12136afc.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.04466601833701134\n",
            "Training Batch 306 - Positive pixels per class: [    0.     0. 45738.     0.]\n",
            "Output stats - Min: -14.75, Max: 2.22265625\n",
            "Image: 720e3f026.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  61% 306/500 [00:59<00:45,  4.27it/s, Loss=0.0957]Image: 24fdedc37.jpg | Classes present: tensor([0])\n",
            "Image: 50cfeaca4.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8df207326.jpg | Classes present: tensor([0])\n",
            "Image: 53e812ced.jpg | Classes present: tensor([0])\n",
            "Image: 3325e2266.jpg | Classes present: tensor([0])\n",
            "Image: 57cb45ba8.jpg | Classes present: tensor([0, 2])\n",
            "Image: 14e90eb54.jpg | Classes present: tensor([0])\n",
            "Image: 01ebe0d32.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 307 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: c5ee627e2.jpg | Classes present: tensor([0])\n",
            "Image: 71553a0d8.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.1796875, Max: 1.3857421875\n",
            "Epoch 10/10:  61% 307/500 [00:59<00:47,  4.08it/s, Loss=0.0384]Image: ac5de187a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 7ea03b257.jpg | Classes present: tensor([0])\n",
            "Image: 0b5051d9f.jpg | Classes present: tensor([0])\n",
            "Image: c7755caf9.jpg | Classes present: tensor([0])\n",
            "Image: dc8e7690a.jpg | Classes present: tensor([0])\n",
            "Image: bd01b8daf.jpg | Classes present: tensor([0])\n",
            "Image: acbe1e2c1.jpg | Classes present: tensor([0])\n",
            "Image: 61e8a808c.jpg | Classes present: tensor([0])\n",
            "Image: 2999deba3.jpg | Classes present: tensor([0])\n",
            "Image: 5e581254c.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0137480478733778\n",
            "Training Batch 308 - Positive pixels per class: [    0.     0. 14078.     0.]\n",
            "Output stats - Min: -16.40625, Max: 2.619140625\n",
            "Image: cba39a205.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  62% 308/500 [00:59<00:49,  3.85it/s, Loss=0.0672]Image: e98ffbe3d.jpg | Classes present: tensor([0])\n",
            "Image: 0a8306bfe.jpg | Classes present: tensor([0])\n",
            "Image: 2cca3ddab.jpg | Classes present: tensor([0])\n",
            "Image: 0a26aceb2.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9a8c769b4.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.004165039397776127\n",
            "Training Batch 309 - Positive pixels per class: [   0.    0. 4265.    0.]\n",
            "Image: 115c02850.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -14.3515625, Max: 1.6083984375\n",
            "Epoch 10/10:  62% 309/500 [00:59<00:45,  4.20it/s, Loss=0.0511]Image: 5c8104408.jpg | Classes present: tensor([0])\n",
            "Image: 86063fcba.jpg | Classes present: tensor([0])\n",
            "Image: 3bde297da.jpg | Classes present: tensor([0])\n",
            "Image: b0038b54c.jpg | Classes present: tensor([0])\n",
            "Image: e93bfa412.jpg | Classes present: tensor([0])\n",
            "Image: 4eb8c6514.jpg | Classes present: tensor([0])\n",
            "Image: 6e4a1d647.jpg | Classes present: tensor([0])\n",
            "Image: 0849ea9f1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 08c2fc120.jpg | Classes present: tensor([0])\n",
            "Image: 6f45aa88d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 181d5197b.jpg | Classes present: tensor([0])\n",
            "Image: 94f2c7910.jpg | Classes present: tensor([0, 2])\n",
            "Image: c683195bf.jpg | Classes present: tensor([0])\n",
            "Image: 2c4fd555c.jpg | Classes present: tensor([0])\n",
            "Image: 0d17b6b4f.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.005252929870039225\n",
            "Training Batch 310 - Positive pixels per class: [   0.    0. 5379.    0.]\n",
            "Output stats - Min: -15.7890625, Max: 1.6220703125\n",
            "Image: 0832de752.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  62% 310/500 [01:00<00:56,  3.37it/s, Loss=0.0482]Image: a508dd004.jpg | Classes present: tensor([0])\n",
            "Image: b90f74ebe.jpg | Classes present: tensor([0, 2])\n",
            "Image: 76aba363e.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 311 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -16.953125, Max: 1.154296875\n",
            "Image: 764fa24b0.jpg | Classes present: tensor([0, 3])\n",
            "Epoch 10/10:  62% 311/500 [01:00<00:47,  4.02it/s, Loss=0.0546]Image: 7668b7312.jpg | Classes present: tensor([0])\n",
            "Image: 89f119c0a.jpg | Classes present: tensor([0])\n",
            "Image: 3463eedaf.jpg | Classes present: tensor([0])\n",
            "Image: 59c00ad1f.jpg | Classes present: tensor([0])\n",
            "Image: cbfeaed02.jpg | Classes present: tensor([0])\n",
            "Image: 9cd1d622e.jpg | Classes present: tensor([0])\n",
            "Image: 8f82d86db.jpg | Classes present: tensor([0])\n",
            "Image: 3c4d16b17.jpg | Classes present: tensor([0, 2])\n",
            "Image: dd9e0257b.jpg | Classes present: tensor([0])\n",
            "Image: 89087f994.jpg | Classes present: tensor([0])\n",
            "Image: 6de9ff56a.jpg | Classes present: tensor([0])\n",
            "Image: 1bf758d80.jpg | Classes present: tensor([0])\n",
            "Image: ab5717ad2.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.016307618468999863\n",
            "Training Batch 312 - Positive pixels per class: [  368.     0.  6032. 10299.]\n",
            "Output stats - Min: -16.296875, Max: 1.7890625\n",
            "Epoch 10/10:  62% 312/500 [01:00<00:53,  3.54it/s, Loss=0.129]Image: 0b7a4c9b9.jpg | Classes present: tensor([0])\n",
            "Image: 497d0a057.jpg | Classes present: tensor([0])\n",
            "Image: 2fe09e89a.jpg | Classes present: tensor([0])\n",
            "Image: c5f88471b.jpg | Classes present: tensor([0])\n",
            "Image: 66b5d6b19.jpg | Classes present: tensor([0])\n",
            "Image: 398ea43ed.jpg | Classes present: tensor([0])\n",
            "Image: af61c6bf8.jpg | Classes present: tensor([0])\n",
            "Image: adbe07a60.jpg | Classes present: tensor([0])\n",
            "Image: 0829af407.jpg | Classes present: tensor([0])\n",
            "Image: ac7b3fdd1.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0004277343978174031\n",
            "Training Batch 313 - Positive pixels per class: [438.   0.   0.   0.]\n",
            "Output stats - Min: -13.9296875, Max: 0.9794921875\n",
            "Epoch 10/10:  63% 313/500 [01:01<00:51,  3.62it/s, Loss=0.0442]Image: 31e86cf3a.jpg | Classes present: tensor([0])\n",
            "Image: 91b250f41.jpg | Classes present: tensor([0])\n",
            "Image: 7bec3eeb7.jpg | Classes present: tensor([0])\n",
            "Image: 41e79c2f4.jpg | Classes present: tensor([0])\n",
            "Image: 016af13d0.jpg | Classes present: tensor([0, 2])\n",
            "Image: c9d2f6b05.jpg | Classes present: tensor([0])\n",
            "Image: cb6fa8f89.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0858830b6.jpg | Classes present: tensor([0])\n",
            "Image: 700de40a7.jpg | Classes present: tensor([0])\n",
            "Image: bedfbcf7b.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 314 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -16.9375, Max: 1.10546875\n",
            "Image: 0bbd121d7.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  63% 314/500 [01:01<00:52,  3.55it/s, Loss=0.0416]Image: dfd8a544d.jpg | Classes present: tensor([0])\n",
            "Image: 4a52380d8.jpg | Classes present: tensor([0])\n",
            "Image: b895d1213.jpg | Classes present: tensor([0])\n",
            "Image: 4bd15a7ae.jpg | Classes present: tensor([0])\n",
            "Image: 5affd9802.jpg | Classes present: tensor([0])\n",
            "Image: 9e009a678.jpg | Classes present: tensor([0])\n",
            "Image: b7f84836b.jpg | Classes present: tensor([0])\n",
            "Image: 8726206f5.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.019098633900284767\n",
            "Training Batch 315 - Positive pixels per class: [    0.     0. 19557.     0.]\n",
            "Output stats - Min: -14.5078125, Max: 2.650390625\n",
            "Epoch 10/10:  63% 315/500 [01:01<00:50,  3.69it/s, Loss=0.0686]Image: 5952d06e5.jpg | Classes present: tensor([0])\n",
            "Image: e34f68168.jpg | Classes present: tensor([0])\n",
            "Image: 169bb9923.jpg | Classes present: tensor([0])\n",
            "Image: 11bf761dc.jpg | Classes present: tensor([0])\n",
            "Image: a8f977b31.jpg | Classes present: tensor([0])\n",
            "Image: 3860f3d39.jpg | Classes present: tensor([0, 3])\n",
            "Image: 0c495b1c8.jpg | Classes present: tensor([0])\n",
            "Image: 92ca72504.jpg | Classes present: tensor([0, 2])\n",
            "Image: 7c27585fd.jpg | Classes present: tensor([0])\n",
            "Image: 74ae351dd.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.004186523612588644\n",
            "Training Batch 316 - Positive pixels per class: [   0.    0. 1348. 2939.]\n",
            "Image: 93b2882fd.jpg | Classes present: tensor([0])\n",
            "Image: 85b8f9d06.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.1171875, Max: 2.23046875\n",
            "Image: 4e39d8c5c.jpg | Classes present: tensor([0])\n",
            "Image: ecb50399d.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  63% 316/500 [01:02<00:53,  3.41it/s, Loss=0.0632]Image: 8ef6dc341.jpg | Classes present: tensor([0])\n",
            "Image: 06b49e34f.jpg | Classes present: tensor([0])\n",
            "Image: bceeb4256.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0bfce2f41.jpg | Classes present: tensor([0, 2])\n",
            "Image: b6c567b64.jpg | Classes present: tensor([0])\n",
            "Image: 80de9f3e1.jpg | Classes present: tensor([0])\n",
            "Image: 5ba43097d.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.007315429858863354\n",
            "Training Batch 317 - Positive pixels per class: [   0.    0. 7491.    0.]\n",
            "Output stats - Min: -16.75, Max: 2.1640625\n",
            "Epoch 10/10:  63% 317/500 [01:02<00:48,  3.75it/s, Loss=0.0562]Image: ae5a0fa7c.jpg | Classes present: tensor([0])\n",
            "Image: 0728b2ac9.jpg | Classes present: tensor([0])\n",
            "Image: 621c5bfe5.jpg | Classes present: tensor([0])\n",
            "Image: 82aafd015.jpg | Classes present: tensor([0])\n",
            "Image: 8cb91efdd.jpg | Classes present: tensor([0])\n",
            "Image: 6d6a1fbe1.jpg | Classes present: tensor([0])\n",
            "Image: e5dfaf632.jpg | Classes present: tensor([0])\n",
            "Image: 9725a81d1.jpg | Classes present: tensor([0])\n",
            "Image: 8c504c51c.jpg | Classes present: tensor([0])\n",
            "Image: 726cff75f.jpg | Classes present: tensor([0])\n",
            "Image: bdb31300b.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.009218750521540642\n",
            "Training Batch 318 - Positive pixels per class: [   0.    0. 9440.    0.]\n",
            "Output stats - Min: -13.8671875, Max: 2.0625\n",
            "Image: d0328c686.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  64% 318/500 [01:02<00:45,  4.04it/s, Loss=0.0493]Image: d2c14891a.jpg | Classes present: tensor([0])\n",
            "Image: 9424f9664.jpg | Classes present: tensor([0])\n",
            "Image: d4c8f8461.jpg | Classes present: tensor([0])\n",
            "Image: 0ec69ca92.jpg | Classes present: tensor([0])\n",
            "Image: b7a2b2275.jpg | Classes present: tensor([0])\n",
            "Image: 039577d49.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 319 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -16.140625, Max: 0.98046875\n",
            "Image: 204949166.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  64% 319/500 [01:02<00:38,  4.70it/s, Loss=0.0395]Image: e7634e770.jpg | Classes present: tensor([0, 2])\n",
            "Image: 765876b94.jpg | Classes present: tensor([0])\n",
            "Image: a6ecee828.jpg | Classes present: tensor([0])\n",
            "Image: 95a8e91c4.jpg | Classes present: tensor([0])\n",
            "Image: b12fc900b.jpg | Classes present: tensor([0])\n",
            "Image: d9d9f2b25.jpg | Classes present: tensor([0])\n",
            "Image: dc4c76517.jpg | Classes present: tensor([0])\n",
            "Image: c9091ca20.jpg | Classes present: tensor([0])\n",
            "Image: 3c8312241.jpg | Classes present: tensor([0])\n",
            "Image: 8ebd4074a.jpg | Classes present: tensor([0])\n",
            "Image: 6ba94954a.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.009564453735947609\n",
            "Training Batch 320 - Positive pixels per class: [   0.    0. 9794.    0.]\n",
            "Image: 4b6e6a56e.jpg | Classes present: tensor([0])\n",
            "Image: c70702ea2.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -18.28125, Max: 2.375\n",
            "Epoch 10/10:  64% 320/500 [01:02<00:39,  4.61it/s, Loss=0.0541]Image: 0281aba7b.jpg | Classes present: tensor([0])\n",
            "Image: e2abceace.jpg | Classes present: tensor([0, 2])\n",
            "Image: d588537b9.jpg | Classes present: tensor([0])\n",
            "Image: 83d2fffd3.jpg | Classes present: tensor([0])\n",
            "Image: a44dd8116.jpg | Classes present: tensor([0])\n",
            "Image: ae7a2de0d.jpg | Classes present: tensor([0])\n",
            "Image: e15a18c3e.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 321 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -16.375, Max: 1.08203125\n",
            "Image: 83ba89ac3.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  64% 321/500 [01:02<00:35,  5.05it/s, Loss=0.041]Image: 29ff8d6f4.jpg | Classes present: tensor([0])\n",
            "Image: cd835f121.jpg | Classes present: tensor([0])\n",
            "Image: 6bd87aed9.jpg | Classes present: tensor([0])\n",
            "Image: 6c9f54be2.jpg | Classes present: tensor([0])\n",
            "Image: cdbc80c3d.jpg | Classes present: tensor([0])\n",
            "Image: 3abba0c59.jpg | Classes present: tensor([0])\n",
            "Image: 10378f8ea.jpg | Classes present: tensor([0])\n",
            "Image: 57e6b1bcd.jpg | Classes present: tensor([0])\n",
            "Image: cb0ac6c6f.jpg | Classes present: tensor([0])\n",
            "Image: 72df2d40d.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0036562501918524504\n",
            "Training Batch 322 - Positive pixels per class: [   0.    0. 3744.    0.]\n",
            "Output stats - Min: -15.71875, Max: 1.8740234375\n",
            "Epoch 10/10:  64% 322/500 [01:03<00:34,  5.12it/s, Loss=0.0482]Image: b3d4c7809.jpg | Classes present: tensor([0])\n",
            "Image: 8b4bb1228.jpg | Classes present: tensor([0])\n",
            "Image: a97d3a84e.jpg | Classes present: tensor([0])\n",
            "Image: 09323504a.jpg | Classes present: tensor([0])\n",
            "Image: b66e36656.jpg | Classes present: tensor([0])\n",
            "Image: aa6bd6ba3.jpg | Classes present: tensor([0])\n",
            "Image: 5956f0975.jpg | Classes present: tensor([0])\n",
            "Image: 2f6858a91.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 323 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -18.46875, Max: 0.982421875\n",
            "Image: 15e21dfad.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  65% 323/500 [01:03<00:32,  5.53it/s, Loss=0.0363]Image: 75e84fb14.jpg | Classes present: tensor([0])\n",
            "Image: 077f0256d.jpg | Classes present: tensor([0])\n",
            "Image: 61f93524d.jpg | Classes present: tensor([0])\n",
            "Image: 7a8fcc7df.jpg | Classes present: tensor([0, 2])\n",
            "Image: c26912861.jpg | Classes present: tensor([0])\n",
            "Image: 0f4a022fd.jpg | Classes present: tensor([0])\n",
            "Image: b5b6de778.jpg | Classes present: tensor([0])\n",
            "Image: 9e467cb05.jpg | Classes present: tensor([0, 2])\n",
            "Image: 764275950.jpg | Classes present: tensor([0])\n",
            "Image: a3a66a86a.jpg | Classes present: tensor([0])\n",
            "Image: 4cf3b3988.jpg | Classes present: tensor([0])\n",
            "Image: 3088a6a0d.jpg | Classes present: tensor([0, 1])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 324 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -16.5625, Max: 1.0341796875\n",
            "Image: 005f19695.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  65% 324/500 [01:03<00:33,  5.26it/s, Loss=0.0665]Image: 6ab70e8cb.jpg | Classes present: tensor([0])\n",
            "Image: 622808ac3.jpg | Classes present: tensor([0])\n",
            "Image: 56774fb7f.jpg | Classes present: tensor([0])\n",
            "Image: 02b906933.jpg | Classes present: tensor([0])\n",
            "Image: 66c487b25.jpg | Classes present: tensor([0])\n",
            "Image: 5ff5438f5.jpg | Classes present: tensor([0])\n",
            "Image: 0bb39cafa.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0201113298535347\n",
            "Training Batch 325 - Positive pixels per class: [ 1167.     0. 19427.     0.]\n",
            "Output stats - Min: -17.203125, Max: 2.267578125\n",
            "Image: 2f390008f.jpg | Classes present: tensor([0])\n",
            "Image: e4c74d00a.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  65% 325/500 [01:03<00:29,  5.85it/s, Loss=0.0929]Image: 0905fe055.jpg | Classes present: tensor([0])\n",
            "Image: 7e8dfabba.jpg | Classes present: tensor([0])\n",
            "Image: 83f88d92e.jpg | Classes present: tensor([0])\n",
            "Image: 03860f6a9.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6355bf572.jpg | Classes present: tensor([0])\n",
            "Image: 00f1665e6.jpg | Classes present: tensor([0])\n",
            "Image: 121d3818a.jpg | Classes present: tensor([0, 2])\n",
            "Image: c8e26e892.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.005693359766155481\n",
            "Training Batch 326 - Positive pixels per class: [   0. 1115. 4715.    0.]\n",
            "Output stats - Min: -15.0390625, Max: 1.7744140625\n",
            "Epoch 10/10:  65% 326/500 [01:03<00:29,  5.93it/s, Loss=0.0807]Image: ed3276a76.jpg | Classes present: tensor([0])\n",
            "Image: 8c8914931.jpg | Classes present: tensor([0])\n",
            "Image: b9f8dffba.jpg | Classes present: tensor([0])\n",
            "Image: 9c1b65eb2.jpg | Classes present: tensor([0])\n",
            "Image: 620568126.jpg | Classes present: tensor([0])\n",
            "Image: b646b6038.jpg | Classes present: tensor([0, 3])\n",
            "Image: 423caf51d.jpg | Classes present: tensor([0])\n",
            "Image: b69920a15.jpg | Classes present: tensor([0])\n",
            "Image: 22e05d569.jpg | Classes present: tensor([0])\n",
            "Image: 04fa19d59.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.001657226588577032\n",
            "Training Batch 327 - Positive pixels per class: [   0.    0. 1697.    0.]\n",
            "Image: 3b8d1d356.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.140625, Max: 1.4482421875\n",
            "Image: 62b81735c.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  65% 327/500 [01:03<00:28,  5.97it/s, Loss=0.0556]Image: 68656ca18.jpg | Classes present: tensor([0])\n",
            "Image: 5cc47b140.jpg | Classes present: tensor([0])\n",
            "Image: bba274c50.jpg | Classes present: tensor([0])\n",
            "Image: 8eb422b05.jpg | Classes present: tensor([0])\n",
            "Image: 92932546c.jpg | Classes present: tensor([0])\n",
            "Image: 7ed64642e.jpg | Classes present: tensor([0, 2])\n",
            "Image: c38e52b4a.jpg | Classes present: tensor([0])\n",
            "Image: a9914e83b.jpg | Classes present: tensor([0])\n",
            "Image: 910127691.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.01787402480840683\n",
            "Training Batch 328 - Positive pixels per class: [    0.     0.  3808. 14495.]\n",
            "Output stats - Min: -18.4375, Max: 2.03515625\n",
            "Image: babc63c5b.jpg | Classes present: tensor([0])\n",
            "Image: a57369d47.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  66% 328/500 [01:04<00:29,  5.78it/s, Loss=0.139]Image: ee44ebd2f.jpg | Classes present: tensor([0])\n",
            "Image: 6d7bc57d2.jpg | Classes present: tensor([0])\n",
            "Image: ed94e8b34.jpg | Classes present: tensor([0])\n",
            "Image: dfe79ed0f.jpg | Classes present: tensor([0])\n",
            "Image: 73ebd716c.jpg | Classes present: tensor([0])\n",
            "Image: 3266ff34d.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 329 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -17.046875, Max: 0.92822265625\n",
            "Image: 7cb5bd6f1.jpg | Classes present: tensor([0])\n",
            "Image: 25ba4dfae.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  66% 329/500 [01:04<00:28,  6.00it/s, Loss=0.0357]Image: 7a8a7403c.jpg | Classes present: tensor([0])\n",
            "Image: b3aa31a86.jpg | Classes present: tensor([0, 2])\n",
            "Image: 7a32eba62.jpg | Classes present: tensor([0])\n",
            "Image: e4547788b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 86226216f.jpg | Classes present: tensor([0])\n",
            "Image: 5bbd809c4.jpg | Classes present: tensor([0])\n",
            "Image: 4f89dd316.jpg | Classes present: tensor([0])\n",
            "Image: 6bedba903.jpg | Classes present: tensor([0])\n",
            "Image: 102ac71fd.jpg | Classes present: tensor([0])\n",
            "Image: 4f1f6dee0.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.02246386744081974\n",
            "Training Batch 330 - Positive pixels per class: [    0.     0. 23003.     0.]\n",
            "Output stats - Min: -14.203125, Max: 2.224609375\n",
            "Image: b1b94f0fc.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  66% 330/500 [01:04<00:29,  5.78it/s, Loss=0.102]Image: c167117c8.jpg | Classes present: tensor([0])\n",
            "Image: a8cd71412.jpg | Classes present: tensor([0])\n",
            "Image: e7ced5b76.jpg | Classes present: tensor([0])\n",
            "Image: be2216e98.jpg | Classes present: tensor([0])\n",
            "Image: 820c4f78c.jpg | Classes present: tensor([0])\n",
            "Image: ce4d5f713.jpg | Classes present: tensor([0])\n",
            "Image: c720250a2.jpg | Classes present: tensor([0])\n",
            "Image: c1a90e9c8.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.028584962710738182\n",
            "Training Batch 331 - Positive pixels per class: [    0.     0. 29271.     0.]\n",
            "Image: b86c963d6.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.7890625, Max: 2.1875\n",
            "Image: 990195c76.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  66% 331/500 [01:04<00:26,  6.30it/s, Loss=0.0887]Image: 1be84c6a7.jpg | Classes present: tensor([0])\n",
            "Image: 636852a01.jpg | Classes present: tensor([0])\n",
            "Image: 24884c39c.jpg | Classes present: tensor([0])\n",
            "Image: 7eacbdb66.jpg | Classes present: tensor([0, 2])\n",
            "Image: 71b1e90a5.jpg | Classes present: tensor([0])\n",
            "Image: 20bb27a04.jpg | Classes present: tensor([0, 1])\n",
            "Image: a3e2c4510.jpg | Classes present: tensor([0])\n",
            "Image: 037fca267.jpg | Classes present: tensor([0])\n",
            "Image: b24d691a6.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.017557617276906967\n",
            "Training Batch 332 - Positive pixels per class: [    0.  2175. 15804.     0.]\n",
            "Image: bfe025097.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.234375, Max: 2.615234375\n",
            "Epoch 10/10:  66% 332/500 [01:04<00:27,  6.08it/s, Loss=0.142]Image: 5f11a4623.jpg | Classes present: tensor([0])\n",
            "Image: ee0ad947e.jpg | Classes present: tensor([0])\n",
            "Image: 534c4e0c8.jpg | Classes present: tensor([0])\n",
            "Image: 5cc70cbdb.jpg | Classes present: tensor([0, 3])\n",
            "Image: 65b01c557.jpg | Classes present: tensor([0])\n",
            "Image: 8066b7589.jpg | Classes present: tensor([0])\n",
            "Image: 3e1ed281b.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.003209961112588644\n",
            "Training Batch 333 - Positive pixels per class: [   0.    0.    0. 3287.]\n",
            "Image: 86752d23a.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -14.546875, Max: 1.6923828125\n",
            "Image: 5f39f57ea.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  67% 333/500 [01:04<00:26,  6.23it/s, Loss=0.0682]Image: 679f4601f.jpg | Classes present: tensor([0])\n",
            "Image: 58673aa89.jpg | Classes present: tensor([0])\n",
            "Image: 56de9f0d1.jpg | Classes present: tensor([0])\n",
            "Image: b05365219.jpg | Classes present: tensor([0])\n",
            "Image: 66987e071.jpg | Classes present: tensor([0])\n",
            "Image: 05a024a74.jpg | Classes present: tensor([0])\n",
            "Image: 192531334.jpg | Classes present: tensor([0])\n",
            "Image: 801887861.jpg | Classes present: tensor([0])\n",
            "Image: 410194f0a.jpg | Classes present: tensor([0, 2])\n",
            "Image: e4d9efbaa.jpg | Classes present: tensor([0])\n",
            "Image: 1a20361c3.jpg | Classes present: tensor([0])\n",
            "Image: 0ebdc1277.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.001111328136175871\n",
            "Training Batch 334 - Positive pixels per class: [   0.    0. 1138.    0.]\n",
            "Output stats - Min: -18.765625, Max: 1.71875\n",
            "Image: d56eec590.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  67% 334/500 [01:05<00:29,  5.60it/s, Loss=0.04]Image: 27f44281b.jpg | Classes present: tensor([0])\n",
            "Image: eedbd0c92.jpg | Classes present: tensor([0])\n",
            "Image: 5a1b1601e.jpg | Classes present: tensor([0])\n",
            "Image: c3206fb3c.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 335 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: 195c2e0d0.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -13.1875, Max: 1.7568359375\n",
            "Image: 20edbd1a8.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  67% 335/500 [01:05<00:25,  6.40it/s, Loss=0.0533]Image: 8d909a69d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1017c52e8.jpg | Classes present: tensor([0])\n",
            "Image: 8ea10e67e.jpg | Classes present: tensor([0, 2])\n",
            "Image: a6ba6acf0.jpg | Classes present: tensor([0])\n",
            "Image: 5ea7bbf5f.jpg | Classes present: tensor([0])\n",
            "Image: 896f852dd.jpg | Classes present: tensor([0])\n",
            "Image: a7e675896.jpg | Classes present: tensor([0])\n",
            "Image: 6eb148407.jpg | Classes present: tensor([0])\n",
            "Image: e0eade7b1.jpg | Classes present: tensor([0])\n",
            "Image: 3cafcfd96.jpg | Classes present: tensor([0])\n",
            "Image: 8b9681587.jpg | Classes present: tensor([0, 2])\n",
            "Image: c7b88e40a.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.00045507814502343535\n",
            "Training Batch 336 - Positive pixels per class: [  0.   0. 466.   0.]\n",
            "Output stats - Min: -16.0625, Max: 1.1396484375\n",
            "Image: 4e438c98c.jpg | Classes present: tensor([0])\n",
            "Image: ec921fcc7.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  67% 336/500 [01:05<00:29,  5.58it/s, Loss=0.0496]Image: 5a752f8cd.jpg | Classes present: tensor([0])\n",
            "Image: be4279ae1.jpg | Classes present: tensor([0, 2])\n",
            "Image: d3369b607.jpg | Classes present: tensor([0])\n",
            "Image: 89158744a.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.009430664591491222\n",
            "Training Batch 337 - Positive pixels per class: [   0.    0. 9657.    0.]\n",
            "Output stats - Min: -15.859375, Max: 1.978515625\n",
            "Image: 69231176e.jpg | Classes present: tensor([0])\n",
            "Image: 659985985.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  67% 337/500 [01:05<00:26,  6.20it/s, Loss=0.063]Image: a4e947fb4.jpg | Classes present: tensor([0, 2])\n",
            "Image: 503c4f93a.jpg | Classes present: tensor([0])\n",
            "Image: 329de935b.jpg | Classes present: tensor([0])\n",
            "Image: c487b1ce1.jpg | Classes present: tensor([0])\n",
            "Image: b963c168c.jpg | Classes present: tensor([0])\n",
            "Image: d65b30b32.jpg | Classes present: tensor([0, 2])\n",
            "Image: dc3740c5c.jpg | Classes present: tensor([0])\n",
            "Image: 1bea66c7a.jpg | Classes present: tensor([0])\n",
            "Image: 2969217e8.jpg | Classes present: tensor([0])\n",
            "Image: 06b384e78.jpg | Classes present: tensor([0])\n",
            "Image: b89490249.jpg | Classes present: tensor([0])\n",
            "Image: 570cb5438.jpg | Classes present: tensor([0])\n",
            "Image: b7e90de47.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0038837892934679985\n",
            "Training Batch 338 - Positive pixels per class: [   0.    0. 3977.    0.]\n",
            "Output stats - Min: -18.25, Max: 1.9609375\n",
            "Image: 3932751f1.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  68% 338/500 [01:05<00:28,  5.73it/s, Loss=0.0743]Image: c873d7724.jpg | Classes present: tensor([0, 2])\n",
            "Image: dc702eb04.jpg | Classes present: tensor([0])\n",
            "Image: a41ba727f.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.02501758001744747\n",
            "Training Batch 339 - Positive pixels per class: [    0.     0. 25618.     0.]\n",
            "Output stats - Min: -15.234375, Max: 3.244140625\n",
            "Image: 139b7e692.jpg | Classes present: tensor([0])\n",
            "Image: 2b53843e0.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  68% 338/500 [01:05<00:28,  5.73it/s, Loss=0.0762]Image: 156a74a49.jpg | Classes present: tensor([0, 1])\n",
            "Image: 3fb78d513.jpg | Classes present: tensor([0])\n",
            "Image: 30f6cb778.jpg | Classes present: tensor([0, 3])\n",
            "Image: a1d0b7617.jpg | Classes present: tensor([0])\n",
            "Image: 8981c24c8.jpg | Classes present: tensor([0])\n",
            "Image: b1e3c11ad.jpg | Classes present: tensor([0])\n",
            "Image: 685b767f1.jpg | Classes present: tensor([0])\n",
            "Image: e1a9e7c49.jpg | Classes present: tensor([0, 3])\n",
            "Image: b641f8ae5.jpg | Classes present: tensor([0])\n",
            "Image: 628aaf2df.jpg | Classes present: tensor([0])\n",
            "Image: 6bf2151b8.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1dba99dc5.jpg | Classes present: tensor([0, 2])\n",
            "Image: 7249ae1f4.jpg | Classes present: tensor([0])\n",
            "Image: e0eefb4a2.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.041951172053813934\n",
            "Training Batch 340 - Positive pixels per class: [    0.  3200. 24265. 15493.]\n",
            "Image: 1be849dd0.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.6875, Max: 2.6171875\n",
            "Image: 0e0377ffa.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  68% 340/500 [01:06<00:28,  5.55it/s, Loss=0.252]Image: 9be9c98eb.jpg | Classes present: tensor([0])\n",
            "Image: 299a15c20.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.033380862325429916\n",
            "Training Batch 341 - Positive pixels per class: [    0.     0. 21386. 12796.]\n",
            "Image: 0c2522533.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -14.9609375, Max: 2.0\n",
            "Image: 05396b495.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  68% 340/500 [01:06<00:28,  5.55it/s, Loss=0.184]Image: 77c387f3b.jpg | Classes present: tensor([0])\n",
            "Image: 5b1e3d933.jpg | Classes present: tensor([0])\n",
            "Image: aea1eb689.jpg | Classes present: tensor([0])\n",
            "Image: 8d0addbbc.jpg | Classes present: tensor([0])\n",
            "Image: c30efa47d.jpg | Classes present: tensor([0])\n",
            "Image: cb9c3d622.jpg | Classes present: tensor([0])\n",
            "Image: 4e2c9230d.jpg | Classes present: tensor([0])\n",
            "Image: be6c49e45.jpg | Classes present: tensor([0])\n",
            "Image: 3a43adb32.jpg | Classes present: tensor([0])\n",
            "Image: 1fc012f23.jpg | Classes present: tensor([0])\n",
            "Image: 373daa632.jpg | Classes present: tensor([0, 2])\n",
            "Image: 397c6e139.jpg | Classes present: tensor([0])\n",
            "Image: ea5c8ec19.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 342 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -16.90625, Max: 1.306640625\n",
            "Image: 382b517ee.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  68% 342/500 [01:06<00:26,  6.01it/s, Loss=0.0449]Image: 002af848d.jpg | Classes present: tensor([0])\n",
            "Image: 941e9a9d6.jpg | Classes present: tensor([0])\n",
            "Image: 17fa32126.jpg | Classes present: tensor([0])\n",
            "Image: d1aaada08.jpg | Classes present: tensor([0])\n",
            "Image: 7998298c2.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.006761719007045031\n",
            "Training Batch 343 - Positive pixels per class: [   0.    0. 6924.    0.]\n",
            "Image: 25ba4dfae.jpg | Classes present: tensor([0])\n",
            "Image: 44a2e6e51.jpg | Classes present: tensor([0, 3])\n",
            "Output stats - Min: -15.484375, Max: 2.08984375\n",
            "Epoch 10/10:  69% 343/500 [01:06<00:24,  6.34it/s, Loss=0.0449]Image: a0a34a07c.jpg | Classes present: tensor([0])\n",
            "Image: 7e9778a9f.jpg | Classes present: tensor([0])\n",
            "Image: c5615e977.jpg | Classes present: tensor([0])\n",
            "Image: 1b7669eb4.jpg | Classes present: tensor([0])\n",
            "Image: d5d024e03.jpg | Classes present: tensor([0])\n",
            "Image: 06713b712.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1860df762.jpg | Classes present: tensor([0])\n",
            "Image: a9108753d.jpg | Classes present: tensor([0, 2])\n",
            "Image: ac550233a.jpg | Classes present: tensor([0])\n",
            "Image: 30171214c.jpg | Classes present: tensor([0, 2])\n",
            "Image: dcc2e4f93.jpg | Classes present: tensor([0])\n",
            "Image: 71e55c4e5.jpg | Classes present: tensor([0])\n",
            "Image: 23c3474fb.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.016361329704523087\n",
            "Training Batch 344 - Positive pixels per class: [   0.    0. 8760. 7994.]\n",
            "Output stats - Min: -14.875, Max: 1.533203125\n",
            "Image: 73303e8a0.jpg | Classes present: tensor([0])\n",
            "Image: 5c8c555a3.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  69% 344/500 [01:06<00:26,  5.94it/s, Loss=0.116]Image: 2694c98fb.jpg | Classes present: tensor([0])\n",
            "Image: d37fb426f.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 345 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -16.4375, Max: 0.943359375\n",
            "Image: a3148f47c.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  69% 344/500 [01:06<00:26,  5.94it/s, Loss=0.0359]Image: d5425f5f5.jpg | Classes present: tensor([0])\n",
            "Image: 1e4aaae3e.jpg | Classes present: tensor([0])\n",
            "Image: 6143631ab.jpg | Classes present: tensor([0])\n",
            "Image: 5b9f92d00.jpg | Classes present: tensor([0])\n",
            "Image: cd8c479c1.jpg | Classes present: tensor([0])\n",
            "Image: c44784905.jpg | Classes present: tensor([0])\n",
            "Image: b045a0df2.jpg | Classes present: tensor([0])\n",
            "Image: e195c6b17.jpg | Classes present: tensor([0])\n",
            "Image: b12e436c3.jpg | Classes present: tensor([0])\n",
            "Image: ad8ffec02.jpg | Classes present: tensor([0])\n",
            "Image: 8345249a8.jpg | Classes present: tensor([0])\n",
            "Image: 41f3899a5.jpg | Classes present: tensor([0])\n",
            "Image: 21365e1a3.jpg | Classes present: tensor([0])\n",
            "Image: 277e3727f.jpg | Classes present: tensor([0])\n",
            "Image: a9107b3b6.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 346 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -15.3046875, Max: 1.2763671875\n",
            "Image: 4157934a2.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  69% 346/500 [01:07<00:25,  5.93it/s, Loss=0.0384]Image: 2f6c4d0e7.jpg | Classes present: tensor([0])\n",
            "Image: 07c8c77a3.jpg | Classes present: tensor([0])\n",
            "Image: 7a961ae18.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.00537402369081974\n",
            "Training Batch 347 - Positive pixels per class: [   0.    0. 5503.    0.]\n",
            "Image: 3c5e34bfa.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -19.484375, Max: 2.2578125\n",
            "Image: 2c113de25.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  69% 346/500 [01:07<00:25,  5.93it/s, Loss=0.0564]Image: 0148e9891.jpg | Classes present: tensor([0])\n",
            "Image: 93851869f.jpg | Classes present: tensor([0, 2])\n",
            "Image: c98404d89.jpg | Classes present: tensor([0])\n",
            "Image: 3f7e10763.jpg | Classes present: tensor([0])\n",
            "Image: b0254cb54.jpg | Classes present: tensor([0])\n",
            "Image: 959218299.jpg | Classes present: tensor([0])\n",
            "Image: 522e17d3e.jpg | Classes present: tensor([0])\n",
            "Image: 92932546c.jpg | Classes present: tensor([0])\n",
            "Image: 22a825813.jpg | Classes present: tensor([0])\n",
            "Image: e880e3468.jpg | Classes present: tensor([0])\n",
            "Image: c635aeb23.jpg | Classes present: tensor([0])\n",
            "Image: a470f2761.jpg | Classes present: tensor([0])\n",
            "Image: 8f4a566fb.jpg | Classes present: tensor([0])\n",
            "Image: 049bad998.jpg | Classes present: tensor([0, 2])\n",
            "Image: c1422b149.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.007968750782310963\n",
            "Training Batch 348 - Positive pixels per class: [   0.    0. 8160.    0.]\n",
            "Image: 6bf94eea0.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.921875, Max: 2.484375\n",
            "Image: 1ab7b5ed2.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  70% 348/500 [01:07<00:25,  5.85it/s, Loss=0.0474]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.00491796899586916\n",
            "Training Batch 349 - Positive pixels per class: [ 259.    0. 4777.    0.]\n",
            "Image: 5cf1c8814.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.03125, Max: 1.4931640625\n",
            "Epoch 10/10:  70% 348/500 [01:07<00:25,  5.85it/s, Loss=0.0469]Image: 51ee8ec48.jpg | Classes present: tensor([0])\n",
            "Image: e690329c1.jpg | Classes present: tensor([0])\n",
            "Image: b1b3ec5fd.jpg | Classes present: tensor([0])\n",
            "Image: 42ef7e425.jpg | Classes present: tensor([0])\n",
            "Image: 084e8ba74.jpg | Classes present: tensor([0, 2])\n",
            "Image: 556c2967b.jpg | Classes present: tensor([0])\n",
            "Image: 802de5801.jpg | Classes present: tensor([0])\n",
            "Image: 531b9c425.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0e232ce72.jpg | Classes present: tensor([0])\n",
            "Image: a2cb5be8f.jpg | Classes present: tensor([0])\n",
            "Image: d61dca6c7.jpg | Classes present: tensor([0])\n",
            "Image: 8da886dcf.jpg | Classes present: tensor([0])\n",
            "Image: b595566b3.jpg | Classes present: tensor([0])\n",
            "Image: b6656880b.jpg | Classes present: tensor([0])\n",
            "Image: cf06584db.jpg | Classes present: tensor([0])\n",
            "Image: 0d3d0dbf2.jpg | Classes present: tensor([0])\n",
            "Image: 476efaa3d.jpg | Classes present: tensor([0])\n",
            "Image: 5c0f7c72d.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.007767578586935997\n",
            "Training Batch 350 - Positive pixels per class: [   0.    0. 7954.    0.]\n",
            "Output stats - Min: -14.53125, Max: 2.251953125\n",
            "Image: e2bdd4236.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  70% 350/500 [01:07<00:25,  5.83it/s, Loss=0.0546]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0010048828553408384\n",
            "Training Batch 351 - Positive pixels per class: [   0.    0. 1029.    0.]\n",
            "Image: b0a1cec01.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.109375, Max: 1.0517578125\n",
            "Epoch 10/10:  70% 350/500 [01:07<00:25,  5.83it/s, Loss=0.0399]Image: 49b34e921.jpg | Classes present: tensor([0])\n",
            "Image: 3bbab6db6.jpg | Classes present: tensor([0])\n",
            "Image: 1f9b8e2e6.jpg | Classes present: tensor([0, 2])\n",
            "Image: e8814afd2.jpg | Classes present: tensor([0])\n",
            "Image: 84edf7afb.jpg | Classes present: tensor([0])\n",
            "Image: 5574a47da.jpg | Classes present: tensor([0])\n",
            "Image: 3d0fc6499.jpg | Classes present: tensor([0])\n",
            "Image: 64dc9ef9a.jpg | Classes present: tensor([0, 2])\n",
            "Image: c448a41ee.jpg | Classes present: tensor([0])\n",
            "Image: cff9230ae.jpg | Classes present: tensor([0])\n",
            "Image: a56d4b7be.jpg | Classes present: tensor([0])\n",
            "Image: 8dce4f71f.jpg | Classes present: tensor([0])\n",
            "Image: 48f6abec0.jpg | Classes present: tensor([0])\n",
            "Image: 3035a46b7.jpg | Classes present: tensor([0])\n",
            "Image: 2d1658337.jpg | Classes present: tensor([0])\n",
            "Image: 9ddbb8f42.jpg | Classes present: tensor([0])\n",
            "Image: 2de22f59f.jpg | Classes present: tensor([0])\n",
            "Image: cc7920c72.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 352 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -19.46875, Max: 1.2021484375\n",
            "Image: a1dba4777.jpg | Classes present: tensor([0])\n",
            "Image: c85ed5c64.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  70% 352/500 [01:08<00:25,  5.85it/s, Loss=0.0315]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.006049804855138063\n",
            "Training Batch 353 - Positive pixels per class: [   0.    0. 6195.    0.]\n",
            "Output stats - Min: -15.7421875, Max: 1.384765625\n",
            "Image: 68c9524d6.jpg | Classes present: tensor([0])\n",
            "Image: cdf669a1f.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  70% 352/500 [01:08<00:25,  5.85it/s, Loss=0.0464]Image: 1c96b0bbc.jpg | Classes present: tensor([0])\n",
            "Image: 5dd5484fc.jpg | Classes present: tensor([0, 2])\n",
            "Image: 447d8ce19.jpg | Classes present: tensor([0])\n",
            "Image: a5b53e614.jpg | Classes present: tensor([0, 2])\n",
            "Image: 39c094b3d.jpg | Classes present: tensor([0])\n",
            "Image: ba3fd31de.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1755b86e4.jpg | Classes present: tensor([0])\n",
            "Image: dd172eb82.jpg | Classes present: tensor([0])\n",
            "Image: 0603c2340.jpg | Classes present: tensor([0])\n",
            "Image: 49d28224c.jpg | Classes present: tensor([0])\n",
            "Image: 1e4e988cd.jpg | Classes present: tensor([0])\n",
            "Image: c2d0a2e19.jpg | Classes present: tensor([0])\n",
            "Image: 4b9eb5d64.jpg | Classes present: tensor([0])\n",
            "Image: a1c385029.jpg | Classes present: tensor([0])\n",
            "Image: 9c4c38dab.jpg | Classes present: tensor([0])\n",
            "Image: bf828b30d.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0021738281939178705\n",
            "Training Batch 354 - Positive pixels per class: [   0.    0. 2226.    0.]\n",
            "Image: 02d573611.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.984375, Max: 1.7705078125\n",
            "Image: bd794618f.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  71% 354/500 [01:08<00:24,  5.88it/s, Loss=0.0483]Image: c2bce72b1.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.006170898675918579\n",
            "Training Batch 355 - Positive pixels per class: [   0.    0. 6319.    0.]\n",
            "Output stats - Min: -18.984375, Max: 2.357421875\n",
            "Epoch 10/10:  71% 354/500 [01:08<00:24,  5.88it/s, Loss=0.0564]Image: e013286ef.jpg | Classes present: tensor([0])\n",
            "Image: 6791c36e9.jpg | Classes present: tensor([0, 1])\n",
            "Image: d422920e3.jpg | Classes present: tensor([0])\n",
            "Image: 0b6cc9daa.jpg | Classes present: tensor([0])\n",
            "Image: 711e49f96.jpg | Classes present: tensor([0])\n",
            "Image: 5b334d4db.jpg | Classes present: tensor([0])\n",
            "Image: d8aeec2d5.jpg | Classes present: tensor([0])\n",
            "Image: 9b2801e98.jpg | Classes present: tensor([0])\n",
            "Image: 3d40be6af.jpg | Classes present: tensor([0])\n",
            "Image: c3a93c97a.jpg | Classes present: tensor([0])\n",
            "Image: 93b0d8e2f.jpg | Classes present: tensor([0])\n",
            "Image: 179b27647.jpg | Classes present: tensor([0])\n",
            "Image: e30a322d7.jpg | Classes present: tensor([0])\n",
            "Image: 81ff630e3.jpg | Classes present: tensor([0])\n",
            "Image: 75f92b24f.jpg | Classes present: tensor([0])\n",
            "Image: d7c560ed5.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.009808594360947609\n",
            "Training Batch 356 - Positive pixels per class: [ 403. 9641.    0.    0.]\n",
            "Output stats - Min: -15.515625, Max: 1.794921875\n",
            "Image: 6b6a070d0.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  71% 356/500 [01:08<00:23,  6.15it/s, Loss=0.469]Image: 9dfb319cc.jpg | Classes present: tensor([0])\n",
            "Image: cf4008024.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 357 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -18.125, Max: 0.9609375\n",
            "Image: dee367c77.jpg | Classes present: tensor([0])\n",
            "Image: 2ccef61c3.jpg | Classes present: tensor([0, 3])\n",
            "Epoch 10/10:  71% 356/500 [01:08<00:23,  6.15it/s, Loss=0.0379]Image: 586b86560.jpg | Classes present: tensor([0])\n",
            "Image: 90246e919.jpg | Classes present: tensor([0])\n",
            "Image: 11f34f40d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 7e25a3973.jpg | Classes present: tensor([0])\n",
            "Image: a732b1b72.jpg | Classes present: tensor([0])\n",
            "Image: bbd3d337f.jpg | Classes present: tensor([0])\n",
            "Image: 40f56ca26.jpg | Classes present: tensor([0, 3])\n",
            "Image: 315405789.jpg | Classes present: tensor([0])\n",
            "Image: 108ea689b.jpg | Classes present: tensor([0])\n",
            "Image: a4334d7da.jpg | Classes present: tensor([0, 3])\n",
            "Image: 9db1d6f4c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 54ce7b2e1.jpg | Classes present: tensor([0])\n",
            "Image: 9236b3124.jpg | Classes present: tensor([0])\n",
            "Image: 5e534a619.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.017539063468575478\n",
            "Training Batch 358 - Positive pixels per class: [    0.     0. 14612.  3348.]\n",
            "Output stats - Min: -15.078125, Max: 2.255859375\n",
            "Image: 2e29001f1.jpg | Classes present: tensor([0])\n",
            "Image: 99b7bd247.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  72% 358/500 [01:09<00:22,  6.19it/s, Loss=0.101]Image: 2e29001f1.jpg | Classes present: tensor([0])\n",
            "Image: 5ff533576.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.00867480505257845\n",
            "Training Batch 359 - Positive pixels per class: [   0.    0.    0. 8883.]\n",
            "Output stats - Min: -15.2265625, Max: 1.98828125\n",
            "Image: 4a9bd840f.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  72% 359/500 [01:09<00:21,  6.63it/s, Loss=0.113]Image: 9a5e9e77c.jpg | Classes present: tensor([0])\n",
            "Image: e851fc03a.jpg | Classes present: tensor([0])\n",
            "Image: d482f0159.jpg | Classes present: tensor([0])\n",
            "Image: cd3b9899c.jpg | Classes present: tensor([0])\n",
            "Image: 9b63ed48c.jpg | Classes present: tensor([0])\n",
            "Image: 60aca03e2.jpg | Classes present: tensor([0])\n",
            "Image: 47aea9052.jpg | Classes present: tensor([0])\n",
            "Image: 2994546cf.jpg | Classes present: tensor([0])\n",
            "Image: eed74bec9.jpg | Classes present: tensor([0])\n",
            "Image: 316414f82.jpg | Classes present: tensor([0])\n",
            "Image: 54fc18824.jpg | Classes present: tensor([0])\n",
            "Image: 1d32009ed.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8e53eee1d.jpg | Classes present: tensor([0])\n",
            "Image: 3ee680a42.jpg | Classes present: tensor([0])\n",
            "Image: 744c6de01.jpg | Classes present: tensor([0])\n",
            "Image: 91a713a73.jpg | Classes present: tensor([0, 2])\n",
            "Image: b023d90ff.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.010255860164761543\n",
            "Training Batch 360 - Positive pixels per class: [    0.     0. 10502.     0.]\n",
            "Image: 301601620.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -18.046875, Max: 2.05078125\n",
            "Image: 7da901e89.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  72% 360/500 [01:09<00:24,  5.60it/s, Loss=0.055]Image: 9ae440fd0.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.004921875428408384\n",
            "Training Batch 361 - Positive pixels per class: [   0.    0. 5040.    0.]\n",
            "Output stats - Min: -16.140625, Max: 1.8681640625\n",
            "Epoch 10/10:  72% 360/500 [01:09<00:24,  5.60it/s, Loss=0.0555]Image: 648e67d1b.jpg | Classes present: tensor([0])\n",
            "Image: 933533867.jpg | Classes present: tensor([0])\n",
            "Image: 9d3f69524.jpg | Classes present: tensor([0])\n",
            "Image: 902ba9941.jpg | Classes present: tensor([0])\n",
            "Image: 09d70d8f0.jpg | Classes present: tensor([0])\n",
            "Image: 741265573.jpg | Classes present: tensor([0])\n",
            "Image: 3604dfc38.jpg | Classes present: tensor([0])\n",
            "Image: 36025df84.jpg | Classes present: tensor([0])\n",
            "Image: 047fa15d0.jpg | Classes present: tensor([0])\n",
            "Image: 2253d7244.jpg | Classes present: tensor([0])\n",
            "Image: c404df4f4.jpg | Classes present: tensor([0, 2])\n",
            "Image: 23d77b3df.jpg | Classes present: tensor([0])\n",
            "Image: 40e52c68b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 349baa83f.jpg | Classes present: tensor([0])\n",
            "Image: eb8aa849b.jpg | Classes present: tensor([0])\n",
            "Image: 506826fc6.jpg | Classes present: tensor([0])\n",
            "Image: 7fe5d431f.jpg | Classes present: tensor([0])\n",
            "Image: 0d617d477.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.007830078713595867\n",
            "Training Batch 362 - Positive pixels per class: [   0.    0. 8018.    0.]\n",
            "Output stats - Min: -16.390625, Max: 1.9619140625\n",
            "Image: 61be1f51b.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  72% 362/500 [01:09<00:23,  5.84it/s, Loss=0.0514]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0007744141039438546\n",
            "Training Batch 363 - Positive pixels per class: [  0.   0. 793.   0.]\n",
            "Image: 744e852d6.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.640625, Max: 1.41796875\n",
            "Epoch 10/10:  72% 362/500 [01:09<00:23,  5.84it/s, Loss=0.0413]Image: 1f6915575.jpg | Classes present: tensor([0, 2])\n",
            "Image: de7e172fb.jpg | Classes present: tensor([0])\n",
            "Image: 250107a1b.jpg | Classes present: tensor([0])\n",
            "Image: dcf0a3a06.jpg | Classes present: tensor([0, 2])\n",
            "Image: b29f4c4ed.jpg | Classes present: tensor([0])\n",
            "Image: d1fedf96b.jpg | Classes present: tensor([0])\n",
            "Image: bb1c6efac.jpg | Classes present: tensor([0])\n",
            "Image: 3158e73b2.jpg | Classes present: tensor([0])\n",
            "Image: 73c295786.jpg | Classes present: tensor([0])\n",
            "Image: 0576d3847.jpg | Classes present: tensor([0])\n",
            "Image: 354760e3e.jpg | Classes present: tensor([0, 2])\n",
            "Image: a345caa40.jpg | Classes present: tensor([0])\n",
            "Image: 534dacff6.jpg | Classes present: tensor([0])\n",
            "Image: 837d38c91.jpg | Classes present: tensor([0])\n",
            "Image: 6e62ddf4e.jpg | Classes present: tensor([0])\n",
            "Image: a5e7b9502.jpg | Classes present: tensor([0])\n",
            "Image: 251ed373d.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.007948242127895355\n",
            "Training Batch 364 - Positive pixels per class: [   0.    0. 8139.    0.]\n",
            "Image: 833433e81.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.75, Max: 1.4765625\n",
            "Image: 16b7dc417.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  73% 364/500 [01:10<00:22,  5.98it/s, Loss=0.0635]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0001367187505820766\n",
            "Training Batch 365 - Positive pixels per class: [  0.   0. 140.   0.]\n",
            "Output stats - Min: -14.828125, Max: 1.369140625\n",
            "Image: af7ca17d0.jpg | Classes present: tensor([0])\n",
            "Image: 6e99aef86.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  73% 364/500 [01:10<00:22,  5.98it/s, Loss=0.0512]Image: e7e2036ef.jpg | Classes present: tensor([0])\n",
            "Image: c55802a79.jpg | Classes present: tensor([0])\n",
            "Image: 8a7121b61.jpg | Classes present: tensor([0, 2])\n",
            "Image: af094b41c.jpg | Classes present: tensor([0])\n",
            "Image: 73f4fb776.jpg | Classes present: tensor([0])\n",
            "Image: 7dcd9d8e2.jpg | Classes present: tensor([0])\n",
            "Image: 8a90952b4.jpg | Classes present: tensor([0])\n",
            "Image: ae41ecb3f.jpg | Classes present: tensor([0])\n",
            "Image: 71c2116d8.jpg | Classes present: tensor([0])\n",
            "Image: 8e5a5ca0f.jpg | Classes present: tensor([0])\n",
            "Image: 2276b004c.jpg | Classes present: tensor([0])\n",
            "Image: 3b42727ff.jpg | Classes present: tensor([0])\n",
            "Image: a0ae0cbcf.jpg | Classes present: tensor([0])\n",
            "Image: 8e340f137.jpg | Classes present: tensor([0])\n",
            "Image: dbd7ba010.jpg | Classes present: tensor([0])\n",
            "Image: 5a3e79676.jpg | Classes present: tensor([0])\n",
            "Image: ecbab23d0.jpg | Classes present: tensor([0])\n",
            "Image: bf9b21859.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 366 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -15.5, Max: 1.9853515625\n",
            "Epoch 10/10:  73% 364/500 [01:10<00:22,  5.98it/s, Loss=0.0565]Image: 3c247ad54.jpg | Classes present: tensor([0, 3])\n",
            "Epoch 10/10:  73% 366/500 [01:10<00:22,  5.94it/s, Loss=0.0565]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.008156250230967999\n",
            "Training Batch 367 - Positive pixels per class: [ 456.    0. 7896.    0.]\n",
            "Image: e04be8eca.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.59375, Max: 1.669921875\n",
            "Image: 1c61eaea9.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  73% 366/500 [01:10<00:22,  5.94it/s, Loss=0.0697]Image: 15b56bf43.jpg | Classes present: tensor([0])\n",
            "Image: dc607256d.jpg | Classes present: tensor([0])\n",
            "Image: 60906c3a1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2dc3dd0a6.jpg | Classes present: tensor([0])\n",
            "Image: ac48ab24b.jpg | Classes present: tensor([0])\n",
            "Image: 36c07efbe.jpg | Classes present: tensor([0])\n",
            "Image: b1b94f0fc.jpg | Classes present: tensor([0])\n",
            "Image: bdd265724.jpg | Classes present: tensor([0])\n",
            "Image: d7dba3a05.jpg | Classes present: tensor([0])\n",
            "Image: ad26af6e4.jpg | Classes present: tensor([0])\n",
            "Image: 8e5f4851e.jpg | Classes present: tensor([0])\n",
            "Image: 2e3b354cd.jpg | Classes present: tensor([0])\n",
            "Image: 00e0398ad.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 368 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -16.328125, Max: 1.220703125\n",
            "Image: acc420cb3.jpg | Classes present: tensor([0])\n",
            "Image: 6a15b9733.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  74% 368/500 [01:10<00:20,  6.54it/s, Loss=0.0489]Image: 6181b0a92.jpg | Classes present: tensor([0])\n",
            "Image: 07ba66beb.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.03456640616059303\n",
            "Training Batch 369 - Positive pixels per class: [    0.     0. 24363. 11033.]\n",
            "Image: 7773445b7.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.875, Max: 2.552734375\n",
            "Image: 40ab005e7.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  74% 368/500 [01:10<00:20,  6.54it/s, Loss=0.147] Image: 5b1e974a2.jpg | Classes present: tensor([0, 2])\n",
            "Image: 690afc09e.jpg | Classes present: tensor([0])\n",
            "Image: 11f788ecf.jpg | Classes present: tensor([0])\n",
            "Image: af426e1d3.jpg | Classes present: tensor([0])\n",
            "Image: 46582cff8.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6705eb964.jpg | Classes present: tensor([0])\n",
            "Image: d6102d7d2.jpg | Classes present: tensor([0])\n",
            "Image: d201f7d4b.jpg | Classes present: tensor([0])\n",
            "Image: 0e0f06208.jpg | Classes present: tensor([0])\n",
            "Image: b5cdb72ff.jpg | Classes present: tensor([0])\n",
            "Image: 6b0b37549.jpg | Classes present: tensor([0])\n",
            "Image: ae9976755.jpg | Classes present: tensor([0])\n",
            "Image: 915b0078c.jpg | Classes present: tensor([0])\n",
            "Image: 0ae4f8a60.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0014375001192092896\n",
            "Training Batch 370 - Positive pixels per class: [   0.    0. 1472.    0.]\n",
            "Image: d3ef0c943.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.984375, Max: 1.515625\n",
            "Image: c7adf7112.jpg | Classes present: tensor([0])\n",
            "Image: 3e63fb99b.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  74% 370/500 [01:11<00:21,  6.11it/s, Loss=0.054]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.000815429724752903\n",
            "Training Batch 371 - Positive pixels per class: [  0.   0. 835.   0.]\n",
            "Output stats - Min: -17.78125, Max: 0.8173828125\n",
            "Image: 9fab4894b.jpg | Classes present: tensor([0])\n",
            "Image: 3eae81bc8.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  74% 370/500 [01:11<00:21,  6.11it/s, Loss=0.0499]Image: aa14f39fd.jpg | Classes present: tensor([0])\n",
            "Image: 2c37ea89f.jpg | Classes present: tensor([0])\n",
            "Image: 08b40a161.jpg | Classes present: tensor([0])\n",
            "Image: 092f8d365.jpg | Classes present: tensor([0])\n",
            "Image: 0f1617841.jpg | Classes present: tensor([0])\n",
            "Image: 84c34d791.jpg | Classes present: tensor([0, 2])\n",
            "Image: 376d2291e.jpg | Classes present: tensor([0])\n",
            "Image: cadf3a94f.jpg | Classes present: tensor([0, 2])\n",
            "Image: 206c20ee0.jpg | Classes present: tensor([0])\n",
            "Image: c3ff1a7cd.jpg | Classes present: tensor([0, 2])\n",
            "Image: a88dc13d6.jpg | Classes present: tensor([0])\n",
            "Image: 5b28f3d4a.jpg | Classes present: tensor([0])\n",
            "Image: bd1e7ea2d.jpg | Classes present: tensor([0])\n",
            "Image: 9c024e0ba.jpg | Classes present: tensor([0])\n",
            "Image: 4c67c9b8e.jpg | Classes present: tensor([0])\n",
            "Image: e4a7202d9.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.015705078840255737\n",
            "Training Batch 372 - Positive pixels per class: [    0.     0. 16082.     0.]\n",
            "Image: 3b4c8b9a4.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -18.859375, Max: 2.248046875\n",
            "Image: edfe6ee4c.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  74% 372/500 [01:11<00:21,  6.04it/s, Loss=0.0793]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0010449219262227416\n",
            "Training Batch 373 - Positive pixels per class: [1070.    0.    0.    0.]\n",
            "Output stats - Min: -15.6484375, Max: 1.4384765625\n",
            "Image: 681af7b91.jpg | Classes present: tensor([0])\n",
            "Image: eaa65effb.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  74% 372/500 [01:11<00:21,  6.04it/s, Loss=0.0598]Image: 71d3b0598.jpg | Classes present: tensor([0])\n",
            "Image: e2037da93.jpg | Classes present: tensor([0])\n",
            "Image: 175c0ee12.jpg | Classes present: tensor([0])\n",
            "Image: e7fb372da.jpg | Classes present: tensor([0])\n",
            "Image: 53a21bba1.jpg | Classes present: tensor([0])\n",
            "Image: 7c847f7b3.jpg | Classes present: tensor([0])\n",
            "Image: dd72a8eef.jpg | Classes present: tensor([0])\n",
            "Image: 69c728b51.jpg | Classes present: tensor([0])\n",
            "Image: 4b624bfdf.jpg | Classes present: tensor([0])\n",
            "Image: 33226811d.jpg | Classes present: tensor([0])\n",
            "Image: 5665ada1b.jpg | Classes present: tensor([0])\n",
            "Image: a8188747f.jpg | Classes present: tensor([0])\n",
            "Image: 78556368f.jpg | Classes present: tensor([0])\n",
            "Image: 26d43765f.jpg | Classes present: tensor([0])\n",
            "Image: 12ee58841.jpg | Classes present: tensor([0])\n",
            "Image: 3f3c1170e.jpg | Classes present: tensor([0])\n",
            "Image: 4bf995227.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 374 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -16.40625, Max: 1.3828125\n",
            "Image: 7b3666172.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  75% 374/500 [01:11<00:20,  6.07it/s, Loss=0.047]Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 375 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: 47d3379c1.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.0078125, Max: 0.962890625\n",
            "Epoch 10/10:  75% 374/500 [01:11<00:20,  6.07it/s, Loss=0.0449]Image: 5bcaca872.jpg | Classes present: tensor([0])\n",
            "Image: d9145f0fb.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3740a6dd1.jpg | Classes present: tensor([0])\n",
            "Image: 6fd6355e3.jpg | Classes present: tensor([0])\n",
            "Image: 94882163b.jpg | Classes present: tensor([0])\n",
            "Image: 49d1ff5e2.jpg | Classes present: tensor([0])\n",
            "Image: 4dc8b9c03.jpg | Classes present: tensor([0])\n",
            "Image: 817a545aa.jpg | Classes present: tensor([0])\n",
            "Image: d407563d4.jpg | Classes present: tensor([0, 2])\n",
            "Image: 98ed0f752.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5aa352ece.jpg | Classes present: tensor([0])\n",
            "Image: 07c8ba1d5.jpg | Classes present: tensor([0, 2])\n",
            "Image: ecb3a4be6.jpg | Classes present: tensor([0])\n",
            "Image: 2cd524ca5.jpg | Classes present: tensor([0])\n",
            "Image: 7ff9e795d.jpg | Classes present: tensor([0])\n",
            "Image: c389100a5.jpg | Classes present: tensor([0])\n",
            "Image: 62122709f.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.016660157591104507\n",
            "Training Batch 376 - Positive pixels per class: [    0.     0. 17060.     0.]\n",
            "Image: 87ebb9d4f.jpg | Classes present: tensor([0, 2])\n",
            "Image: 79679dd6a.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.671875, Max: 1.9091796875\n",
            "Epoch 10/10:  75% 376/500 [01:12<00:20,  6.13it/s, Loss=0.0658]Image: d43c06a93.jpg | Classes present: tensor([0, 3])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.015583985485136509\n",
            "Training Batch 377 - Positive pixels per class: [    0.     0. 15958.     0.]\n",
            "Image: 65841b207.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -14.9296875, Max: 2.427734375\n",
            "Epoch 10/10:  75% 376/500 [01:12<00:20,  6.13it/s, Loss=0.0839]Image: 0f7b0f4ab.jpg | Classes present: tensor([0])\n",
            "Image: 707534bdb.jpg | Classes present: tensor([0])\n",
            "Image: 1ca7f19cf.jpg | Classes present: tensor([0])\n",
            "Image: d1fdc8367.jpg | Classes present: tensor([0])\n",
            "Image: 08b40a161.jpg | Classes present: tensor([0])\n",
            "Image: 5fccf97d8.jpg | Classes present: tensor([0])\n",
            "Image: bd77f2c37.jpg | Classes present: tensor([0, 2])\n",
            "Image: cb95ba6d9.jpg | Classes present: tensor([0])\n",
            "Image: bde2a33eb.jpg | Classes present: tensor([0, 3])\n",
            "Image: 47aae4725.jpg | Classes present: tensor([0])\n",
            "Image: ac03345dc.jpg | Classes present: tensor([0])\n",
            "Image: e4fe95209.jpg | Classes present: tensor([0])\n",
            "Image: baca6503a.jpg | Classes present: tensor([0])\n",
            "Image: c35fa49e2.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.017957031726837158\n",
            "Training Batch 378 - Positive pixels per class: [   0.    0. 9813. 8575.]\n",
            "Output stats - Min: -17.828125, Max: 2.048828125\n",
            "Epoch 10/10:  76% 378/500 [01:12<00:21,  5.73it/s, Loss=0.128]Image: bacfd8fc8.jpg | Classes present: tensor([0])\n",
            "Image: aff2b8b8a.jpg | Classes present: tensor([0])\n",
            "Image: acd295ec3.jpg | Classes present: tensor([0])\n",
            "Image: c5a43f4e1.jpg | Classes present: tensor([0])\n",
            "Image: 13c1d516a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5848791de.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.030714845284819603\n",
            "Training Batch 379 - Positive pixels per class: [    0.     0. 12242. 19210.]\n",
            "Output stats - Min: -14.6953125, Max: 2.1015625\n",
            "Epoch 10/10:  76% 379/500 [01:12<00:21,  5.74it/s, Loss=0.163]Image: 8898932bd.jpg | Classes present: tensor([0, 2])\n",
            "Image: d5d900def.jpg | Classes present: tensor([0])\n",
            "Image: 61b4b7771.jpg | Classes present: tensor([0])\n",
            "Image: 090a6a4b5.jpg | Classes present: tensor([0])\n",
            "Image: 2467e2b6e.jpg | Classes present: tensor([0])\n",
            "Image: 9e1406b36.jpg | Classes present: tensor([0])\n",
            "Image: 402c5369d.jpg | Classes present: tensor([0])\n",
            "Image: b080280d8.jpg | Classes present: tensor([0, 2])\n",
            "Image: a71670d83.jpg | Classes present: tensor([0])\n",
            "Image: 539a30638.jpg | Classes present: tensor([0])\n",
            "Image: c571c7c32.jpg | Classes present: tensor([0])\n",
            "Image: 708756850.jpg | Classes present: tensor([0])\n",
            "Image: 2c23eefec.jpg | Classes present: tensor([0])\n",
            "Image: 5b537b5fa.jpg | Classes present: tensor([0])\n",
            "Image: 0b4c8e681.jpg | Classes present: tensor([0])\n",
            "Image: 127504e0f.jpg | Classes present: tensor([0])\n",
            "Image: 63b6edd7e.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.004143554717302322\n",
            "Training Batch 380 - Positive pixels per class: [   0.    0. 4243.    0.]\n",
            "Image: b8f1c53e2.jpg | Classes present: tensor([0])\n",
            "Image: 7046618f6.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -19.453125, Max: 1.794921875\n",
            "Epoch 10/10:  76% 380/500 [01:13<00:28,  4.24it/s, Loss=0.0509]Image: 8ad6069fe.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 381 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: 7e6fe6786.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.953125, Max: 0.888671875\n",
            "Epoch 10/10:  76% 380/500 [01:13<00:28,  4.24it/s, Loss=0.0461]Image: 49fa7d0fa.jpg | Classes present: tensor([0, 3])\n",
            "Image: d0d0e589a.jpg | Classes present: tensor([0])\n",
            "Image: ce2da8536.jpg | Classes present: tensor([0, 2])\n",
            "Image: c7edb8625.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0167a740e.jpg | Classes present: tensor([0])\n",
            "Image: b35ab5606.jpg | Classes present: tensor([0])\n",
            "Image: a053e52ca.jpg | Classes present: tensor([0])\n",
            "Image: 454d794dc.jpg | Classes present: tensor([0])\n",
            "Image: 5bf4948c3.jpg | Classes present: tensor([0])\n",
            "Image: 33c961de1.jpg | Classes present: tensor([0])\n",
            "Image: e848a32dd.jpg | Classes present: tensor([0])\n",
            "Image: 03da79fda.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.007988281548023224\n",
            "Training Batch 382 - Positive pixels per class: [   0.    0. 2693. 5487.]\n",
            "Image: de89591c4.jpg | Classes present: tensor([0])\n",
            "Image: 11b801a0a.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.515625, Max: 2.443359375\n",
            "Epoch 10/10:  76% 382/500 [01:13<00:26,  4.38it/s, Loss=0.0822]Image: a9914e83b.jpg | Classes present: tensor([0])\n",
            "Image: 5de4f67ec.jpg | Classes present: tensor([0])\n",
            "Image: 4d930ad34.jpg | Classes present: tensor([0])\n",
            "Image: 494ead378.jpg | Classes present: tensor([0])\n",
            "Image: 0391d44d6.jpg | Classes present: tensor([0])\n",
            "Image: 6916a083e.jpg | Classes present: tensor([0])\n",
            "Image: 2f06514ea.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.004433594178408384\n",
            "Training Batch 383 - Positive pixels per class: [1408.    0. 3132.    0.]\n",
            "Image: d9a63b372.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.5390625, Max: 1.7119140625\n",
            "Epoch 10/10:  77% 383/500 [01:13<00:26,  4.38it/s, Loss=0.0674]Image: 1a0f5230a.jpg | Classes present: tensor([0])\n",
            "Image: caead5f75.jpg | Classes present: tensor([0])\n",
            "Image: 6d3f92952.jpg | Classes present: tensor([0])\n",
            "Image: c60002bcd.jpg | Classes present: tensor([0])\n",
            "Image: bb1977eed.jpg | Classes present: tensor([0])\n",
            "Image: 9f101a24e.jpg | Classes present: tensor([0])\n",
            "Image: 627b98bc7.jpg | Classes present: tensor([0])\n",
            "Image: 56011ad29.jpg | Classes present: tensor([0, 3])\n",
            "Image: db1c5b4f7.jpg | Classes present: tensor([0])\n",
            "Image: c56e3ffcb.jpg | Classes present: tensor([0, 2])\n",
            "Image: a115aabc4.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.023979492485523224\n",
            "Training Batch 384 - Positive pixels per class: [    0.     0.  9984. 14571.]\n",
            "Output stats - Min: -15.125, Max: 2.234375\n",
            "Epoch 10/10:  77% 384/500 [01:14<00:28,  4.03it/s, Loss=0.131]Image: 756390c3a.jpg | Classes present: tensor([0])\n",
            "Image: 27b1670da.jpg | Classes present: tensor([0])\n",
            "Image: 68cc04a14.jpg | Classes present: tensor([0])\n",
            "Image: 409ebd086.jpg | Classes present: tensor([0])\n",
            "Image: 9cfa9539e.jpg | Classes present: tensor([0])\n",
            "Image: 313c72ff8.jpg | Classes present: tensor([0])\n",
            "Image: 51d3e5941.jpg | Classes present: tensor([0])\n",
            "Image: 4e5aabaae.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.004345703404396772\n",
            "Training Batch 385 - Positive pixels per class: [   0.    0. 4450.    0.]\n",
            "Image: 848b66095.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -14.75, Max: 2.001953125\n",
            "Epoch 10/10:  77% 385/500 [01:14<00:27,  4.13it/s, Loss=0.0725]Image: 3ba5b066f.jpg | Classes present: tensor([0])\n",
            "Image: ed69c5fcf.jpg | Classes present: tensor([0])\n",
            "Image: 75878cb48.jpg | Classes present: tensor([0, 2])\n",
            "Image: bfaf69bd5.jpg | Classes present: tensor([0])\n",
            "Image: 8fc4cc556.jpg | Classes present: tensor([0])\n",
            "Image: e29a708e0.jpg | Classes present: tensor([0])\n",
            "Image: 1ffe887dd.jpg | Classes present: tensor([0])\n",
            "Image: babc99f0c.jpg | Classes present: tensor([0])\n",
            "Image: 8c3539cdd.jpg | Classes present: tensor([0])\n",
            "Image: 841c364ec.jpg | Classes present: tensor([0])\n",
            "Image: 7f30b9c64.jpg | Classes present: tensor([0, 2])\n",
            "Image: e59a4b5cb.jpg | Classes present: tensor([0])\n",
            "Image: 64fdc1a7a.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.008025391027331352\n",
            "Training Batch 386 - Positive pixels per class: [   0.    0. 8218.    0.]\n",
            "Output stats - Min: -13.5, Max: 1.5302734375\n",
            "Image: 4b3de8933.jpg | Classes present: tensor([0])\n",
            "Image: b95e49245.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  77% 386/500 [01:14<00:30,  3.70it/s, Loss=0.0789]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.009760743007063866\n",
            "Training Batch 387 - Positive pixels per class: [ 536.    0. 9459.    0.]\n",
            "Output stats - Min: -16.46875, Max: 1.9189453125\n",
            "Image: 4d967fdb0.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  77% 386/500 [01:14<00:30,  3.70it/s, Loss=0.0606]Image: b35a7ff2e.jpg | Classes present: tensor([0])\n",
            "Image: 01afbfa7a.jpg | Classes present: tensor([0])\n",
            "Image: 80f2eef6e.jpg | Classes present: tensor([0])\n",
            "Image: cb933c3e8.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6e8878a30.jpg | Classes present: tensor([0])\n",
            "Image: ce34adc8c.jpg | Classes present: tensor([0])\n",
            "Image: 2d4471837.jpg | Classes present: tensor([0])\n",
            "Image: 14ff2a474.jpg | Classes present: tensor([0])\n",
            "Image: 25548e840.jpg | Classes present: tensor([0])\n",
            "Image: 2776642e1.jpg | Classes present: tensor([0])\n",
            "Image: b94f92e51.jpg | Classes present: tensor([0])\n",
            "Image: 397221566.jpg | Classes present: tensor([0])\n",
            "Image: 627fef214.jpg | Classes present: tensor([0])\n",
            "Image: 1a70268d4.jpg | Classes present: tensor([0])\n",
            "Image: 24d88228f.jpg | Classes present: tensor([0])\n",
            "Image: 75970889c.jpg | Classes present: tensor([0])\n",
            "Image: 385f6dc61.jpg | Classes present: tensor([0])\n",
            "Image: 234ba0510.jpg | Classes present: tensor([0])\n",
            "Image: 4ab1aeab6.jpg | Classes present: tensor([0])\n",
            "Image: 51434f59b.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 388 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -14.671875, Max: 0.9462890625\n",
            "Image: 75785b3eb.jpg | Classes present: tensor([0])\n",
            "Image: b8a9fb7d0.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  78% 388/500 [01:15<00:31,  3.60it/s, Loss=0.0584]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.004599609412252903\n",
            "Training Batch 389 - Positive pixels per class: [   0.    0. 4710.    0.]\n",
            "Output stats - Min: -15.90625, Max: 2.5\n",
            "Image: 260e316eb.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  78% 388/500 [01:15<00:31,  3.60it/s, Loss=0.0566]Image: 6ff8d1e9c.jpg | Classes present: tensor([0])\n",
            "Image: 87106dfdb.jpg | Classes present: tensor([0, 2])\n",
            "Image: 24e3826ff.jpg | Classes present: tensor([0])\n",
            "Image: da522f333.jpg | Classes present: tensor([0])\n",
            "Image: 166fff927.jpg | Classes present: tensor([0, 2])\n",
            "Image: e7c69aea5.jpg | Classes present: tensor([0])\n",
            "Image: 955b5bbf3.jpg | Classes present: tensor([0])\n",
            "Image: 59f0c09bb.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4c2bd254d.jpg | Classes present: tensor([0])\n",
            "Image: 8a642f9d3.jpg | Classes present: tensor([0])\n",
            "Image: ad5a2ea44.jpg | Classes present: tensor([0])\n",
            "Image: 7150719e7.jpg | Classes present: tensor([0])\n",
            "Image: bdfa2974d.jpg | Classes present: tensor([0])\n",
            "Image: 300c525ff.jpg | Classes present: tensor([0])\n",
            "Image: 016efe618.jpg | Classes present: tensor([0, 3])\n",
            "Image: c9a42a79e.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.014334961771965027\n",
            "Training Batch 390 - Positive pixels per class: [    0.     0.  1914. 12765.]\n",
            "Output stats - Min: -15.7109375, Max: 2.404296875\n",
            "Image: bc67d17de.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  78% 390/500 [01:15<00:29,  3.68it/s, Loss=0.131]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.011786133050918579\n",
            "Training Batch 391 - Positive pixels per class: [    0.     0. 12069.     0.]\n",
            "Image: af67d55bd.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.7578125, Max: 2.517578125\n",
            "Image: 32dca5f32.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  78% 390/500 [01:15<00:29,  3.68it/s, Loss=0.0556]Image: d55dd8719.jpg | Classes present: tensor([0])\n",
            "Image: 8364cd311.jpg | Classes present: tensor([0])\n",
            "Image: 8d4e680c6.jpg | Classes present: tensor([0])\n",
            "Image: 594d97d26.jpg | Classes present: tensor([0])\n",
            "Image: 8beef62a7.jpg | Classes present: tensor([0])\n",
            "Image: b868c43ca.jpg | Classes present: tensor([0])\n",
            "Image: 45b946123.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3abc94d79.jpg | Classes present: tensor([0, 2])\n",
            "Image: 496790c19.jpg | Classes present: tensor([0])\n",
            "Image: 5370c78e0.jpg | Classes present: tensor([0])\n",
            "Image: 4e36f104c.jpg | Classes present: tensor([0])\n",
            "Image: 3467968c0.jpg | Classes present: tensor([0])\n",
            "Image: 094fd70ea.jpg | Classes present: tensor([0])\n",
            "Image: c804959b3.jpg | Classes present: tensor([0])\n",
            "Image: 7393b145f.jpg | Classes present: tensor([0])\n",
            "Image: 8562a95b4.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.004424804821610451\n",
            "Training Batch 392 - Positive pixels per class: [   0.    0. 4531.    0.]\n",
            "Output stats - Min: -13.65625, Max: 2.158203125\n",
            "Epoch 10/10:  78% 392/500 [01:16<00:28,  3.74it/s, Loss=0.0525]Image: 8f38c1314.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.01939941570162773\n",
            "Training Batch 393 - Positive pixels per class: [ 1231.     0. 18634.     0.]\n",
            "Output stats - Min: -17.09375, Max: 2.4453125\n",
            "Epoch 10/10:  78% 392/500 [01:16<00:28,  3.74it/s, Loss=0.0727]Image: 1ad10c316.jpg | Classes present: tensor([0])\n",
            "Image: 4edc8b817.jpg | Classes present: tensor([0, 3])\n",
            "Image: 70a38928c.jpg | Classes present: tensor([0])\n",
            "Image: 521f4df19.jpg | Classes present: tensor([0])\n",
            "Image: b5352d213.jpg | Classes present: tensor([0])\n",
            "Image: 2a374ceaa.jpg | Classes present: tensor([0])\n",
            "Image: 37f4e9602.jpg | Classes present: tensor([0])\n",
            "Image: b8eadd5bf.jpg | Classes present: tensor([0, 2])\n",
            "Image: e9e04715b.jpg | Classes present: tensor([0])\n",
            "Image: 03ca4d04c.jpg | Classes present: tensor([0, 2])\n",
            "Image: eab4edf22.jpg | Classes present: tensor([0])\n",
            "Image: c57607580.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4d042c66f.jpg | Classes present: tensor([0, 2])\n",
            "Image: 313b9ba80.jpg | Classes present: tensor([0])\n",
            "Image: 2ec116cea.jpg | Classes present: tensor([0])\n",
            "Image: 784b81af8.jpg | Classes present: tensor([0])\n",
            "Image: 7a1251b77.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.003276367438957095\n",
            "Training Batch 394 - Positive pixels per class: [   0.    0. 3110.  245.]\n",
            "Output stats - Min: -13.5625, Max: 2.25390625\n",
            "Image: c6cb040ad.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  79% 394/500 [01:16<00:28,  3.76it/s, Loss=0.0519]Image: b68c2531c.jpg | Classes present: tensor([0])\n",
            "Image: 6588cf973.jpg | Classes present: tensor([0, 2])\n",
            "Image: cd662eda7.jpg | Classes present: tensor([0])\n",
            "Image: 4ee570810.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.01433105580508709\n",
            "Training Batch 395 - Positive pixels per class: [    0.     0. 14675.     0.]\n",
            "Output stats - Min: -15.59375, Max: 3.470703125\n",
            "Image: 8a87c8067.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  79% 394/500 [01:16<00:28,  3.76it/s, Loss=0.0639]Image: ea2ebb194.jpg | Classes present: tensor([0])\n",
            "Image: e4da37c1e.jpg | Classes present: tensor([0])\n",
            "Image: 6e34351b6.jpg | Classes present: tensor([0])\n",
            "Image: c0ceecd96.jpg | Classes present: tensor([0])\n",
            "Image: 1a603f8dd.jpg | Classes present: tensor([0])\n",
            "Image: 1a77fb759.jpg | Classes present: tensor([0, 3])\n",
            "Image: d685dc83f.jpg | Classes present: tensor([0])\n",
            "Image: 603bb9003.jpg | Classes present: tensor([0])\n",
            "Image: b732ea1f3.jpg | Classes present: tensor([0])\n",
            "Image: 0fb56c62d.jpg | Classes present: tensor([0])\n",
            "Image: 80d241bc5.jpg | Classes present: tensor([0])\n",
            "Image: 6e1a98592.jpg | Classes present: tensor([0])\n",
            "Image: e1e0a91b8.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1b6aefdb7.jpg | Classes present: tensor([0])\n",
            "Image: bc136ed5c.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.006375976838171482\n",
            "Training Batch 396 - Positive pixels per class: [   0.    0. 6529.    0.]\n",
            "Output stats - Min: -13.0703125, Max: 1.3994140625\n",
            "Epoch 10/10:  79% 396/500 [01:17<00:24,  4.25it/s, Loss=0.0915]Image: d0ba35b7f.jpg | Classes present: tensor([0])\n",
            "Image: ea23dae53.jpg | Classes present: tensor([0])\n",
            "Image: 2a113071b.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.009813477285206318\n",
            "Training Batch 397 - Positive pixels per class: [ 801.    0. 6275. 2973.]\n",
            "Image: a2c0731d2.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.09375, Max: 1.9794921875\n",
            "Epoch 10/10:  79% 396/500 [01:17<00:24,  4.25it/s, Loss=0.103] Image: 83c2e79d1.jpg | Classes present: tensor([0])\n",
            "Image: 4ade4b747.jpg | Classes present: tensor([0])\n",
            "Image: 7ac20d5a6.jpg | Classes present: tensor([0, 3])\n",
            "Image: 2511b27f5.jpg | Classes present: tensor([0])\n",
            "Image: 2365be47a.jpg | Classes present: tensor([0])\n",
            "Image: 3412f557e.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3b58d7324.jpg | Classes present: tensor([0])\n",
            "Image: 649822bd7.jpg | Classes present: tensor([0])\n",
            "Image: 5457e4e20.jpg | Classes present: tensor([0])\n",
            "Image: bae58dc36.jpg | Classes present: tensor([0])\n",
            "Image: 0934b8bff.jpg | Classes present: tensor([0])\n",
            "Image: 9a1f7c238.jpg | Classes present: tensor([0, 2])\n",
            "Image: ae93df7d1.jpg | Classes present: tensor([0])\n",
            "Image: 9570a27f4.jpg | Classes present: tensor([0])\n",
            "Image: a909833f5.jpg | Classes present: tensor([0])\n",
            "Image: b76bbb3cf.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.014854492619633675\n",
            "Training Batch 398 - Positive pixels per class: [    0.     0. 13991.  1220.]\n",
            "Output stats - Min: -14.1015625, Max: 1.7109375\n",
            "Epoch 10/10:  80% 398/500 [01:17<00:21,  4.77it/s, Loss=0.0782]Image: 89ef83ab7.jpg | Classes present: tensor([0, 3])\n",
            "Image: 22a125a81.jpg | Classes present: tensor([0])\n",
            "Image: 45e10836b.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 399 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: 944ef524a.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.90625, Max: 0.87255859375\n",
            "Image: 9f2f9704e.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  80% 398/500 [01:17<00:21,  4.77it/s, Loss=0.0419]Image: 76096b17b.jpg | Classes present: tensor([0])\n",
            "Image: ea28bb97c.jpg | Classes present: tensor([0])\n",
            "Image: 14ff2a474.jpg | Classes present: tensor([0])\n",
            "Image: c293952c8.jpg | Classes present: tensor([0])\n",
            "Image: 7aa11e186.jpg | Classes present: tensor([0])\n",
            "Image: bea606041.jpg | Classes present: tensor([0])\n",
            "Image: 5f0c8d167.jpg | Classes present: tensor([0])\n",
            "Image: 29936b461.jpg | Classes present: tensor([0])\n",
            "Image: 36a689ebf.jpg | Classes present: tensor([0])\n",
            "Image: 80841e418.jpg | Classes present: tensor([0])\n",
            "Image: 205e05371.jpg | Classes present: tensor([0])\n",
            "Image: c210d2e08.jpg | Classes present: tensor([0])\n",
            "Image: 058a1e3b8.jpg | Classes present: tensor([0])\n",
            "Image: 9bba9fd75.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.006797851994633675\n",
            "Training Batch 400 - Positive pixels per class: [ 620.    0. 5252. 1089.]\n",
            "Output stats - Min: -16.125, Max: 2.5078125\n",
            "Image: cc59639b2.jpg | Classes present: tensor([0, 3])\n",
            "Image: d127abcc8.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  80% 400/500 [01:17<00:19,  5.04it/s, Loss=0.0655]Image: 46dfd5be4.jpg | Classes present: tensor([0])\n",
            "Image: ded3e76e3.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.008844726718962193\n",
            "Training Batch 401 - Positive pixels per class: [   0.    0.    0. 9057.]\n",
            "Image: 62849bbef.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.5625, Max: 2.53515625\n",
            "Image: 0d2a4e766.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  80% 400/500 [01:17<00:19,  5.04it/s, Loss=0.116] Image: bff6cdfad.jpg | Classes present: tensor([0])\n",
            "Image: 352063998.jpg | Classes present: tensor([0])\n",
            "Image: 008ef3d74.jpg | Classes present: tensor([0])\n",
            "Image: 6355bcd53.jpg | Classes present: tensor([0])\n",
            "Image: 8ac717af9.jpg | Classes present: tensor([0])\n",
            "Image: 5d1aac191.jpg | Classes present: tensor([0])\n",
            "Image: badc94207.jpg | Classes present: tensor([0])\n",
            "Image: 81891e821.jpg | Classes present: tensor([0])\n",
            "Image: b1b3ec5fd.jpg | Classes present: tensor([0])\n",
            "Image: 6c9d6cc47.jpg | Classes present: tensor([0])\n",
            "Image: df8e56f94.jpg | Classes present: tensor([0])\n",
            "Image: c223d7b2e.jpg | Classes present: tensor([0])\n",
            "Image: 39e4216eb.jpg | Classes present: tensor([0])\n",
            "Image: 8eddcadff.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 402 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: 3a4f825e7.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.1875, Max: 1.3271484375\n",
            "Epoch 10/10:  80% 402/500 [01:18<00:18,  5.44it/s, Loss=0.0497]Image: ac0682b30.jpg | Classes present: tensor([0])\n",
            "Image: 3ecff5d55.jpg | Classes present: tensor([0])\n",
            "Image: 5377dbac1.jpg | Classes present: tensor([0, 2])\n",
            "Image: bd4957b80.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.02184472791850567\n",
            "Training Batch 403 - Positive pixels per class: [  354.     0. 22015.     0.]\n",
            "Output stats - Min: -16.15625, Max: 2.828125\n",
            "Image: 42996bbcf.jpg | Classes present: tensor([0])\n",
            "Image: d377de6cc.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  81% 403/500 [01:18<00:16,  5.81it/s, Loss=0.0748]Image: b595566b3.jpg | Classes present: tensor([0])\n",
            "Image: 86756300d.jpg | Classes present: tensor([0])\n",
            "Image: 5132041da.jpg | Classes present: tensor([0])\n",
            "Image: 07732248e.jpg | Classes present: tensor([0, 2])\n",
            "Image: eb5d79866.jpg | Classes present: tensor([0])\n",
            "Image: 8c81bbce4.jpg | Classes present: tensor([0])\n",
            "Image: 638b05d55.jpg | Classes present: tensor([0])\n",
            "Image: 76bbd78b2.jpg | Classes present: tensor([0])\n",
            "Image: a831d2806.jpg | Classes present: tensor([0, 2])\n",
            "Image: 739f32100.jpg | Classes present: tensor([0])\n",
            "Image: c081bd8c5.jpg | Classes present: tensor([0])\n",
            "Image: a6195e2d6.jpg | Classes present: tensor([0, 3])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.002194336149841547\n",
            "Training Batch 404 - Positive pixels per class: [   0.    0. 2247.    0.]\n",
            "Image: a0ce98154.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.53125, Max: 1.71875\n",
            "Epoch 10/10:  81% 404/500 [01:18<00:16,  5.70it/s, Loss=0.0505]Image: 2d61e4f9f.jpg | Classes present: tensor([0])\n",
            "Image: 3598309b5.jpg | Classes present: tensor([0])\n",
            "Image: 141bea747.jpg | Classes present: tensor([0, 3])\n",
            "Image: 321a6df3f.jpg | Classes present: tensor([0])\n",
            "Image: ad76bc064.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.00843359436839819\n",
            "Training Batch 405 - Positive pixels per class: [ 549.    0. 1344. 6743.]\n",
            "Image: 94c4ca4c1.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.171875, Max: 1.5830078125\n",
            "Image: d1dc95b58.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  81% 405/500 [01:18<00:15,  6.18it/s, Loss=0.116]Image: 661fcb87e.jpg | Classes present: tensor([0])\n",
            "Image: c1c3651cc.jpg | Classes present: tensor([0])\n",
            "Image: 5ff6ee14c.jpg | Classes present: tensor([0])\n",
            "Image: b7df222b1.jpg | Classes present: tensor([0])\n",
            "Image: aa53582ee.jpg | Classes present: tensor([0])\n",
            "Image: 6fcd94e33.jpg | Classes present: tensor([0])\n",
            "Image: 3c8312241.jpg | Classes present: tensor([0])\n",
            "Image: 61a06d797.jpg | Classes present: tensor([0])\n",
            "Image: 8c9286f4e.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8e08d9cd6.jpg | Classes present: tensor([0])\n",
            "Image: dbe2d92ec.jpg | Classes present: tensor([0])\n",
            "Image: a10a35f4f.jpg | Classes present: tensor([0])\n",
            "Image: 3ca2ba71b.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0007919922354631126\n",
            "Training Batch 406 - Positive pixels per class: [  0.   0.   0. 811.]\n",
            "Output stats - Min: -17.203125, Max: 1.8505859375\n",
            "Epoch 10/10:  81% 406/500 [01:18<00:17,  5.51it/s, Loss=0.0714]Image: 57794735f.jpg | Classes present: tensor([0])\n",
            "Image: c22ead98c.jpg | Classes present: tensor([0])\n",
            "Image: a77af14dd.jpg | Classes present: tensor([0])\n",
            "Image: bf0c81db6.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.001352539169602096\n",
            "Training Batch 407 - Positive pixels per class: [   0.    0. 1385.    0.]\n",
            "Output stats - Min: -12.90625, Max: 1.2158203125\n",
            "Image: 636214476.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  81% 406/500 [01:18<00:17,  5.51it/s, Loss=0.056] Image: c2a409a0b.jpg | Classes present: tensor([0])\n",
            "Image: 6860ae804.jpg | Classes present: tensor([0])\n",
            "Image: 2932c0dd3.jpg | Classes present: tensor([0])\n",
            "Image: ba54b162d.jpg | Classes present: tensor([0])\n",
            "Image: e2d7cf5a9.jpg | Classes present: tensor([0])\n",
            "Image: 3fb1d9448.jpg | Classes present: tensor([0])\n",
            "Image: 6e7bace88.jpg | Classes present: tensor([0])\n",
            "Image: 631c2334a.jpg | Classes present: tensor([0])\n",
            "Image: 95df642ba.jpg | Classes present: tensor([0, 2])\n",
            "Image: db89feeba.jpg | Classes present: tensor([0])\n",
            "Image: 878824b35.jpg | Classes present: tensor([0])\n",
            "Image: c33e20d0b.jpg | Classes present: tensor([0])\n",
            "Image: 5c7a09dc0.jpg | Classes present: tensor([0])\n",
            "Image: 7424ab9af.jpg | Classes present: tensor([0])\n",
            "Image: 4216b133c.jpg | Classes present: tensor([0])\n",
            "Image: a0fcb1803.jpg | Classes present: tensor([0])\n",
            "Image: 8e431ebe0.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 408 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -13.4609375, Max: 1.7041015625\n",
            "Image: d5b2ba152.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  82% 408/500 [01:19<00:16,  5.47it/s, Loss=0.0587]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.009233399294316769\n",
            "Training Batch 409 - Positive pixels per class: [   0.    0. 9455.    0.]\n",
            "Output stats - Min: -16.0625, Max: 1.486328125\n",
            "Image: c4370b942.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  82% 408/500 [01:19<00:16,  5.47it/s, Loss=0.0592]Image: 35665c5b9.jpg | Classes present: tensor([0])\n",
            "Image: 0a8cb8ddf.jpg | Classes present: tensor([0])\n",
            "Image: b845ef149.jpg | Classes present: tensor([0])\n",
            "Image: a2e96800f.jpg | Classes present: tensor([0])\n",
            "Image: a70b5d0c5.jpg | Classes present: tensor([0])\n",
            "Image: 286f459e6.jpg | Classes present: tensor([0])\n",
            "Image: 528112571.jpg | Classes present: tensor([0])\n",
            "Image: 140e59cff.jpg | Classes present: tensor([0])\n",
            "Image: 5c238e376.jpg | Classes present: tensor([0])\n",
            "Image: 6ad48f01b.jpg | Classes present: tensor([0, 3])\n",
            "Image: a5a0e4b19.jpg | Classes present: tensor([0])\n",
            "Image: 025dc8dc8.jpg | Classes present: tensor([0])\n",
            "Image: d3d2df811.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9eeadb0f5.jpg | Classes present: tensor([0])\n",
            "Image: 55a585807.jpg | Classes present: tensor([0])\n",
            "Image: 762c16cc9.jpg | Classes present: tensor([0])\n",
            "Image: d0fb25531.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.022572265937924385\n",
            "Training Batch 410 - Positive pixels per class: [    0.     0.  1470. 21644.]\n",
            "Image: a634d3a24.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -13.765625, Max: 2.33203125\n",
            "Image: 489bc785a.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  82% 410/500 [01:19<00:16,  5.58it/s, Loss=0.175]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.003825195599347353\n",
            "Training Batch 411 - Positive pixels per class: [   0.    0. 3917.    0.]\n",
            "Image: 400144782.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.625, Max: 1.6435546875\n",
            "Image: 55042415c.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  82% 410/500 [01:19<00:16,  5.58it/s, Loss=0.0701]Image: 7168496a4.jpg | Classes present: tensor([0])\n",
            "Image: dd8e822bb.jpg | Classes present: tensor([0])\n",
            "Image: 6078cc0b1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8dbca8b82.jpg | Classes present: tensor([0, 2])\n",
            "Image: e63aa9aaa.jpg | Classes present: tensor([0])\n",
            "Image: 3ace653be.jpg | Classes present: tensor([0])\n",
            "Image: a5d8010d4.jpg | Classes present: tensor([0])\n",
            "Image: 638531c87.jpg | Classes present: tensor([0])\n",
            "Image: d75a84b44.jpg | Classes present: tensor([0])\n",
            "Image: 07cbfd1f8.jpg | Classes present: tensor([0, 3])\n",
            "Image: 5aa7997bd.jpg | Classes present: tensor([0])\n",
            "Image: 89ef83ab7.jpg | Classes present: tensor([0, 3])\n",
            "Image: 5e2aaff78.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0e7f04eb4.jpg | Classes present: tensor([0])\n",
            "Image: d79e948c4.jpg | Classes present: tensor([0])\n",
            "Image: 328c0fc75.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9d57d9095.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.02673633024096489\n",
            "Training Batch 412 - Positive pixels per class: [    0.     0. 11301. 16077.]\n",
            "Output stats - Min: -16.1875, Max: 1.962890625\n",
            "Image: 9085aef37.jpg | Classes present: tensor([0])\n",
            "Image: b5d9dfe6d.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  82% 412/500 [01:19<00:15,  5.55it/s, Loss=0.176]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.01190918032079935\n",
            "Training Batch 413 - Positive pixels per class: [    0.     0. 12195.     0.]\n",
            "Image: 03db6bbc3.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -19.671875, Max: 2.19921875\n",
            "Epoch 10/10:  82% 412/500 [01:19<00:15,  5.55it/s, Loss=0.0507]Image: b15e6ca53.jpg | Classes present: tensor([0])\n",
            "Image: c646462b5.jpg | Classes present: tensor([0])\n",
            "Image: 8d2e8b456.jpg | Classes present: tensor([0])\n",
            "Image: c131d5030.jpg | Classes present: tensor([0, 2])\n",
            "Image: a08e02e56.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2a184dcbe.jpg | Classes present: tensor([0])\n",
            "Image: 1efff24a0.jpg | Classes present: tensor([0])\n",
            "Image: 7a7282702.jpg | Classes present: tensor([0])\n",
            "Image: 943c5abcd.jpg | Classes present: tensor([0])\n",
            "Image: 6d97f7c81.jpg | Classes present: tensor([0])\n",
            "Image: 278a21a00.jpg | Classes present: tensor([0])\n",
            "Image: d9077b7f2.jpg | Classes present: tensor([0])\n",
            "Image: 65f1d83fb.jpg | Classes present: tensor([0])\n",
            "Image: 1d99e94a9.jpg | Classes present: tensor([0])\n",
            "Image: 9822aabfc.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8d23e30d7.jpg | Classes present: tensor([0])\n",
            "Image: 75a2d7690.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.025822266936302185\n",
            "Training Batch 414 - Positive pixels per class: [    0.     0. 26442.     0.]\n",
            "Image: 8e2d247c4.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.6796875, Max: 2.505859375\n",
            "Image: d03dd68d9.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  83% 414/500 [01:20<00:15,  5.63it/s, Loss=0.121]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.023319337517023087\n",
            "Training Batch 415 - Positive pixels per class: [    0.     0. 23879.     0.]\n",
            "Output stats - Min: -15.84375, Max: 2.345703125\n",
            "Image: 5f33ded37.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  83% 414/500 [01:20<00:15,  5.63it/s, Loss=0.0989]Image: c389100a5.jpg | Classes present: tensor([0])\n",
            "Image: 931c4b9aa.jpg | Classes present: tensor([0])\n",
            "Image: 1ee38e570.jpg | Classes present: tensor([0])\n",
            "Image: c448a41ee.jpg | Classes present: tensor([0])\n",
            "Image: 4b925c919.jpg | Classes present: tensor([0, 2])\n",
            "Image: cc7c66720.jpg | Classes present: tensor([0])\n",
            "Image: 2453b68e2.jpg | Classes present: tensor([0])\n",
            "Image: 0f9a12222.jpg | Classes present: tensor([0])\n",
            "Image: d1fedf96b.jpg | Classes present: tensor([0])\n",
            "Image: 643f181f4.jpg | Classes present: tensor([0])\n",
            "Image: 56a9e36dd.jpg | Classes present: tensor([0])\n",
            "Image: bbc246c1b.jpg | Classes present: tensor([0])\n",
            "Image: d86727f32.jpg | Classes present: tensor([0])\n",
            "Image: 470a96423.jpg | Classes present: tensor([0])\n",
            "Image: 3a222ca8a.jpg | Classes present: tensor([0, 2])\n",
            "Image: a4d22b821.jpg | Classes present: tensor([0, 3])\n",
            "Image: cbdb0828d.jpg | Classes present: tensor([0])\n",
            "Image: 1422f2b27.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.03664258122444153\n",
            "Training Batch 416 - Positive pixels per class: [    0.     0. 16045. 21477.]\n",
            "Output stats - Min: -16.84375, Max: 2.23046875\n",
            "Image: 7ee479373.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  83% 416/500 [01:20<00:14,  5.63it/s, Loss=0.236]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.005398437846451998\n",
            "Training Batch 417 - Positive pixels per class: [   0.    0. 5528.    0.]\n",
            "Image: 7eb32e8b8.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.5078125, Max: 2.21875\n",
            "Epoch 10/10:  83% 416/500 [01:20<00:14,  5.63it/s, Loss=0.0767]Image: 6ee81c40c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6267f94de.jpg | Classes present: tensor([0])\n",
            "Image: 69231176e.jpg | Classes present: tensor([0])\n",
            "Image: 10c05e806.jpg | Classes present: tensor([0])\n",
            "Image: d68b1117c.jpg | Classes present: tensor([0, 3])\n",
            "Image: 10b23eabe.jpg | Classes present: tensor([0])\n",
            "Image: dcfd9b8c4.jpg | Classes present: tensor([0, 2])\n",
            "Image: e67ffcc83.jpg | Classes present: tensor([0])\n",
            "Image: 6ccde604d.jpg | Classes present: tensor([0])\n",
            "Image: 67a047923.jpg | Classes present: tensor([0, 2])\n",
            "Image: dccd32def.jpg | Classes present: tensor([0])\n",
            "Image: b8642bd0a.jpg | Classes present: tensor([0])\n",
            "Image: 4f6a3b984.jpg | Classes present: tensor([0])\n",
            "Image: b94f92e51.jpg | Classes present: tensor([0])\n",
            "Image: b93cc6719.jpg | Classes present: tensor([0])\n",
            "Image: ecad316bb.jpg | Classes present: tensor([0])\n",
            "Image: edbd80289.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0022568360436707735\n",
            "Training Batch 418 - Positive pixels per class: [   0.    0.  547. 1764.]\n",
            "Output stats - Min: -14.203125, Max: 1.38671875\n",
            "Image: 58fd1ce30.jpg | Classes present: tensor([0])\n",
            "Image: ef60f8163.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  84% 418/500 [01:20<00:13,  5.93it/s, Loss=0.0994]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.01502832118421793\n",
            "Training Batch 419 - Positive pixels per class: [    0.     0. 15389.     0.]\n",
            "Output stats - Min: -13.390625, Max: 2.27734375\n",
            "Epoch 10/10:  84% 418/500 [01:20<00:13,  5.93it/s, Loss=0.066] Image: c3429572b.jpg | Classes present: tensor([0])\n",
            "Image: 0c888ecb5.jpg | Classes present: tensor([0])\n",
            "Image: ec3fe85d6.jpg | Classes present: tensor([0])\n",
            "Image: 180478e66.jpg | Classes present: tensor([0])\n",
            "Image: 6d98714d9.jpg | Classes present: tensor([0, 2])\n",
            "Image: 16b7dc417.jpg | Classes present: tensor([0])\n",
            "Image: cbbe86379.jpg | Classes present: tensor([0])\n",
            "Image: 9805e5d5d.jpg | Classes present: tensor([0])\n",
            "Image: 127a4a097.jpg | Classes present: tensor([0, 2])\n",
            "Image: 82c806ebb.jpg | Classes present: tensor([0])\n",
            "Image: 8f81e6d35.jpg | Classes present: tensor([0, 2])\n",
            "Image: 460b13d7e.jpg | Classes present: tensor([0, 2])\n",
            "Image: b68a9259a.jpg | Classes present: tensor([0, 2])\n",
            "Image: cdaceb274.jpg | Classes present: tensor([0])\n",
            "Image: 2a7f8bab0.jpg | Classes present: tensor([0])\n",
            "Image: 25c0df351.jpg | Classes present: tensor([0])\n",
            "Image: 889c66e18.jpg | Classes present: tensor([0, 3])\n",
            "Image: 097eaf94c.jpg | Classes present: tensor([0])\n",
            "Image: bd967bd29.jpg | Classes present: tensor([0])\n",
            "Image: 06d0fbb0c.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0037753907963633537\n",
            "Training Batch 420 - Positive pixels per class: [   0.    0. 3110.  756.]\n",
            "Image: 286d2eb1c.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.203125, Max: 1.9130859375\n",
            "Epoch 10/10:  84% 418/500 [01:21<00:13,  5.93it/s, Loss=0.0585]Image: 9546b5abe.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  84% 420/500 [01:21<00:14,  5.69it/s, Loss=0.0585]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.022519532591104507\n",
            "Training Batch 421 - Positive pixels per class: [    0.     0. 23060.     0.]\n",
            "Image: 354bf035a.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.9609375, Max: 1.8759765625\n",
            "Image: 28f005ffe.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  84% 420/500 [01:21<00:14,  5.69it/s, Loss=0.11]  Image: 7be8a27c8.jpg | Classes present: tensor([0])\n",
            "Image: 71aec9cb8.jpg | Classes present: tensor([0])\n",
            "Image: bb24cde95.jpg | Classes present: tensor([0, 2])\n",
            "Image: 380c01646.jpg | Classes present: tensor([0])\n",
            "Image: 40c6fac5a.jpg | Classes present: tensor([0])\n",
            "Image: cfe40128c.jpg | Classes present: tensor([0])\n",
            "Image: e90e3e9e3.jpg | Classes present: tensor([0])\n",
            "Image: 5757100f0.jpg | Classes present: tensor([0])\n",
            "Image: c5b9dccf7.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8de7a3873.jpg | Classes present: tensor([0])\n",
            "Image: b19603805.jpg | Classes present: tensor([0])\n",
            "Image: 3a0e5cad8.jpg | Classes present: tensor([0])\n",
            "Image: 38c25b61a.jpg | Classes present: tensor([0])\n",
            "Image: ef5c1b08e.jpg | Classes present: tensor([0])\n",
            "Image: 614a8349b.jpg | Classes present: tensor([0])\n",
            "Image: 16aabaf79.jpg | Classes present: tensor([0])\n",
            "Image: 1ecd0214c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 60f9f7ff2.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.000946289103012532\n",
            "Training Batch 422 - Positive pixels per class: [  0.   0. 969.   0.]\n",
            "Output stats - Min: -16.03125, Max: 1.5703125\n",
            "Image: d35fb7129.jpg | Classes present: tensor([0])\n",
            "Image: c9c7d9ddb.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  84% 422/500 [01:21<00:13,  5.71it/s, Loss=0.0422]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.03416113555431366\n",
            "Training Batch 423 - Positive pixels per class: [    0.     0. 34981.     0.]\n",
            "Output stats - Min: -14.421875, Max: 2.177734375\n",
            "Image: b954698ba.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  84% 422/500 [01:21<00:13,  5.71it/s, Loss=0.0804]Image: 7c5918274.jpg | Classes present: tensor([0])\n",
            "Image: 7ec4cd778.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4a9bd840f.jpg | Classes present: tensor([0])\n",
            "Image: 3f92145f5.jpg | Classes present: tensor([0])\n",
            "Image: 306b1dbc1.jpg | Classes present: tensor([0])\n",
            "Image: 1fc012f23.jpg | Classes present: tensor([0])\n",
            "Image: dbcd9e81c.jpg | Classes present: tensor([0])\n",
            "Image: 33e32bbf2.jpg | Classes present: tensor([0])\n",
            "Image: e5d954e34.jpg | Classes present: tensor([0])\n",
            "Image: 78c34b020.jpg | Classes present: tensor([0])\n",
            "Image: c802d3e11.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4d38c353e.jpg | Classes present: tensor([0])\n",
            "Image: 8866a93f6.jpg | Classes present: tensor([0])\n",
            "Image: 352c15e36.jpg | Classes present: tensor([0])\n",
            "Image: 1b9fb7411.jpg | Classes present: tensor([0, 3])\n",
            "Image: 8d26ca58c.jpg | Classes present: tensor([0])\n",
            "Image: 41ec6505f.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.014196289703249931\n",
            "Training Batch 424 - Positive pixels per class: [    0.     0.  1851. 12686.]\n",
            "Output stats - Min: -18.578125, Max: 2.900390625\n",
            "Image: 82168bba3.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  85% 424/500 [01:21<00:13,  5.70it/s, Loss=0.136]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0020810547284781933\n",
            "Training Batch 425 - Positive pixels per class: [  18.    0. 2113.    0.]\n",
            "Image: 1d4d33873.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.515625, Max: 1.716796875\n",
            "Image: 8bb64b5b3.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  85% 424/500 [01:21<00:13,  5.70it/s, Loss=0.0424]Image: d6f5d9247.jpg | Classes present: tensor([0])\n",
            "Image: 78c25510b.jpg | Classes present: tensor([0])\n",
            "Image: 2c64d5644.jpg | Classes present: tensor([0])\n",
            "Image: 9406cb49a.jpg | Classes present: tensor([0])\n",
            "Image: 277b133dc.jpg | Classes present: tensor([0])\n",
            "Image: a49cff42b.jpg | Classes present: tensor([0])\n",
            "Image: 565cfa48c.jpg | Classes present: tensor([0])\n",
            "Image: 2c8c3cb8a.jpg | Classes present: tensor([0])\n",
            "Image: 4b16dc9ee.jpg | Classes present: tensor([0])\n",
            "Image: 675ee4ba3.jpg | Classes present: tensor([0])\n",
            "Image: dff1d028a.jpg | Classes present: tensor([0])\n",
            "Image: 575e5be94.jpg | Classes present: tensor([0])\n",
            "Image: 7638de35f.jpg | Classes present: tensor([0])\n",
            "Image: a9840c747.jpg | Classes present: tensor([0])\n",
            "Image: 0aafd7471.jpg | Classes present: tensor([0])\n",
            "Image: 4803fc0ae.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 426 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: 836ccf3b0.jpg | Classes present: tensor([0, 2])\n",
            "Output stats - Min: -15.609375, Max: 0.8642578125\n",
            "Image: 0bc3f8ce8.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  85% 426/500 [01:22<00:12,  5.87it/s, Loss=0.0347]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.004720703233033419\n",
            "Training Batch 427 - Positive pixels per class: [   0.    0. 4834.    0.]\n",
            "Image: 81f75d1b5.jpg | Classes present: tensor([0])\n",
            "Image: e40e068f3.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.359375, Max: 1.939453125\n",
            "Epoch 10/10:  85% 426/500 [01:22<00:12,  5.87it/s, Loss=0.0598]Image: 112d183e5.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2b8fcb5b7.jpg | Classes present: tensor([0])\n",
            "Image: 20617dd9a.jpg | Classes present: tensor([0])\n",
            "Image: 3af904b99.jpg | Classes present: tensor([0])\n",
            "Image: 82e82b713.jpg | Classes present: tensor([0])\n",
            "Image: 16498a156.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3c4f32f77.jpg | Classes present: tensor([0])\n",
            "Image: acb2ad63d.jpg | Classes present: tensor([0])\n",
            "Image: 0cb590f8e.jpg | Classes present: tensor([0])\n",
            "Image: 5c7613c97.jpg | Classes present: tensor([0])\n",
            "Image: a6c3abdb9.jpg | Classes present: tensor([0])\n",
            "Image: def2ff0c5.jpg | Classes present: tensor([0, 2])\n",
            "Image: e76e3e8a5.jpg | Classes present: tensor([0])\n",
            "Image: 79af8b197.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6ebc3df02.jpg | Classes present: tensor([0])\n",
            "Image: 063571c5c.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.02397461049258709\n",
            "Training Batch 428 - Positive pixels per class: [    0.     0. 24550.     0.]\n",
            "Image: 2722e2ba6.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.25, Max: 2.25390625\n",
            "Image: c71558eac.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  86% 428/500 [01:22<00:12,  5.82it/s, Loss=0.0856]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.015317383222281933\n",
            "Training Batch 429 - Positive pixels per class: [    0.     0. 15685.     0.]\n",
            "Image: 04ae7853c.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -14.7421875, Max: 2.462890625\n",
            "Image: 812ddd1e4.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  86% 428/500 [01:22<00:12,  5.82it/s, Loss=0.0627]Image: bdc4fe767.jpg | Classes present: tensor([0])\n",
            "Image: 8ae110bc5.jpg | Classes present: tensor([0])\n",
            "Image: 37da29373.jpg | Classes present: tensor([0])\n",
            "Image: ac6367260.jpg | Classes present: tensor([0])\n",
            "Image: 19a352c2f.jpg | Classes present: tensor([0])\n",
            "Image: 75e1310cc.jpg | Classes present: tensor([0])\n",
            "Image: dff14f87b.jpg | Classes present: tensor([0, 3])\n",
            "Image: 4dc35083b.jpg | Classes present: tensor([0])\n",
            "Image: 2929284cc.jpg | Classes present: tensor([0])\n",
            "Image: 8abd1fbf5.jpg | Classes present: tensor([0])\n",
            "Image: 15e512a0f.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5613bb745.jpg | Classes present: tensor([0, 2])\n",
            "Image: 63b63d495.jpg | Classes present: tensor([0])\n",
            "Image: b3d88bde6.jpg | Classes present: tensor([0, 2])\n",
            "Image: d12cfc50a.jpg | Classes present: tensor([0])\n",
            "Image: 65903909a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 76a390db7.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.041407227516174316\n",
            "Training Batch 430 - Positive pixels per class: [ 3502.     0. 38899.     0.]\n",
            "Output stats - Min: -16.390625, Max: 1.986328125\n",
            "Image: edc0d2bf8.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  86% 430/500 [01:22<00:11,  5.90it/s, Loss=0.175]Image: 62a9535b1.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.008420898579061031\n",
            "Training Batch 431 - Positive pixels per class: [   0.    0.    0. 8623.]\n",
            "Output stats - Min: -17.78125, Max: 1.7841796875\n",
            "Epoch 10/10:  86% 430/500 [01:22<00:11,  5.90it/s, Loss=0.0912]Image: 2dd360833.jpg | Classes present: tensor([0, 2])\n",
            "Image: 925f6be0d.jpg | Classes present: tensor([0])\n",
            "Image: 84ba31d0a.jpg | Classes present: tensor([0])\n",
            "Image: 616646b4d.jpg | Classes present: tensor([0])\n",
            "Image: ce68af0bf.jpg | Classes present: tensor([0])\n",
            "Image: 461f83c57.jpg | Classes present: tensor([0])\n",
            "Image: 463fe382b.jpg | Classes present: tensor([0])\n",
            "Image: 28bcb3a6e.jpg | Classes present: tensor([0])\n",
            "Image: bd54aaaea.jpg | Classes present: tensor([0])\n",
            "Image: 70be92f18.jpg | Classes present: tensor([0])\n",
            "Image: e8ea20f7f.jpg | Classes present: tensor([0])\n",
            "Image: 692c14cc2.jpg | Classes present: tensor([0])\n",
            "Image: c4c5b8e2a.jpg | Classes present: tensor([0])\n",
            "Image: a0058b3fe.jpg | Classes present: tensor([0])\n",
            "Image: c80be4ee4.jpg | Classes present: tensor([0])\n",
            "Image: 428586f79.jpg | Classes present: tensor([0])\n",
            "Image: 681d859d3.jpg | Classes present: tensor([0])\n",
            "Image: 1bd3a1f4c.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.005259765777736902\n",
            "Training Batch 432 - Positive pixels per class: [   0.    0. 5386.    0.]\n",
            "Image: 3672e84bc.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.40625, Max: 2.306640625\n",
            "Epoch 10/10:  86% 432/500 [01:23<00:11,  5.99it/s, Loss=0.0552]Image: 9c7d10c89.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.00575781287625432\n",
            "Training Batch 433 - Positive pixels per class: [   0.    0. 5896.    0.]\n",
            "Image: 9efc6682e.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.90625, Max: 1.7021484375\n",
            "Epoch 10/10:  86% 432/500 [01:23<00:11,  5.99it/s, Loss=0.0538]Image: 9252073f0.jpg | Classes present: tensor([0])\n",
            "Image: 49e3afca8.jpg | Classes present: tensor([0])\n",
            "Image: 6ed69f517.jpg | Classes present: tensor([0])\n",
            "Image: 1dd76fb74.jpg | Classes present: tensor([0])\n",
            "Image: 769fe56c3.jpg | Classes present: tensor([0])\n",
            "Image: 1af650ab4.jpg | Classes present: tensor([0])\n",
            "Image: 914b6941d.jpg | Classes present: tensor([0])\n",
            "Image: 44b8a9dec.jpg | Classes present: tensor([0])\n",
            "Image: 808c30930.jpg | Classes present: tensor([0])\n",
            "Image: 19e918673.jpg | Classes present: tensor([0])\n",
            "Image: e3e1bb16a.jpg | Classes present: tensor([0])\n",
            "Image: 757aa3828.jpg | Classes present: tensor([0])\n",
            "Image: ebce68542.jpg | Classes present: tensor([0])\n",
            "Image: c9358e43f.jpg | Classes present: tensor([0])\n",
            "Image: 33a479d47.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 434 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -15.265625, Max: 1.51953125\n",
            "Image: b1cf6d807.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  87% 434/500 [01:23<00:10,  6.19it/s, Loss=0.0636]Image: e2037da93.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 435 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -14.5078125, Max: 1.18359375\n",
            "Image: 542084ea9.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  87% 434/500 [01:23<00:10,  6.19it/s, Loss=0.0407]Image: b34272d97.jpg | Classes present: tensor([0])\n",
            "Image: 8f64891a6.jpg | Classes present: tensor([0])\n",
            "Image: 00c88fed0.jpg | Classes present: tensor([0, 1])\n",
            "Image: c3a1d6cd0.jpg | Classes present: tensor([0])\n",
            "Image: 29dc27ca2.jpg | Classes present: tensor([0])\n",
            "Image: 57c752901.jpg | Classes present: tensor([0])\n",
            "Image: 45d294946.jpg | Classes present: tensor([0, 2])\n",
            "Image: 70e4c95b6.jpg | Classes present: tensor([0])\n",
            "Image: 12c0b2b5c.jpg | Classes present: tensor([0])\n",
            "Image: d812de018.jpg | Classes present: tensor([0])\n",
            "Image: d21be4a4b.jpg | Classes present: tensor([0])\n",
            "Image: eb5d79866.jpg | Classes present: tensor([0])\n",
            "Image: 84865746c.jpg | Classes present: tensor([0])\n",
            "Image: b1e5931af.jpg | Classes present: tensor([0, 2])\n",
            "Image: 00f6e702c.jpg | Classes present: tensor([0])\n",
            "Image: 72d5da20f.jpg | Classes present: tensor([0, 2])\n",
            "Image: d30ad2e83.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.028832033276557922\n",
            "Training Batch 436 - Positive pixels per class: [  407.  4439. 24678.     0.]\n",
            "Output stats - Min: -13.3046875, Max: 1.9091796875\n",
            "Image: a8241cf3d.jpg | Classes present: tensor([0])\n",
            "Image: e857c7372.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  87% 436/500 [01:23<00:10,  6.12it/s, Loss=0.195]Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 437 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -14.8828125, Max: 0.95263671875\n",
            "Epoch 10/10:  87% 436/500 [01:23<00:10,  6.12it/s, Loss=0.0465]Image: a5e9195b6.jpg | Classes present: tensor([0, 2])\n",
            "Image: 38a1d7aab.jpg | Classes present: tensor([0])\n",
            "Image: 0518e79e9.jpg | Classes present: tensor([0])\n",
            "Image: 183383e8d.jpg | Classes present: tensor([0])\n",
            "Image: 577afb2d8.jpg | Classes present: tensor([0])\n",
            "Image: 837645cf1.jpg | Classes present: tensor([0])\n",
            "Image: 06d3a99cb.jpg | Classes present: tensor([0])\n",
            "Image: ce72a126f.jpg | Classes present: tensor([0, 3])\n",
            "Image: 79d28bbe8.jpg | Classes present: tensor([0])\n",
            "Image: defcae4cc.jpg | Classes present: tensor([0])\n",
            "Image: 7cfcbdc4a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 65eed1612.jpg | Classes present: tensor([0])\n",
            "Image: 37d48f05d.jpg | Classes present: tensor([0])\n",
            "Image: 974b07e79.jpg | Classes present: tensor([0])\n",
            "Image: deaa30604.jpg | Classes present: tensor([0])\n",
            "Image: 8299f5460.jpg | Classes present: tensor([0, 3])\n",
            "Image: 8364a4654.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0037402345333248377\n",
            "Training Batch 438 - Positive pixels per class: [   0.    0. 3830.    0.]\n",
            "Image: 56918910e.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.7734375, Max: 1.962890625\n",
            "Image: 650fa0a7a.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  88% 438/500 [01:24<00:09,  6.22it/s, Loss=0.0494]Image: 1699951da.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.02216210961341858\n",
            "Training Batch 439 - Positive pixels per class: [    0.     0. 14256.  8438.]\n",
            "Output stats - Min: -14.359375, Max: 1.6162109375\n",
            "Image: 7f281a162.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  88% 438/500 [01:24<00:09,  6.22it/s, Loss=0.119] Image: e007cfe77.jpg | Classes present: tensor([0])\n",
            "Image: c314f43f3.jpg | Classes present: tensor([0])\n",
            "Image: 97bf2a97c.jpg | Classes present: tensor([0])\n",
            "Image: 2490c490c.jpg | Classes present: tensor([0, 3])\n",
            "Image: 308cc088e.jpg | Classes present: tensor([0])\n",
            "Image: e9fa75516.jpg | Classes present: tensor([0])\n",
            "Image: 51a3f4c59.jpg | Classes present: tensor([0])\n",
            "Image: 6defb795f.jpg | Classes present: tensor([0])\n",
            "Image: 29ae2bdc9.jpg | Classes present: tensor([0])\n",
            "Image: d869026cd.jpg | Classes present: tensor([0])\n",
            "Image: 69e618f88.jpg | Classes present: tensor([0, 2])\n",
            "Image: 28edbd61f.jpg | Classes present: tensor([0, 2])\n",
            "Image: 16a1cf5b9.jpg | Classes present: tensor([0])\n",
            "Image: 498b9c526.jpg | Classes present: tensor([0])\n",
            "Image: 82f3be402.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.007727539632469416\n",
            "Training Batch 440 - Positive pixels per class: [   0.    0. 4764. 3149.]\n",
            "Output stats - Min: -15.546875, Max: 2.287109375\n",
            "Image: 5d1d529b0.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  88% 440/500 [01:24<00:09,  6.38it/s, Loss=0.0941]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.03024902567267418\n",
            "Training Batch 441 - Positive pixels per class: [  908.     0. 11967. 18100.]\n",
            "Image: 0db7ec4f0.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.3203125, Max: 2.365234375\n",
            "Epoch 10/10:  88% 440/500 [01:24<00:09,  6.38it/s, Loss=0.194] Image: 7c764812d.jpg | Classes present: tensor([0])\n",
            "Image: bc0071fd2.jpg | Classes present: tensor([0])\n",
            "Image: c6e9a9d66.jpg | Classes present: tensor([0])\n",
            "Image: 861a262c8.jpg | Classes present: tensor([0])\n",
            "Image: a725b623a.jpg | Classes present: tensor([0])\n",
            "Image: e97006670.jpg | Classes present: tensor([0])\n",
            "Image: 21f157362.jpg | Classes present: tensor([0])\n",
            "Image: 3da8dae0b.jpg | Classes present: tensor([0])\n",
            "Image: c35fa49e2.jpg | Classes present: tensor([0])\n",
            "Image: a27bd6af7.jpg | Classes present: tensor([0])\n",
            "Image: 9c4e61003.jpg | Classes present: tensor([0])\n",
            "Image: 1d7f05244.jpg | Classes present: tensor([0])\n",
            "Image: cdb6b6c23.jpg | Classes present: tensor([0])\n",
            "Image: 9d3b4a019.jpg | Classes present: tensor([0])\n",
            "Image: e63ad114c.jpg | Classes present: tensor([0])\n",
            "Image: e75c7bbd9.jpg | Classes present: tensor([0])\n",
            "Image: 650ae9b05.jpg | Classes present: tensor([0])\n",
            "Image: a567b95ad.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 442 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -15.3828125, Max: 1.505859375\n",
            "Epoch 10/10:  88% 442/500 [01:24<00:09,  6.23it/s, Loss=0.0384]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.010778320953249931\n",
            "Training Batch 443 - Positive pixels per class: [    0.     0. 11037.     0.]\n",
            "Image: 426581acf.jpg | Classes present: tensor([0])\n",
            "Image: 5238bc100.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.28125, Max: 1.689453125\n",
            "Epoch 10/10:  88% 442/500 [01:24<00:09,  6.23it/s, Loss=0.0786]Image: 4af9e9b53.jpg | Classes present: tensor([0])\n",
            "Image: 308f2e562.jpg | Classes present: tensor([0])\n",
            "Image: 207d87ea7.jpg | Classes present: tensor([0])\n",
            "Image: 6e0729dc0.jpg | Classes present: tensor([0, 2])\n",
            "Image: b6fdc1d5e.jpg | Classes present: tensor([0])\n",
            "Image: 527b50f74.jpg | Classes present: tensor([0])\n",
            "Image: d36df54f6.jpg | Classes present: tensor([0])\n",
            "Image: 43a450e62.jpg | Classes present: tensor([0])\n",
            "Image: 0888e6a84.jpg | Classes present: tensor([0])\n",
            "Image: 1e7893a11.jpg | Classes present: tensor([0])\n",
            "Image: 194cce1be.jpg | Classes present: tensor([0])\n",
            "Image: c20b32738.jpg | Classes present: tensor([0])\n",
            "Image: a912cf0b9.jpg | Classes present: tensor([0])\n",
            "Image: 6e785e50c.jpg | Classes present: tensor([0])\n",
            "Image: 6a6c25bd1.jpg | Classes present: tensor([0])\n",
            "Image: a9b4c5d52.jpg | Classes present: tensor([0])\n",
            "Image: 91222b4c9.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 444 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: dd7fcaf4e.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.1875, Max: 0.67431640625\n",
            "Epoch 10/10:  89% 444/500 [01:25<00:08,  6.43it/s, Loss=0.0426]Image: 25ccece7f.jpg | Classes present: tensor([0])\n",
            "Image: 5b1c96f09.jpg | Classes present: tensor([0])\n",
            "Image: cb0ac6c6f.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.006418945733457804\n",
            "Training Batch 445 - Positive pixels per class: [   0.    0. 6573.    0.]\n",
            "Output stats - Min: -15.6875, Max: 1.9267578125\n",
            "Image: 1b88aba1a.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  89% 444/500 [01:25<00:08,  6.43it/s, Loss=0.0603]Image: 89eec1aae.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8cd6472c3.jpg | Classes present: tensor([0])\n",
            "Image: 3ab4ca44c.jpg | Classes present: tensor([0])\n",
            "Image: cc93ff156.jpg | Classes present: tensor([0, 2])\n",
            "Image: 838135ec4.jpg | Classes present: tensor([0, 2])\n",
            "Image: 28a1ea8c2.jpg | Classes present: tensor([0, 2])\n",
            "Image: 568439b6c.jpg | Classes present: tensor([0])\n",
            "Image: ad8744ba7.jpg | Classes present: tensor([0])\n",
            "Image: 5eae1fad1.jpg | Classes present: tensor([0])\n",
            "Image: 1efdd626e.jpg | Classes present: tensor([0])\n",
            "Image: b0038b54c.jpg | Classes present: tensor([0])\n",
            "Image: acbe1e2c1.jpg | Classes present: tensor([0])\n",
            "Image: c66ba3e27.jpg | Classes present: tensor([0, 2])\n",
            "Image: 7690902ee.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.021015625447034836\n",
            "Training Batch 446 - Positive pixels per class: [    0.     0. 21520.     0.]\n",
            "Output stats - Min: -15.265625, Max: 2.771484375\n",
            "Image: 13067c801.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  89% 446/500 [01:25<00:08,  6.28it/s, Loss=0.07]Image: 9c9ea5f57.jpg | Classes present: tensor([0])\n",
            "Image: a189ded53.jpg | Classes present: tensor([0])\n",
            "Image: d23d243cc.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8f42319aa.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.010890625417232513\n",
            "Training Batch 447 - Positive pixels per class: [    0.     0. 11152.     0.]\n",
            "Output stats - Min: -13.9375, Max: 1.9296875\n",
            "Image: 7620c36fb.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  89% 447/500 [01:25<00:07,  6.63it/s, Loss=0.057]Image: ea675dd1e.jpg | Classes present: tensor([0])\n",
            "Image: db7670e3e.jpg | Classes present: tensor([0])\n",
            "Image: 5becb5ee2.jpg | Classes present: tensor([0])\n",
            "Image: a5f996baa.jpg | Classes present: tensor([0, 2])\n",
            "Image: 140e59cff.jpg | Classes present: tensor([0])\n",
            "Image: 5f2223804.jpg | Classes present: tensor([0])\n",
            "Image: ee8ab74c9.jpg | Classes present: tensor([0])\n",
            "Image: a9d3b0f3e.jpg | Classes present: tensor([0])\n",
            "Image: 54f1891ad.jpg | Classes present: tensor([0, 2])\n",
            "Image: 46e0f0f9c.jpg | Classes present: tensor([0, 2])\n",
            "Image: cdb6b6c23.jpg | Classes present: tensor([0])\n",
            "Image: dbf8177c1.jpg | Classes present: tensor([0])\n",
            "Image: 21ac40700.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0039042970165610313\n",
            "Training Batch 448 - Positive pixels per class: [   0.    0. 3998.    0.]\n",
            "Output stats - Min: -13.9765625, Max: 2.060546875\n",
            "Image: 65cdc6528.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  90% 448/500 [01:25<00:08,  6.20it/s, Loss=0.0537]Image: 29e57e1de.jpg | Classes present: tensor([0])\n",
            "Image: c98702129.jpg | Classes present: tensor([0, 3])\n",
            "Image: 9b62dc81c.jpg | Classes present: tensor([0])\n",
            "Image: 31acd60ad.jpg | Classes present: tensor([0, 2])\n",
            "Image: 190190a6f.jpg | Classes present: tensor([0, 3])\n",
            "Image: e5f9a5bb9.jpg | Classes present: tensor([0])\n",
            "Image: 759b68ebd.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.03558984398841858\n",
            "Training Batch 449 - Positive pixels per class: [    0.     0. 29354.  7090.]\n",
            "Output stats - Min: -19.046875, Max: 1.7373046875\n",
            "Epoch 10/10:  90% 449/500 [01:25<00:07,  6.42it/s, Loss=0.183]Image: 60bdfb21b.jpg | Classes present: tensor([0])\n",
            "Image: 51498e7a6.jpg | Classes present: tensor([0, 2])\n",
            "Image: b07380a2e.jpg | Classes present: tensor([0])\n",
            "Image: 2ef6ad027.jpg | Classes present: tensor([0])\n",
            "Image: 8baffdc70.jpg | Classes present: tensor([0])\n",
            "Image: cdbc4d8ec.jpg | Classes present: tensor([0])\n",
            "Image: d68320987.jpg | Classes present: tensor([0])\n",
            "Image: 7b0a87344.jpg | Classes present: tensor([0])\n",
            "Image: 16371ae14.jpg | Classes present: tensor([0])\n",
            "Image: b845c99d9.jpg | Classes present: tensor([0])\n",
            "Image: 172e692e1.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0049824221059679985\n",
            "Training Batch 450 - Positive pixels per class: [   0.    0. 4079. 1023.]\n",
            "Image: df17684d1.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.96875, Max: 1.865234375\n",
            "Image: 6f998a931.jpg | Classes present: tensor([0])\n",
            "Image: 1e1d1606e.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  90% 450/500 [01:26<00:08,  6.06it/s, Loss=0.054]Image: 342a65f7b.jpg | Classes present: tensor([0])\n",
            "Image: c084838d5.jpg | Classes present: tensor([0])\n",
            "Image: 624e942f6.jpg | Classes present: tensor([0])\n",
            "Image: 0803acf1f.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 451 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -14.328125, Max: 1.78125\n",
            "Image: 712faf067.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  90% 451/500 [01:26<00:07,  6.60it/s, Loss=0.064]Image: 9699f82fe.jpg | Classes present: tensor([0, 3])\n",
            "Image: 18bacf0e3.jpg | Classes present: tensor([0])\n",
            "Image: ca02e9e92.jpg | Classes present: tensor([0])\n",
            "Image: 4c03cad47.jpg | Classes present: tensor([0])\n",
            "Image: e941885fb.jpg | Classes present: tensor([0])\n",
            "Image: 3f2a7867c.jpg | Classes present: tensor([0])\n",
            "Image: bc9e35c07.jpg | Classes present: tensor([0])\n",
            "Image: c199d741a.jpg | Classes present: tensor([0])\n",
            "Image: 105f93d9e.jpg | Classes present: tensor([0])\n",
            "Image: 55303df62.jpg | Classes present: tensor([0])\n",
            "Image: 1849f8952.jpg | Classes present: tensor([0])\n",
            "Image: d07afd5bf.jpg | Classes present: tensor([0])\n",
            "Image: 88f00028d.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.011872070841491222\n",
            "Training Batch 452 - Positive pixels per class: [    0.     0.     0. 12157.]\n",
            "Output stats - Min: -14.3828125, Max: 2.466796875\n",
            "Image: 672a24d19.jpg | Classes present: tensor([0])\n",
            "Image: de85a0a75.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  90% 452/500 [01:26<00:08,  5.85it/s, Loss=0.178]Image: 868759698.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3beb63791.jpg | Classes present: tensor([0])\n",
            "Image: ab0010546.jpg | Classes present: tensor([0])\n",
            "Image: 9741c9475.jpg | Classes present: tensor([0, 3])\n",
            "Image: cac09c825.jpg | Classes present: tensor([0])\n",
            "Image: 44c129ab7.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.010504883714020252\n",
            "Training Batch 453 - Positive pixels per class: [    0.     0. 10757.     0.]\n",
            "Output stats - Min: -17.171875, Max: 2.087890625\n",
            "Epoch 10/10:  91% 453/500 [01:26<00:07,  6.23it/s, Loss=0.0585]Image: afbab41f0.jpg | Classes present: tensor([0])\n",
            "Image: b38f593fd.jpg | Classes present: tensor([0, 3])\n",
            "Image: 5a9f713f3.jpg | Classes present: tensor([0])\n",
            "Image: 73d8f9fa7.jpg | Classes present: tensor([0, 2])\n",
            "Image: 59b3bbeaf.jpg | Classes present: tensor([0])\n",
            "Image: d37fb426f.jpg | Classes present: tensor([0])\n",
            "Image: 9661e7677.jpg | Classes present: tensor([0, 2])\n",
            "Image: db03ee270.jpg | Classes present: tensor([0, 2])\n",
            "Image: cd7d5af6d.jpg | Classes present: tensor([0])\n",
            "Image: 116d673e3.jpg | Classes present: tensor([0, 2])\n",
            "Image: 82cf55ab9.jpg | Classes present: tensor([0])\n",
            "Image: 8e11e6dff.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.03889257833361626\n",
            "Training Batch 454 - Positive pixels per class: [    0.     0. 33906.  5920.]\n",
            "Image: 5ec5dd646.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.71875, Max: 2.6171875\n",
            "Image: 767b96d1a.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  91% 454/500 [01:26<00:08,  5.25it/s, Loss=0.156]Image: ce7570214.jpg | Classes present: tensor([0])\n",
            "Image: 221f866cc.jpg | Classes present: tensor([0])\n",
            "Image: 28a3f7928.jpg | Classes present: tensor([0])\n",
            "Image: 79730ecdc.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.027750002220273018\n",
            "Training Batch 455 - Positive pixels per class: [    0.     0. 27248.  1168.]\n",
            "Image: baa9d44b3.jpg | Classes present: tensor([0])\n",
            "Image: 8f0e1809d.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.21875, Max: 2.205078125\n",
            "Epoch 10/10:  91% 455/500 [01:27<00:08,  5.51it/s, Loss=0.0907]Image: 98e2146e9.jpg | Classes present: tensor([0])\n",
            "Image: 42b398dcf.jpg | Classes present: tensor([0])\n",
            "Image: 4dba4db98.jpg | Classes present: tensor([0, 2])\n",
            "Image: 85e44e158.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8fc48f131.jpg | Classes present: tensor([0])\n",
            "Image: 7fc7bab6b.jpg | Classes present: tensor([0])\n",
            "Image: c0e730a68.jpg | Classes present: tensor([0])\n",
            "Image: 79f669380.jpg | Classes present: tensor([0])\n",
            "Image: 45a59cfec.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4ea0f4710.jpg | Classes present: tensor([0])\n",
            "Image: 1bb1e1055.jpg | Classes present: tensor([0])\n",
            "Image: 0d7e52a91.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.00028222656692378223\n",
            "Training Batch 456 - Positive pixels per class: [  0.   0. 289.   0.]\n",
            "Image: 01053d28f.jpg | Classes present: tensor([0])\n",
            "Image: 86ded721f.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.59375, Max: 1.1689453125\n",
            "Image: 41b122bb7.jpg | Classes present: tensor([0])\n",
            "Image: 8c1fe4329.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  91% 456/500 [01:27<00:11,  3.83it/s, Loss=0.0363]Image: e42311f08.jpg | Classes present: tensor([0])\n",
            "Image: e96249f5a.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.027792969718575478\n",
            "Training Batch 457 - Positive pixels per class: [    0.     0. 28460.     0.]\n",
            "Image: 13fa1d70d.jpg | Classes present: tensor([0, 3])\n",
            "Image: 46655e050.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.109375, Max: 2.259765625\n",
            "Epoch 10/10:  91% 457/500 [01:27<00:09,  4.35it/s, Loss=0.0645]Image: 8a642f9d3.jpg | Classes present: tensor([0])\n",
            "Image: 87e990d66.jpg | Classes present: tensor([0])\n",
            "Image: a81d409c6.jpg | Classes present: tensor([0])\n",
            "Image: 06f4583b1.jpg | Classes present: tensor([0])\n",
            "Image: 06e6582af.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5a03cd4f1.jpg | Classes present: tensor([0])\n",
            "Image: ced626afb.jpg | Classes present: tensor([0])\n",
            "Image: edcf5abf7.jpg | Classes present: tensor([0])\n",
            "Image: 0b475b419.jpg | Classes present: tensor([0])\n",
            "Image: d571030d2.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.007066406775265932\n",
            "Training Batch 458 - Positive pixels per class: [   0.    0. 4161. 3075.]\n",
            "Output stats - Min: -13.7109375, Max: 1.6044921875\n",
            "Epoch 10/10:  92% 458/500 [01:27<00:10,  4.13it/s, Loss=0.0835]Image: 712f7df78.jpg | Classes present: tensor([0])\n",
            "Image: 5affd9802.jpg | Classes present: tensor([0])\n",
            "Image: 4787645e5.jpg | Classes present: tensor([0])\n",
            "Image: dabbc106c.jpg | Classes present: tensor([0])\n",
            "Image: 9271c7e3d.jpg | Classes present: tensor([0])\n",
            "Image: 9f179959b.jpg | Classes present: tensor([0])\n",
            "Image: 2cfa7ea6f.jpg | Classes present: tensor([0])\n",
            "Image: e831de714.jpg | Classes present: tensor([0])\n",
            "Image: cdb3a875b.jpg | Classes present: tensor([0])\n",
            "Image: 64ca31bd3.jpg | Classes present: tensor([0, 2])\n",
            "Image: 37782387c.jpg | Classes present: tensor([0])\n",
            "Image: a01c8ce20.jpg | Classes present: tensor([0])\n",
            "Image: d665abf9d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8faba402b.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0135878911241889\n",
            "Training Batch 459 - Positive pixels per class: [    0.     0. 13914.     0.]\n",
            "Output stats - Min: -15.9375, Max: 1.97265625\n",
            "Epoch 10/10:  92% 459/500 [01:28<00:11,  3.72it/s, Loss=0.0629]Image: 0fa3f0dab.jpg | Classes present: tensor([0])\n",
            "Image: 72cbdf3c1.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 460 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -16.734375, Max: 2.279296875\n",
            "Epoch 10/10:  92% 459/500 [01:28<00:11,  3.72it/s, Loss=0.0479]Image: 676de457e.jpg | Classes present: tensor([0])\n",
            "Image: 74e593376.jpg | Classes present: tensor([0])\n",
            "Image: 8bd35f020.jpg | Classes present: tensor([0])\n",
            "Image: d8254a8ee.jpg | Classes present: tensor([0, 2])\n",
            "Image: a7942bafe.jpg | Classes present: tensor([0])\n",
            "Image: 3ca970143.jpg | Classes present: tensor([0])\n",
            "Image: 7c3a553d0.jpg | Classes present: tensor([0])\n",
            "Image: 58ee62fd7.jpg | Classes present: tensor([0])\n",
            "Image: ee3ace56f.jpg | Classes present: tensor([0, 3])\n",
            "Image: 764fa24b0.jpg | Classes present: tensor([0, 3])\n",
            "Image: 3b2f9b14d.jpg | Classes present: tensor([0])\n",
            "Image: 751db247d.jpg | Classes present: tensor([0])\n",
            "Image: bdff0aefc.jpg | Classes present: tensor([0])\n",
            "Image: 9dc65bc1e.jpg | Classes present: tensor([0, 1])\n",
            "Image: 21ea71d4a.jpg | Classes present: tensor([0])\n",
            "Image: b4d920147.jpg | Classes present: tensor([0])\n",
            "Image: 5f28ca6de.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8484468e0.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.032704103738069534\n",
            "Training Batch 461 - Positive pixels per class: [    0.  5282. 17908. 10299.]\n",
            "Output stats - Min: -15.609375, Max: 2.044921875\n",
            "Epoch 10/10:  92% 461/500 [01:28<00:10,  3.73it/s, Loss=0.266]Image: 401614c72.jpg | Classes present: tensor([0])\n",
            "Image: 519599df3.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0035429690033197403\n",
            "Training Batch 462 - Positive pixels per class: [   0.    0.  146. 3482.]\n",
            "Image: 73afc8798.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.65625, Max: 1.4892578125\n",
            "Image: 9eace863c.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  92% 461/500 [01:28<00:10,  3.73it/s, Loss=0.0677]Image: caf49d870.jpg | Classes present: tensor([0])\n",
            "Image: 7329b8668.jpg | Classes present: tensor([0])\n",
            "Image: 26b0e74fe.jpg | Classes present: tensor([0])\n",
            "Image: a2444ac38.jpg | Classes present: tensor([0])\n",
            "Image: 9844183a4.jpg | Classes present: tensor([0])\n",
            "Image: 82d728afa.jpg | Classes present: tensor([0])\n",
            "Image: 1cb27ff90.jpg | Classes present: tensor([0])\n",
            "Image: eec5da0ae.jpg | Classes present: tensor([0, 2])\n",
            "Image: 218bbc6fe.jpg | Classes present: tensor([0])\n",
            "Image: 653eb7e80.jpg | Classes present: tensor([0])\n",
            "Image: c9415c620.jpg | Classes present: tensor([0])\n",
            "Image: c89490346.jpg | Classes present: tensor([0])\n",
            "Image: baba8612a.jpg | Classes present: tensor([0])\n",
            "Image: b93118acc.jpg | Classes present: tensor([0])\n",
            "Image: 4c47ebc03.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 463 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: 384f7f848.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.28125, Max: 1.09375\n",
            "Image: 94da85f76.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  93% 463/500 [01:29<00:10,  3.59it/s, Loss=0.0375]Image: e0593f542.jpg | Classes present: tensor([0])\n",
            "Image: 97a67b410.jpg | Classes present: tensor([0, 2])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.00015722657553851604\n",
            "Training Batch 464 - Positive pixels per class: [  0.   0. 161.   0.]\n",
            "Output stats - Min: -14.9375, Max: 1.3837890625\n",
            "Epoch 10/10:  93% 464/500 [01:29<00:08,  4.13it/s, Loss=0.0576]Image: 8ee7a7a6a.jpg | Classes present: tensor([0])\n",
            "Image: 7c6e58a02.jpg | Classes present: tensor([0])\n",
            "Image: b1fd37779.jpg | Classes present: tensor([0])\n",
            "Image: 47111332b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3b35a1f8e.jpg | Classes present: tensor([0, 3])\n",
            "Image: 8e85eb81f.jpg | Classes present: tensor([0])\n",
            "Image: b3ff830e0.jpg | Classes present: tensor([0])\n",
            "Image: 44ad9ef30.jpg | Classes present: tensor([0])\n",
            "Image: eebcc0af3.jpg | Classes present: tensor([0])\n",
            "Image: 394edb848.jpg | Classes present: tensor([0])\n",
            "Image: 9f15729ba.jpg | Classes present: tensor([0])\n",
            "Image: de15e1a31.jpg | Classes present: tensor([0])\n",
            "Image: 3c4cc1168.jpg | Classes present: tensor([0, 2])\n",
            "Image: 7b80d479b.jpg | Classes present: tensor([0, 2])\n",
            "Image: a6aceec2e.jpg | Classes present: tensor([0])\n",
            "Image: 7420f27c9.jpg | Classes present: tensor([0])\n",
            "Image: c6cac1cac.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.007592773996293545\n",
            "Training Batch 465 - Positive pixels per class: [   0.    0. 7775.    0.]\n",
            "Image: be04fa57f.jpg | Classes present: tensor([0])\n",
            "Image: b6d964955.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.578125, Max: 1.7861328125\n",
            "Epoch 10/10:  93% 465/500 [01:29<00:10,  3.32it/s, Loss=0.0531]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.011177734471857548\n",
            "Training Batch 466 - Positive pixels per class: [ 245.    0. 7969. 3232.]\n",
            "Output stats - Min: -16.125, Max: 2.22265625\n",
            "Image: 2c6b52b3f.jpg | Classes present: tensor([0, 2])\n",
            "Image: 294c646fd.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  93% 465/500 [01:30<00:10,  3.32it/s, Loss=0.0977]Image: b6a5c7a5b.jpg | Classes present: tensor([0])\n",
            "Image: 167ae556b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 286f459e6.jpg | Classes present: tensor([0])\n",
            "Image: 0046839bd.jpg | Classes present: tensor([0])\n",
            "Image: a98f00f6b.jpg | Classes present: tensor([0])\n",
            "Image: 98bb49ca7.jpg | Classes present: tensor([0])\n",
            "Image: abedd15e2.jpg | Classes present: tensor([0])\n",
            "Image: 0db448eb7.jpg | Classes present: tensor([0])\n",
            "Image: 428ebe246.jpg | Classes present: tensor([0])\n",
            "Image: 048d14d3f.jpg | Classes present: tensor([0])\n",
            "Image: 994aa6f1d.jpg | Classes present: tensor([0])\n",
            "Image: 62a1af2c1.jpg | Classes present: tensor([0])\n",
            "Image: 832c4b74c.jpg | Classes present: tensor([0, 2])\n",
            "Image: b0f9fff35.jpg | Classes present: tensor([0])\n",
            "Image: a69fb48e2.jpg | Classes present: tensor([0])\n",
            "Image: c686055be.jpg | Classes present: tensor([0])\n",
            "Image: da30cbaf7.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.02120019681751728\n",
            "Training Batch 467 - Positive pixels per class: [    0.     0. 21709.     0.]\n",
            "Image: 390e9ea29.jpg | Classes present: tensor([0])\n",
            "Image: e30a322d7.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.625, Max: 2.10546875\n",
            "Epoch 10/10:  93% 467/500 [01:30<00:10,  3.30it/s, Loss=0.0644]Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 468 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: 2cf9274ea.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.953125, Max: 1.1787109375\n",
            "Image: 843b29efa.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  93% 467/500 [01:30<00:10,  3.30it/s, Loss=0.0572]Image: 460d229ec.jpg | Classes present: tensor([0])\n",
            "Image: 6c1bc5d11.jpg | Classes present: tensor([0])\n",
            "Image: b1933b386.jpg | Classes present: tensor([0])\n",
            "Image: 618f0ff16.jpg | Classes present: tensor([0])\n",
            "Image: 6fd820bb6.jpg | Classes present: tensor([0])\n",
            "Image: 2757df221.jpg | Classes present: tensor([0])\n",
            "Image: dcebef38e.jpg | Classes present: tensor([0])\n",
            "Image: 8ed3c433b.jpg | Classes present: tensor([0])\n",
            "Image: ec37ebae6.jpg | Classes present: tensor([0])\n",
            "Image: e8a04b4f8.jpg | Classes present: tensor([0])\n",
            "Image: a4334d7da.jpg | Classes present: tensor([0, 3])\n",
            "Image: 66e89afaa.jpg | Classes present: tensor([0])\n",
            "Image: 07c8ba1d5.jpg | Classes present: tensor([0, 2])\n",
            "Image: 36979a804.jpg | Classes present: tensor([0])\n",
            "Image: b754c1efe.jpg | Classes present: tensor([0])\n",
            "Image: 961333d4e.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.004916016012430191\n",
            "Training Batch 469 - Positive pixels per class: [   0.    0. 1495. 3539.]\n",
            "Output stats - Min: -15.484375, Max: 1.6181640625\n",
            "Image: 431234941.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  94% 469/500 [01:31<00:08,  3.47it/s, Loss=0.0724]Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 470 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: 6966ed5f1.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.5078125, Max: 1.1474609375\n",
            "Image: e7d7c87e2.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  94% 469/500 [01:31<00:08,  3.47it/s, Loss=0.0583]Image: cf5e8eb2c.jpg | Classes present: tensor([0])\n",
            "Image: 9ea9ca4c8.jpg | Classes present: tensor([0])\n",
            "Image: ed3615966.jpg | Classes present: tensor([0])\n",
            "Image: a0c650375.jpg | Classes present: tensor([0])\n",
            "Image: d32f48999.jpg | Classes present: tensor([0])\n",
            "Image: ba7ed19b3.jpg | Classes present: tensor([0])\n",
            "Image: 6458159d8.jpg | Classes present: tensor([0, 2])\n",
            "Image: 443f8564b.jpg | Classes present: tensor([0])\n",
            "Image: 741a5c461.jpg | Classes present: tensor([0])\n",
            "Image: 0da1c044f.jpg | Classes present: tensor([0])\n",
            "Image: 715a4faf3.jpg | Classes present: tensor([0])\n",
            "Image: b8f684e65.jpg | Classes present: tensor([0])\n",
            "Image: 961c828de.jpg | Classes present: tensor([0])\n",
            "Image: 409453bc7.jpg | Classes present: tensor([0])\n",
            "Image: ccd0ad960.jpg | Classes present: tensor([0])\n",
            "Image: c3d7412a0.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.017213867977261543\n",
            "Training Batch 471 - Positive pixels per class: [    0.     0. 17627.     0.]\n",
            "Image: 81ff630e3.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.328125, Max: 2.46875\n",
            "Image: ce54cb872.jpg | Classes present: tensor([0])\n",
            "Image: 7abd14b6a.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  94% 471/500 [01:31<00:07,  4.01it/s, Loss=0.0649]Image: 44bddb2d2.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 472 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -20.078125, Max: 1.2763671875\n",
            "Image: 646a4e69a.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  94% 471/500 [01:31<00:07,  4.01it/s, Loss=0.0325]Image: c9091a2ef.jpg | Classes present: tensor([0])\n",
            "Image: b448498eb.jpg | Classes present: tensor([0])\n",
            "Image: 1b12de419.jpg | Classes present: tensor([0])\n",
            "Image: b4efa00f7.jpg | Classes present: tensor([0])\n",
            "Image: d62e553a8.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8d5fd264c.jpg | Classes present: tensor([0])\n",
            "Image: 9202ebeb6.jpg | Classes present: tensor([0])\n",
            "Image: 72aaba8ad.jpg | Classes present: tensor([0])\n",
            "Image: d8a8fed32.jpg | Classes present: tensor([0])\n",
            "Image: 44aea3a11.jpg | Classes present: tensor([0])\n",
            "Image: 82f6ab6aa.jpg | Classes present: tensor([0])\n",
            "Image: c78f55508.jpg | Classes present: tensor([0])\n",
            "Image: a9945ecd5.jpg | Classes present: tensor([0])\n",
            "Image: 5a6a8196b.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0025273438077419996\n",
            "Training Batch 473 - Positive pixels per class: [ 588.    0. 2000.    0.]\n",
            "Image: e078bff60.jpg | Classes present: tensor([0, 2])\n",
            "Output stats - Min: -17.21875, Max: 1.5791015625\n",
            "Image: 4bf953606.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  95% 473/500 [01:31<00:05,  4.54it/s, Loss=0.0519]Image: bbaeed54e.jpg | Classes present: tensor([0, 3])\n",
            "Image: 71553a0d8.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 474 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Output stats - Min: -17.84375, Max: 1.3173828125\n",
            "Image: 62c1c5dcb.jpg | Classes present: tensor([0, 2])\n",
            "Image: c80f387aa.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  95% 473/500 [01:31<00:05,  4.54it/s, Loss=0.0334]Image: 37f4c573f.jpg | Classes present: tensor([0])\n",
            "Image: ac172af5a.jpg | Classes present: tensor([0])\n",
            "Image: 97bbf0668.jpg | Classes present: tensor([0])\n",
            "Image: 58b26c5f1.jpg | Classes present: tensor([0])\n",
            "Image: cc73c4765.jpg | Classes present: tensor([0])\n",
            "Image: 7e18303fd.jpg | Classes present: tensor([0])\n",
            "Image: dfc895f18.jpg | Classes present: tensor([0])\n",
            "Image: 52122168a.jpg | Classes present: tensor([0])\n",
            "Image: 398ff41cf.jpg | Classes present: tensor([0])\n",
            "Image: 83eb3fd63.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2507ce3e3.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6190fe546.jpg | Classes present: tensor([0])\n",
            "Image: 6d1467855.jpg | Classes present: tensor([0])\n",
            "Image: 1b5427b35.jpg | Classes present: tensor([0])\n",
            "Image: 044700866.jpg | Classes present: tensor([0, 3])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.028098633512854576\n",
            "Training Batch 475 - Positive pixels per class: [    0.     0.  9957. 18816.]\n",
            "Output stats - Min: -16.921875, Max: 1.7900390625\n",
            "Image: 94a97adc8.jpg | Classes present: tensor([0])\n",
            "Image: 8bc5aeca3.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  95% 475/500 [01:32<00:05,  4.92it/s, Loss=0.159]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.013044922612607479\n",
            "Training Batch 476 - Positive pixels per class: [   0.    0. 8691. 4667.]\n",
            "Output stats - Min: -15.8515625, Max: 1.990234375\n",
            "Image: 21eb1e1aa.jpg | Classes present: tensor([0])\n",
            "Image: e1560e1d0.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  95% 475/500 [01:32<00:05,  4.92it/s, Loss=0.106]Image: ca3f209ad.jpg | Classes present: tensor([0, 2])\n",
            "Image: c87ca8539.jpg | Classes present: tensor([0])\n",
            "Image: addd390e9.jpg | Classes present: tensor([0])\n",
            "Image: a430d56ba.jpg | Classes present: tensor([0])\n",
            "Image: 6f0683e45.jpg | Classes present: tensor([0])\n",
            "Image: 66e43edf6.jpg | Classes present: tensor([0])\n",
            "Image: 71ce72925.jpg | Classes present: tensor([0])\n",
            "Image: 6395f8bf1.jpg | Classes present: tensor([0])\n",
            "Image: 89332ba01.jpg | Classes present: tensor([0])\n",
            "Image: 01cf446d4.jpg | Classes present: tensor([0])\n",
            "Image: 8516fcc92.jpg | Classes present: tensor([0])\n",
            "Image: 1298b6dbb.jpg | Classes present: tensor([0])\n",
            "Image: 3ce4ece71.jpg | Classes present: tensor([0])\n",
            "Image: cb933c3e8.jpg | Classes present: tensor([0, 2])\n",
            "Image: 84df99a15.jpg | Classes present: tensor([0])\n",
            "Image: a922818e9.jpg | Classes present: tensor([0])\n",
            "Image: c23ef14ee.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.015193359926342964\n",
            "Training Batch 477 - Positive pixels per class: [  612.     0. 14946.     0.]\n",
            "Output stats - Min: -14.375, Max: 2.59765625\n",
            "Image: 3a14b011a.jpg | Classes present: tensor([0])\n",
            "Image: 4cbb91ed2.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  95% 477/500 [01:32<00:04,  5.08it/s, Loss=0.0729]Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Training Batch 478 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: eee142d9a.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.015625, Max: 0.9248046875\n",
            "Epoch 10/10:  95% 477/500 [01:32<00:04,  5.08it/s, Loss=0.0528]Image: ab312df89.jpg | Classes present: tensor([0])\n",
            "Image: 3856224a4.jpg | Classes present: tensor([0, 2])\n",
            "Image: d614b65db.jpg | Classes present: tensor([0])\n",
            "Image: 2749c24a9.jpg | Classes present: tensor([0])\n",
            "Image: 363eb9fdc.jpg | Classes present: tensor([0])\n",
            "Image: 7a8a7403c.jpg | Classes present: tensor([0])\n",
            "Image: c14eabf41.jpg | Classes present: tensor([0])\n",
            "Image: c24f45fd3.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0ee20797b.jpg | Classes present: tensor([0])\n",
            "Image: 4353697d9.jpg | Classes present: tensor([0])\n",
            "Image: c83b606d1.jpg | Classes present: tensor([0])\n",
            "Image: dbe3f3192.jpg | Classes present: tensor([0])\n",
            "Image: 55c689cd0.jpg | Classes present: tensor([0])\n",
            "Image: 9d7ed0880.jpg | Classes present: tensor([0])\n",
            "Image: 548f2444a.jpg | Classes present: tensor([0, 2])\n",
            "Image: d802b10c5.jpg | Classes present: tensor([0])\n",
            "Image: 2eae7322b.jpg | Classes present: tensor([0])\n",
            "Image: c048dbdc5.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.00012011719081783667\n",
            "Training Batch 479 - Positive pixels per class: [  0.   0. 123.   0.]\n",
            "Image: aa626ae0c.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.15625, Max: 1.4228515625\n",
            "Epoch 10/10:  96% 479/500 [01:32<00:03,  5.35it/s, Loss=0.0559]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.019346680492162704\n",
            "Training Batch 480 - Positive pixels per class: [    0.     0. 19811.     0.]\n",
            "Image: 4d57922af.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -14.734375, Max: 1.9150390625\n",
            "Image: 9612cf3ee.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  96% 479/500 [01:32<00:03,  5.35it/s, Loss=0.0701]Image: 5188851b2.jpg | Classes present: tensor([0])\n",
            "Image: eb0969906.jpg | Classes present: tensor([0])\n",
            "Image: b3e51537d.jpg | Classes present: tensor([0])\n",
            "Image: a045e21e6.jpg | Classes present: tensor([0])\n",
            "Image: 3974a2a75.jpg | Classes present: tensor([0])\n",
            "Image: e7758b305.jpg | Classes present: tensor([0])\n",
            "Image: cc02b6f5a.jpg | Classes present: tensor([0])\n",
            "Image: 95b95a425.jpg | Classes present: tensor([0, 2])\n",
            "Image: e8fefd824.jpg | Classes present: tensor([0])\n",
            "Image: 3f3ddfea8.jpg | Classes present: tensor([0])\n",
            "Image: 046c35525.jpg | Classes present: tensor([0])\n",
            "Image: 71f154968.jpg | Classes present: tensor([0])\n",
            "Image: b3b742102.jpg | Classes present: tensor([0])\n",
            "Image: 62e356985.jpg | Classes present: tensor([0])\n",
            "Image: bb9bfedfd.jpg | Classes present: tensor([0, 3])\n",
            "Image: df4d01acb.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.011418946087360382\n",
            "Training Batch 481 - Positive pixels per class: [    0.     0.     0. 11693.]\n",
            "Output stats - Min: -14.171875, Max: 2.076171875\n",
            "Image: 3a7d9b5c1.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  96% 481/500 [01:33<00:03,  5.66it/s, Loss=0.108]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.004440430086106062\n",
            "Training Batch 482 - Positive pixels per class: [   0.    0. 4547.    0.]\n",
            "Image: 70807c2c5.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -15.8828125, Max: 1.6552734375\n",
            "Image: aa49482e5.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  96% 481/500 [01:33<00:03,  5.66it/s, Loss=0.076]Image: 0c888ecb5.jpg | Classes present: tensor([0])\n",
            "Image: 37bc122bd.jpg | Classes present: tensor([0])\n",
            "Image: 6336c7ef4.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8e01fb963.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3c9b7b316.jpg | Classes present: tensor([0])\n",
            "Image: 933675d91.jpg | Classes present: tensor([0])\n",
            "Image: 18c141479.jpg | Classes present: tensor([0])\n",
            "Image: 9531c4b99.jpg | Classes present: tensor([0])\n",
            "Image: 818a68773.jpg | Classes present: tensor([0])\n",
            "Image: 50b542cdd.jpg | Classes present: tensor([0])\n",
            "Image: ce0b7102f.jpg | Classes present: tensor([0])\n",
            "Image: ef8ba30c0.jpg | Classes present: tensor([0])\n",
            "Image: 5e5f3ea95.jpg | Classes present: tensor([0])\n",
            "Image: 0391d44d6.jpg | Classes present: tensor([0])\n",
            "Image: 8d9b704ff.jpg | Classes present: tensor([0])\n",
            "Image: c0eb3a086.jpg | Classes present: tensor([0])\n",
            "Image: 24066d57e.jpg | Classes present: tensor([0])\n",
            "Image: e9ed21340.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.00815136730670929\n",
            "Training Batch 483 - Positive pixels per class: [   0.    0. 8347.    0.]\n",
            "Output stats - Min: -14.546875, Max: 1.755859375\n",
            "Image: 7a807824c.jpg | Classes present: tensor([0])\n",
            "Image: 07ba16aba.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  97% 483/500 [01:33<00:02,  5.80it/s, Loss=0.0477]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0003828125190921128\n",
            "Training Batch 484 - Positive pixels per class: [  0.   0. 392.   0.]\n",
            "Output stats - Min: -16.59375, Max: 1.05078125\n",
            "Epoch 10/10:  97% 483/500 [01:33<00:02,  5.80it/s, Loss=0.0507]Image: e29f1a47a.jpg | Classes present: tensor([0])\n",
            "Image: 303f25bee.jpg | Classes present: tensor([0])\n",
            "Image: 5b202c6f5.jpg | Classes present: tensor([0])\n",
            "Image: 19955420c.jpg | Classes present: tensor([0])\n",
            "Image: 2434f1395.jpg | Classes present: tensor([0, 2])\n",
            "Image: d96428a9e.jpg | Classes present: tensor([0])\n",
            "Image: 64361cd8b.jpg | Classes present: tensor([0, 2])\n",
            "Image: ada844648.jpg | Classes present: tensor([0])\n",
            "Image: 39ae1a183.jpg | Classes present: tensor([0, 3])\n",
            "Image: 3ae2aba5e.jpg | Classes present: tensor([0])\n",
            "Image: 3221a0d79.jpg | Classes present: tensor([0])\n",
            "Image: c0dee2521.jpg | Classes present: tensor([0])\n",
            "Image: cfedba84c.jpg | Classes present: tensor([0])\n",
            "Image: 49416ce82.jpg | Classes present: tensor([0])\n",
            "Image: 50de95d7f.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2a4e81982.jpg | Classes present: tensor([0])\n",
            "Image: a29c6239f.jpg | Classes present: tensor([0])\n",
            "Image: d4ce2a21d.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0012753907358273864\n",
            "Training Batch 485 - Positive pixels per class: [   0.    0. 1306.    0.]\n",
            "Output stats - Min: -14.984375, Max: 1.875\n",
            "Image: 0a9aaba9a.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  97% 485/500 [01:33<00:02,  5.80it/s, Loss=0.0471]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.03254882991313934\n",
            "Training Batch 486 - Positive pixels per class: [    0.     0. 20115. 13215.]\n",
            "Image: 2dbd01639.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -13.390625, Max: 1.9306640625\n",
            "Epoch 10/10:  97% 485/500 [01:33<00:02,  5.80it/s, Loss=0.147] Image: 7202e52d8.jpg | Classes present: tensor([0])\n",
            "Image: ce93931e9.jpg | Classes present: tensor([0])\n",
            "Image: e816d6d9a.jpg | Classes present: tensor([0])\n",
            "Image: 16c60441c.jpg | Classes present: tensor([0])\n",
            "Image: 702bf6ed3.jpg | Classes present: tensor([0])\n",
            "Image: 7dcd46899.jpg | Classes present: tensor([0, 1])\n",
            "Image: 39b2dbb9b.jpg | Classes present: tensor([0])\n",
            "Image: 1897882a1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 21fb2df8d.jpg | Classes present: tensor([0])\n",
            "Image: eb3f5c9c8.jpg | Classes present: tensor([0])\n",
            "Image: e3e8594fa.jpg | Classes present: tensor([0])\n",
            "Image: eaebc549c.jpg | Classes present: tensor([0])\n",
            "Image: 62f1544bb.jpg | Classes present: tensor([0, 2])\n",
            "Image: 975e50a09.jpg | Classes present: tensor([0])\n",
            "Image: 2a5fe1870.jpg | Classes present: tensor([0])\n",
            "Image: d89d52e53.jpg | Classes present: tensor([0])\n",
            "Image: 117ddaa9f.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.021808594465255737\n",
            "Training Batch 487 - Positive pixels per class: [  338.  2852. 19142.     0.]\n",
            "Image: 782cfb1c5.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -17.71875, Max: 2.375\n",
            "Image: 7eb958c89.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  97% 487/500 [01:34<00:02,  5.87it/s, Loss=0.19]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.004485351964831352\n",
            "Training Batch 488 - Positive pixels per class: [   0.    0. 4593.    0.]\n",
            "Output stats - Min: -18.203125, Max: 2.056640625\n",
            "Image: 917cdbff6.jpg | Classes present: tensor([0])\n",
            "Image: 0970201e2.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  97% 487/500 [01:34<00:02,  5.87it/s, Loss=0.0403]Image: 6cbc3708d.jpg | Classes present: tensor([0])\n",
            "Image: ec5abc2f0.jpg | Classes present: tensor([0])\n",
            "Image: 3df2a0383.jpg | Classes present: tensor([0])\n",
            "Image: de001c4e1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 30070d59d.jpg | Classes present: tensor([0])\n",
            "Image: 36a3259fa.jpg | Classes present: tensor([0, 2])\n",
            "Image: 35ce31284.jpg | Classes present: tensor([0])\n",
            "Image: 6d9559d13.jpg | Classes present: tensor([0])\n",
            "Image: 9b1abd245.jpg | Classes present: tensor([0])\n",
            "Image: 4f64d3b50.jpg | Classes present: tensor([0])\n",
            "Image: bbc81b646.jpg | Classes present: tensor([0])\n",
            "Image: 685593407.jpg | Classes present: tensor([0])\n",
            "Image: 8ed87432c.jpg | Classes present: tensor([0])\n",
            "Image: 0bb37f2aa.jpg | Classes present: tensor([0])\n",
            "Image: 99923d074.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0009746094001457095\n",
            "Training Batch 489 - Positive pixels per class: [998.   0.   0.   0.]\n",
            "Output stats - Min: -16.984375, Max: 1.5361328125\n",
            "Image: d0d818b7d.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  98% 489/500 [01:34<00:01,  6.24it/s, Loss=0.0765]Image: 09140dda7.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.027222657576203346\n",
            "Training Batch 490 - Positive pixels per class: [    0.     0. 27876.     0.]\n",
            "Output stats - Min: -15.8125, Max: 2.15234375\n",
            "Image: 448e30068.jpg | Classes present: tensor([0])\n",
            "Image: ec3fe85d6.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  98% 489/500 [01:34<00:01,  6.24it/s, Loss=0.0659]Image: ae9a53e90.jpg | Classes present: tensor([0])\n",
            "Image: 596c1c20f.jpg | Classes present: tensor([0])\n",
            "Image: e13e952d1.jpg | Classes present: tensor([0, 2])\n",
            "Image: c1f1011b0.jpg | Classes present: tensor([0])\n",
            "Image: d572dc596.jpg | Classes present: tensor([0])\n",
            "Image: 271551c4f.jpg | Classes present: tensor([0])\n",
            "Image: d7eb453fe.jpg | Classes present: tensor([0])\n",
            "Image: ba0c890a2.jpg | Classes present: tensor([0, 2])\n",
            "Image: 848713301.jpg | Classes present: tensor([0])\n",
            "Image: 112942aed.jpg | Classes present: tensor([0])\n",
            "Image: 144fdd925.jpg | Classes present: tensor([0])\n",
            "Image: 276111a31.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3c456ebb8.jpg | Classes present: tensor([0])\n",
            "Image: 238cfd09f.jpg | Classes present: tensor([0])\n",
            "Image: 7af339322.jpg | Classes present: tensor([0])\n",
            "Image: 39bec5e5e.jpg | Classes present: tensor([0])\n",
            "Image: bc23335bc.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.02805468812584877\n",
            "Training Batch 491 - Positive pixels per class: [    0.     0. 28728.     0.]\n",
            "Output stats - Min: -16.96875, Max: 2.80859375\n",
            "Epoch 10/10:  98% 491/500 [01:34<00:01,  6.02it/s, Loss=0.0859]Mask stats - Min: 0.0, Max: 0.0, Mean: 0.0\n",
            "Image: 86d953299.jpg | Classes present: tensor([0])\n",
            "Training Batch 492 - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Image: bbcf45362.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -14.6953125, Max: 1.5341796875\n",
            "Epoch 10/10:  98% 491/500 [01:34<00:01,  6.02it/s, Loss=0.0536]Image: 0bee4edeb.jpg | Classes present: tensor([0, 2])\n",
            "Image: 162f17999.jpg | Classes present: tensor([0])\n",
            "Image: 703421ef2.jpg | Classes present: tensor([0])\n",
            "Image: 9574104d6.jpg | Classes present: tensor([0])\n",
            "Image: a223350f7.jpg | Classes present: tensor([0])\n",
            "Image: 1d7f89efa.jpg | Classes present: tensor([0])\n",
            "Image: af807ce02.jpg | Classes present: tensor([0])\n",
            "Image: ac7848f35.jpg | Classes present: tensor([0, 2])\n",
            "Image: b00741c0a.jpg | Classes present: tensor([0, 3])\n",
            "Image: 7f1b37606.jpg | Classes present: tensor([0])\n",
            "Image: 6343860bc.jpg | Classes present: tensor([0])\n",
            "Image: 8aaf23412.jpg | Classes present: tensor([0])\n",
            "Image: d99f9f7ac.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6353833df.jpg | Classes present: tensor([0])\n",
            "Image: 9aa437d47.jpg | Classes present: tensor([0])\n",
            "Image: 41dedb89b.jpg | Classes present: tensor([0])\n",
            "Image: 525d0e51e.jpg | Classes present: tensor([0])\n",
            "Image: 183dbcde4.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.03024902567267418\n",
            "Training Batch 493 - Positive pixels per class: [6.4500e+02 0.0000e+00 3.0328e+04 2.0000e+00]\n",
            "Output stats - Min: -15.9921875, Max: 1.958984375\n",
            "Image: 1919bde53.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  99% 493/500 [01:35<00:01,  5.98it/s, Loss=0.0989]Image: 3012f44e9.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.020732423290610313\n",
            "Training Batch 494 - Positive pixels per class: [    0.     0. 21230.     0.]\n",
            "Output stats - Min: -15.25, Max: 3.14453125\n",
            "Epoch 10/10:  99% 493/500 [01:35<00:01,  5.98it/s, Loss=0.0702]Image: ef8ba30c0.jpg | Classes present: tensor([0])\n",
            "Image: b89d58ef2.jpg | Classes present: tensor([0, 2])\n",
            "Image: 81770ddda.jpg | Classes present: tensor([0])\n",
            "Image: 165a55d5c.jpg | Classes present: tensor([0])\n",
            "Image: 12234aab8.jpg | Classes present: tensor([0])\n",
            "Image: 1a3cb1bfc.jpg | Classes present: tensor([0])\n",
            "Image: 8dc0f0966.jpg | Classes present: tensor([0, 2])\n",
            "Image: 7404322b0.jpg | Classes present: tensor([0])\n",
            "Image: e13c443d5.jpg | Classes present: tensor([0, 2])\n",
            "Image: 359e3fb7c.jpg | Classes present: tensor([0])\n",
            "Image: 74aedfa3c.jpg | Classes present: tensor([0])\n",
            "Image: 5d8d3463a.jpg | Classes present: tensor([0])\n",
            "Image: 94947e1f9.jpg | Classes present: tensor([0])\n",
            "Image: 2111e4f3f.jpg | Classes present: tensor([0])\n",
            "Image: 2d61e4f9f.jpg | Classes present: tensor([0])\n",
            "Image: 5432ff65a.jpg | Classes present: tensor([0])\n",
            "Image: da505edce.jpg | Classes present: tensor([0])\n",
            "Image: 4c2198026.jpg | Classes present: tensor([0])\n",
            "Image: b6f5f2414.jpg | Classes present: tensor([0])\n",
            "Image: 42877dc1a.jpg | Classes present: tensor([0, 2, 3])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.028943359851837158\n",
            "Training Batch 495 - Positive pixels per class: [    0.     0. 29638.     0.]\n",
            "Output stats - Min: -15.28125, Max: 2.44140625\n",
            "Image: d51a45df9.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  99% 495/500 [01:35<00:00,  5.61it/s, Loss=0.0832]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.005339844152331352\n",
            "Training Batch 496 - Positive pixels per class: [   0.    0. 5468.    0.]\n",
            "Image: 736c09835.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -16.140625, Max: 1.1728515625\n",
            "Epoch 10/10:  99% 495/500 [01:35<00:00,  5.61it/s, Loss=0.0789]Image: 5b202c6f5.jpg | Classes present: tensor([0])\n",
            "Image: d5ff65cd6.jpg | Classes present: tensor([0])\n",
            "Image: 4ebff3a81.jpg | Classes present: tensor([0])\n",
            "Image: 053e9a29c.jpg | Classes present: tensor([0])\n",
            "Image: 69f4aebe6.jpg | Classes present: tensor([0])\n",
            "Image: ea476b31f.jpg | Classes present: tensor([0])\n",
            "Image: 10972add9.jpg | Classes present: tensor([0])\n",
            "Image: 18fc395b4.jpg | Classes present: tensor([0])\n",
            "Image: a49edb718.jpg | Classes present: tensor([0])\n",
            "Image: 4d0d86a96.jpg | Classes present: tensor([0])\n",
            "Image: 460ab7579.jpg | Classes present: tensor([0])\n",
            "Image: adc257b59.jpg | Classes present: tensor([0])\n",
            "Image: c62ca3c1f.jpg | Classes present: tensor([0])\n",
            "Image: 80d40cc9c.jpg | Classes present: tensor([0])\n",
            "Image: d9a5c3aae.jpg | Classes present: tensor([0])\n",
            "Image: 9db16f031.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0027099610306322575\n",
            "Training Batch 497 - Positive pixels per class: [ 265.    0. 2510.    0.]\n",
            "Image: 96ad2b246.jpg | Classes present: tensor([0, 2])\n",
            "Image: 612c0d930.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -18.375, Max: 1.2578125\n",
            "Image: 8355a5249.jpg | Classes present: tensor([0])\n",
            "Epoch 10/10:  99% 497/500 [01:35<00:00,  5.84it/s, Loss=0.0496]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.002547851763665676\n",
            "Training Batch 498 - Positive pixels per class: [ 357.    0.  673. 1579.]\n",
            "Image: d1a774781.jpg | Classes present: tensor([0])\n",
            "Image: 9cee4ab2e.jpg | Classes present: tensor([0])\n",
            "Output stats - Min: -18.890625, Max: 1.345703125\n",
            "Image: 13ab7b13e.jpg | Classes present: tensor([0, 2])\n",
            "Epoch 10/10:  99% 497/500 [01:35<00:00,  5.84it/s, Loss=0.0644]Image: 8bc5aeca3.jpg | Classes present: tensor([0])\n",
            "Image: 0e62d06d5.jpg | Classes present: tensor([0, 2])\n",
            "Image: cee5fab38.jpg | Classes present: tensor([0])\n",
            "Image: 49a46692e.jpg | Classes present: tensor([0, 3])\n",
            "Image: 3aaaf3e64.jpg | Classes present: tensor([0])\n",
            "Image: 82f4c0b69.jpg | Classes present: tensor([0])\n",
            "Image: 3124b1e5c.jpg | Classes present: tensor([0])\n",
            "Image: d13688eac.jpg | Classes present: tensor([0])\n",
            "Image: 58c262a8b.jpg | Classes present: tensor([0])\n",
            "Image: 041a93b6d.jpg | Classes present: tensor([0])\n",
            "Image: 5ce3611e3.jpg | Classes present: tensor([0])\n",
            "Image: e83d27de8.jpg | Classes present: tensor([0])\n",
            "Image: 22e2195c1.jpg | Classes present: tensor([0])\n",
            "Image: 1795867f2.jpg | Classes present: tensor([0])\n",
            "Mask stats - Min: 0.0, Max: 1.0, Mean: 0.0238183606415987\n",
            "Training Batch 499 - Positive pixels per class: [    0.     0. 24197.   193.]\n",
            "Output stats - Min: -15.2890625, Max: 2.408203125\n",
            "Epoch 10/10: 100% 499/500 [01:36<00:00,  5.92it/s, Loss=0.0691]Mask stats - Min: 0.0, Max: 1.0, Mean: 0.01818554848432541\n",
            "Training Batch 500 - Positive pixels per class: [    0.     0. 18622.     0.]\n",
            "Output stats - Min: -14.9453125, Max: 2.361328125\n",
            "Epoch 10/10: 100% 500/500 [01:36<00:00,  5.19it/s, Loss=0.0558]\n",
            "\n",
            "=== Validation Phase ===\n",
            "Validating Epoch 10:   0% 0/134 [00:00<?, ?it/s]Image: 000a4bcdd.jpg | Classes present: tensor([0])\n",
            "Image: 00d639396.jpg | Classes present: tensor([0])\n",
            "Image: 01338c0ea.jpg | Classes present: tensor([0])\n",
            "Image: 000f6bf48.jpg | Classes present: tensor([0])\n",
            "Image: 0139dd004.jpg | Classes present: tensor([0])\n",
            "Image: 0014fce06.jpg | Classes present: tensor([0])\n",
            "Image: 01764ee81.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0025bde0c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 01919944c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0025bde0c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0095cd374.jpg | Classes present: tensor([0, 2])\n",
            "Image: 01cfacf80.jpg | Classes present: tensor([0, 3])\n",
            "Image: 00ac8372f.jpg | Classes present: tensor([0])\n",
            "Image: 01cfacf80.jpg | Classes present: tensor([0, 3])\n",
            "Image: 00ac8372f.jpg | Classes present: tensor([0])\n",
            "Image: 00af2671f.jpg | Classes present: tensor([0])\n",
            "Image: 01df77e59.jpg | Classes present: tensor([0])\n",
            "Image: 01e020dc5.jpg | Classes present: tensor([0])\n",
            "Image: 00bf8497a.jpg | Classes present: tensor([0])\n",
            "Image: 01fd320c9.jpg | Classes present: tensor([0])\n",
            "Image: 020ff3106.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 21631.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 04072b39a.jpg | Classes present: tensor([0])\n",
            "Image: 02291e913.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:   1% 1/134 [00:00<01:09,  1.91it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [  874.     0. 28884. 31832.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 04d49c95d.jpg | Classes present: tensor([0])\n",
            "Image: 02701c239.jpg | Classes present: tensor([0])\n",
            "Image: 04e23e414.jpg | Classes present: tensor([0])\n",
            "Image: 02b2d3aa4.jpg | Classes present: tensor([0])\n",
            "Image: 056e34021.jpg | Classes present: tensor([0])\n",
            "Image: 02c79bfcb.jpg | Classes present: tensor([0])\n",
            "Image: 05d6bccf8.jpg | Classes present: tensor([0])\n",
            "Image: 02d18b8a4.jpg | Classes present: tensor([0, 2])\n",
            "Image: 060964105.jpg | Classes present: tensor([0])\n",
            "Image: 034941f9d.jpg | Classes present: tensor([0])\n",
            "Image: 068c6c4a9.jpg | Classes present: tensor([0])\n",
            "Image: 0386ce84b.jpg | Classes present: tensor([0])\n",
            "Image: 038f14456.jpg | Classes present: tensor([0])\n",
            "Image: 0696cfa05.jpg | Classes present: tensor([0, 2])\n",
            "Image: 03faf7462.jpg | Classes present: tensor([0])\n",
            "Image: 06ad83bac.jpg | Classes present: tensor([0, 2])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [  0.   0. 895.   0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 06e6e7a8c.jpg | Classes present: tensor([0])\n",
            "Image: 06e7b157a.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:   2% 3/134 [00:00<00:31,  4.10it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 30599.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 06eb2151d.jpg | Classes present: tensor([0])\n",
            "Image: 085bcd104.jpg | Classes present: tensor([0, 2])\n",
            "Image: 06f52f4dd.jpg | Classes present: tensor([0])\n",
            "Image: 088aee82e.jpg | Classes present: tensor([0, 2])\n",
            "Image: 06fb3a6e5.jpg | Classes present: tensor([0])\n",
            "Image: 08a1a079b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0712fbd90.jpg | Classes present: tensor([0])\n",
            "Image: 08a1a079b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 07ac7620c.jpg | Classes present: tensor([0])\n",
            "Image: 08de8621d.jpg | Classes present: tensor([0])\n",
            "Image: 07c917711.jpg | Classes present: tensor([0])\n",
            "Image: 08de8df60.jpg | Classes present: tensor([0])\n",
            "Image: 0808a098b.jpg | Classes present: tensor([0])\n",
            "Image: 08193cfc8.jpg | Classes present: tensor([0])\n",
            "Image: 08de8df60.jpg | Classes present: tensor([0])\n",
            "Image: 08e3aadde.jpg | Classes present: tensor([0])\n",
            "Image: 0841074c1.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 092145f0c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 08f9c685f.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:   4% 5/134 [00:01<00:26,  4.91it/s]Image: 08f9c685f.jpg | Classes present: tensor([0])\n",
            "Image: 099e4e39a.jpg | Classes present: tensor([0, 2])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [ 1064.     0. 14181.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 09f1605ee.jpg | Classes present: tensor([0])\n",
            "Image: 0c59df320.jpg | Classes present: tensor([0])\n",
            "Image: 0a37f0a29.jpg | Classes present: tensor([0])\n",
            "Image: 0caf53aba.jpg | Classes present: tensor([0])\n",
            "Image: 0a4ad45a5.jpg | Classes present: tensor([0])\n",
            "Image: 0ce6ef153.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0aa4399a4.jpg | Classes present: tensor([0])\n",
            "Image: 0db535c8c.jpg | Classes present: tensor([0])\n",
            "Image: 0af6b34a8.jpg | Classes present: tensor([0])\n",
            "Image: 0dc953a31.jpg | Classes present: tensor([0])\n",
            "Image: 0b1993a49.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0b56da4ff.jpg | Classes present: tensor([0])\n",
            "Image: 0dd8c9f61.jpg | Classes present: tensor([0])\n",
            "Image: 0bfcf7a71.jpg | Classes present: tensor([0])\n",
            "Image: 0ddbc9fb5.jpg | Classes present: tensor([0, 3])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 6895.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 0e0d5004d.jpg | Classes present: tensor([0])\n",
            "Image: 0e71cd651.jpg | Classes present: tensor([0])\n",
            "Image: 0e1925eb6.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:   5% 7/134 [00:01<00:23,  5.49it/s]Image: 0e71cd651.jpg | Classes present: tensor([0])\n",
            "Image: 0e650e720.jpg | Classes present: tensor([0])\n",
            "Image: 0e86dea5b.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 1136. 3681.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 0eae06feb.jpg | Classes present: tensor([0])\n",
            "Image: 101bc8aa5.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0eb09950a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 106fd7aad.jpg | Classes present: tensor([0])\n",
            "Image: 0ef465b25.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1082cfe08.jpg | Classes present: tensor([0])\n",
            "Image: 0f9f79a88.jpg | Classes present: tensor([0])\n",
            "Image: 1086196e1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0fc3d194a.jpg | Classes present: tensor([0])\n",
            "Image: 10d98c2be.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0ff13bf69.jpg | Classes present: tensor([0])\n",
            "Image: 10d9f85be.jpg | Classes present: tensor([0])\n",
            "Image: 1013a0b6e.jpg | Classes present: tensor([0])\n",
            "Image: 11192bc94.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [ 1354.     0. 10288.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 11418b1c5.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:   7% 9/134 [00:01<00:20,  5.96it/s]Image: 118b71091.jpg | Classes present: tensor([0])\n",
            "Image: 11ff6a6f4.jpg | Classes present: tensor([0, 2])\n",
            "Image: 124204a30.jpg | Classes present: tensor([0])\n",
            "Image: 11b37e4d7.jpg | Classes present: tensor([0])\n",
            "Image: 12d38a1d4.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 17194.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 12dd3899c.jpg | Classes present: tensor([0])\n",
            "Image: 147ca5516.jpg | Classes present: tensor([0])\n",
            "Image: 135fe211d.jpg | Classes present: tensor([0])\n",
            "Image: 14e4da366.jpg | Classes present: tensor([0])\n",
            "Image: 137b5546d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1387583da.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1501f53a2.jpg | Classes present: tensor([0])\n",
            "Image: 153b56c43.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1561eb657.jpg | Classes present: tensor([0])\n",
            "Image: 140e212df.jpg | Classes present: tensor([0])\n",
            "Image: 1422b7da0.jpg | Classes present: tensor([0])\n",
            "Image: 15796b4d5.jpg | Classes present: tensor([0])\n",
            "Image: 159b43d49.jpg | Classes present: tensor([0])\n",
            "Image: 1435cd970.jpg | Classes present: tensor([0])\n",
            "Image: 15ce9e5cf.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 10167.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 163cc2750.jpg | Classes present: tensor([0, 3])\n",
            "Validating Epoch 10:   8% 11/134 [00:02<00:20,  6.01it/s]Image: 15e8d5e3d.jpg | Classes present: tensor([0])\n",
            "Image: 166818755.jpg | Classes present: tensor([0])\n",
            "Image: 161ca82bf.jpg | Classes present: tensor([0])\n",
            "Image: 167d6930a.jpg | Classes present: tensor([0])\n",
            "Image: 17f9f952a.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 2120.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 1809bcad9.jpg | Classes present: tensor([0])\n",
            "Image: 16d0b11ff.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:   9% 12/134 [00:02<00:18,  6.44it/s]Image: 180bb19f9.jpg | Classes present: tensor([0])\n",
            "Image: 16d0b11ff.jpg | Classes present: tensor([0])\n",
            "Image: 189659389.jpg | Classes present: tensor([0])\n",
            "Image: 171c64a72.jpg | Classes present: tensor([0])\n",
            "Image: 18ace9a9a.jpg | Classes present: tensor([0, 3])\n",
            "Image: 172b72353.jpg | Classes present: tensor([0])\n",
            "Image: 174af9fd6.jpg | Classes present: tensor([0])\n",
            "Image: 18c14f720.jpg | Classes present: tensor([0])\n",
            "Image: 192e256ba.jpg | Classes present: tensor([0])\n",
            "Image: 17e7cd5c6.jpg | Classes present: tensor([0, 2])\n",
            "Image: 195e36565.jpg | Classes present: tensor([0])\n",
            "Image: 17f611256.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 7239.  955.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 196e624f5.jpg | Classes present: tensor([0])\n",
            "Image: 19ab4c335.jpg | Classes present: tensor([0, 3])\n",
            "Validating Epoch 10:  10% 13/134 [00:02<00:20,  5.86it/s]Image: 198252b95.jpg | Classes present: tensor([0])\n",
            "Image: 19ab4c335.jpg | Classes present: tensor([0, 3])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0.    0. 4530.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 1b4642fd5.jpg | Classes present: tensor([0])\n",
            "Image: 19c645c25.jpg | Classes present: tensor([0])\n",
            "Image: 1b52ec552.jpg | Classes present: tensor([0])\n",
            "Image: 19d892dd9.jpg | Classes present: tensor([0, 3])\n",
            "Image: 1b7e426bc.jpg | Classes present: tensor([0])\n",
            "Image: 1a075e075.jpg | Classes present: tensor([0])\n",
            "Image: 1b8ef5392.jpg | Classes present: tensor([0])\n",
            "Image: 1a4039711.jpg | Classes present: tensor([0])\n",
            "Image: 1bc37a6f4.jpg | Classes present: tensor([0])\n",
            "Image: 1a9c38991.jpg | Classes present: tensor([0])\n",
            "Image: 1bd394dd6.jpg | Classes present: tensor([0])\n",
            "Image: 1abb621ee.jpg | Classes present: tensor([0])\n",
            "Image: 1b213d816.jpg | Classes present: tensor([0])\n",
            "Image: 1bdb7f26f.jpg | Classes present: tensor([0])\n",
            "Image: 1be49cb6f.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1b2c029b8.jpg | Classes present: tensor([0])\n",
            "Image: 1c18acd30.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0.     0. 34694.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 1cac6e1f3.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  11% 15/134 [00:02<00:19,  6.05it/s]Image: 1cac6e1f3.jpg | Classes present: tensor([0])\n",
            "Image: 1c97d1861.jpg | Classes present: tensor([0])\n",
            "Image: 1d28002da.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 10693.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 1e979fb66.jpg | Classes present: tensor([0])\n",
            "Image: 1d56ccf70.jpg | Classes present: tensor([0])\n",
            "Image: 1ea25d4fa.jpg | Classes present: tensor([0])\n",
            "Image: 1d71764d0.jpg | Classes present: tensor([0])\n",
            "Image: 1ea40df0e.jpg | Classes present: tensor([0])\n",
            "Image: 1d718ddb9.jpg | Classes present: tensor([0])\n",
            "Image: 1f3e0b337.jpg | Classes present: tensor([0])\n",
            "Image: 1dd8107e9.jpg | Classes present: tensor([0])\n",
            "Image: 1f8ea6702.jpg | Classes present: tensor([0])\n",
            "Image: 1e0220d5c.jpg | Classes present: tensor([0])\n",
            "Image: 1fc4c5a4b.jpg | Classes present: tensor([0])\n",
            "Image: 1fd098a38.jpg | Classes present: tensor([0])\n",
            "Image: 1e0980950.jpg | Classes present: tensor([0])\n",
            "Image: 1ff3214db.jpg | Classes present: tensor([0])\n",
            "Image: 1e7b96509.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 2012a6d02.jpg | Classes present: tensor([0])\n",
            "Image: 207e88d4a.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  13% 17/134 [00:03<00:19,  6.14it/s]Image: 206c8bb0c.jpg | Classes present: tensor([0])\n",
            "Image: 207f33325.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 208825e67.jpg | Classes present: tensor([0])\n",
            "Image: 21bf9d854.jpg | Classes present: tensor([0])\n",
            "Image: 20964a4f0.jpg | Classes present: tensor([0, 3])\n",
            "Image: 22123f29f.jpg | Classes present: tensor([0])\n",
            "Image: 20964a4f0.jpg | Classes present: tensor([0, 3])\n",
            "Image: 2222a03b3.jpg | Classes present: tensor([0])\n",
            "Image: 20a894ca5.jpg | Classes present: tensor([0])\n",
            "Image: 225ef7f0d.jpg | Classes present: tensor([0])\n",
            "Image: 2122b99c0.jpg | Classes present: tensor([0])\n",
            "Image: 2395db536.jpg | Classes present: tensor([0])\n",
            "Image: 214465021.jpg | Classes present: tensor([0])\n",
            "Image: 23bb4d637.jpg | Classes present: tensor([0])\n",
            "Image: 2188f5429.jpg | Classes present: tensor([0])\n",
            "Image: 23c450c03.jpg | Classes present: tensor([0])\n",
            "Image: 21af0ec58.jpg | Classes present: tensor([0, 2])\n",
            "Image: 23db57033.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 13056.  1854.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 23e4a530a.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  14% 19/134 [00:03<00:18,  6.19it/s]Image: 242894fc4.jpg | Classes present: tensor([0])\n",
            "Image: 248220d45.jpg | Classes present: tensor([0, 2])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [2299.    0.    0.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 2558c43bf.jpg | Classes present: tensor([0])\n",
            "Image: 2558c43bf.jpg | Classes present: tensor([0])\n",
            "Image: 248585a26.jpg | Classes present: tensor([0, 3])\n",
            "Image: 25c940a74.jpg | Classes present: tensor([0])\n",
            "Image: 25f9a8622.jpg | Classes present: tensor([0, 3])\n",
            "Image: 248585a26.jpg | Classes present: tensor([0, 3])\n",
            "Image: 2491d607d.jpg | Classes present: tensor([0])\n",
            "Image: 25fc987a1.jpg | Classes present: tensor([0])\n",
            "Image: 24a91d324.jpg | Classes present: tensor([0])\n",
            "Image: 26272c2a7.jpg | Classes present: tensor([0])\n",
            "Image: 24debd5d7.jpg | Classes present: tensor([0, 2])\n",
            "Image: 268446e17.jpg | Classes present: tensor([0])\n",
            "Image: 26f6f4c72.jpg | Classes present: tensor([0])\n",
            "Image: 24e21e85a.jpg | Classes present: tensor([0])\n",
            "Image: 270f5361d.jpg | Classes present: tensor([0])\n",
            "Image: 24e249331.jpg | Classes present: tensor([0])\n",
            "Image: 27207fb2e.jpg | Classes present: tensor([0])\n",
            "Image: 2527831fa.jpg | Classes present: tensor([0])\n",
            "Image: 294d6d5f8.jpg | Classes present: tensor([0])\n",
            "Image: 25515c2f6.jpg | Classes present: tensor([0])\n",
            "Image: 299d06031.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 10272. 16810.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 275e3bca6.jpg | Classes present: tensor([0])\n",
            "Image: 29c39b183.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  16% 21/134 [00:03<00:19,  5.74it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0.    0. 3389.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 279af89c7.jpg | Classes present: tensor([0])\n",
            "Image: 279b82aaf.jpg | Classes present: tensor([0])\n",
            "Image: 29c39b183.jpg | Classes present: tensor([0])\n",
            "Image: 29d83d9ce.jpg | Classes present: tensor([0])\n",
            "Image: 27faa1de7.jpg | Classes present: tensor([0, 2])\n",
            "Image: 282cd397d.jpg | Classes present: tensor([0])\n",
            "Image: 2a07798b5.jpg | Classes present: tensor([0])\n",
            "Image: 2a6669d9a.jpg | Classes present: tensor([0])\n",
            "Image: 282cd397d.jpg | Classes present: tensor([0])\n",
            "Image: 2a74520ed.jpg | Classes present: tensor([0])\n",
            "Image: 29124169b.jpg | Classes present: tensor([0])\n",
            "Image: 2a95756e7.jpg | Classes present: tensor([0])\n",
            "Image: 2912df978.jpg | Classes present: tensor([0])\n",
            "Image: 2a9e93a87.jpg | Classes present: tensor([0])\n",
            "Image: 2930b4f52.jpg | Classes present: tensor([0])\n",
            "Image: 2d37a1ebe.jpg | Classes present: tensor([0])\n",
            "Image: 2930b4f52.jpg | Classes present: tensor([0])\n",
            "Image: 2e4da1fd1.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 4799.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 2e4fefc28.jpg | Classes present: tensor([0, 2])\n",
            "Validating Epoch 10:  17% 23/134 [00:04<00:18,  5.96it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 2ae658a56.jpg | Classes present: tensor([0])\n",
            "Image: 2b0055ed4.jpg | Classes present: tensor([0])\n",
            "Image: 2e55a1149.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2b15517b1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2e84c0c34.jpg | Classes present: tensor([0])\n",
            "Image: 2b449bdcf.jpg | Classes present: tensor([0])\n",
            "Image: 2e8733afa.jpg | Classes present: tensor([0])\n",
            "Image: 2b8dfbe0b.jpg | Classes present: tensor([0])\n",
            "Image: 2e8f2ddb8.jpg | Classes present: tensor([0])\n",
            "Image: 2bdb48c91.jpg | Classes present: tensor([0])\n",
            "Image: 2e97e0251.jpg | Classes present: tensor([0])\n",
            "Image: 2c56741a3.jpg | Classes present: tensor([0])\n",
            "Image: 2c63f60e3.jpg | Classes present: tensor([0])\n",
            "Image: 2ede3bc01.jpg | Classes present: tensor([0])\n",
            "Image: 2ef5b3de1.jpg | Classes present: tensor([0])\n",
            "Image: 2c7e26f0d.jpg | Classes present: tensor([0])\n",
            "Image: 30799f11c.jpg | Classes present: tensor([0])\n",
            "Image: 2d26b9dda.jpg | Classes present: tensor([0])\n",
            "Image: 308c978a7.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [1120.    0. 6786.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 2eff528e8.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  19% 25/134 [00:04<00:20,  5.20it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 2347.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 30ba0b89a.jpg | Classes present: tensor([0])\n",
            "Image: 2f5690028.jpg | Classes present: tensor([0])\n",
            "Image: 30c2d753f.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2f8cf11d3.jpg | Classes present: tensor([0])\n",
            "Image: 30d00096d.jpg | Classes present: tensor([0])\n",
            "Image: 2fa3a9f3e.jpg | Classes present: tensor([0])\n",
            "Image: 3116edfe6.jpg | Classes present: tensor([0])\n",
            "Image: 2fa996a4c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 31262e8f9.jpg | Classes present: tensor([0])\n",
            "Image: 2fbdc1244.jpg | Classes present: tensor([0])\n",
            "Image: 31433d3b4.jpg | Classes present: tensor([0])\n",
            "Image: 2fcfb108a.jpg | Classes present: tensor([0])\n",
            "Image: 3159ee27a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2fcfb108a.jpg | Classes present: tensor([0])\n",
            "Image: 316f0cc50.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2fe9f78c9.jpg | Classes present: tensor([0])\n",
            "Image: 32eca38d5.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3071e65a5.jpg | Classes present: tensor([0])\n",
            "Image: 33514c0b1.jpg | Classes present: tensor([0, 2])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [  0.   0. 681.   0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 335be17fa.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  20% 27/134 [00:04<00:20,  5.31it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 15554.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 31716f6ae.jpg | Classes present: tensor([0, 2])\n",
            "Image: 33754aa9b.jpg | Classes present: tensor([0])\n",
            "Image: 31a43a534.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3377332c0.jpg | Classes present: tensor([0, 2])\n",
            "Image: 31dee4189.jpg | Classes present: tensor([0])\n",
            "Image: 3385f9e14.jpg | Classes present: tensor([0])\n",
            "Image: 31eda6a87.jpg | Classes present: tensor([0])\n",
            "Image: 338d3b828.jpg | Classes present: tensor([0])\n",
            "Image: 320557243.jpg | Classes present: tensor([0])\n",
            "Image: 338d3b828.jpg | Classes present: tensor([0])\n",
            "Image: 321975fb3.jpg | Classes present: tensor([0])\n",
            "Image: 33a4b4335.jpg | Classes present: tensor([0])\n",
            "Image: 32578d3e5.jpg | Classes present: tensor([0])\n",
            "Image: 345cf1dc3.jpg | Classes present: tensor([0])\n",
            "Image: 36789516a.jpg | Classes present: tensor([0])\n",
            "Image: 326d25e8c.jpg | Classes present: tensor([0])\n",
            "Image: 369ac4b0a.jpg | Classes present: tensor([0])\n",
            "Image: 3294c9bd1.jpg | Classes present: tensor([0])\n",
            "Image: 36a804181.jpg | Classes present: tensor([0])\n",
            "Image: 3294c9bd1.jpg | Classes present: tensor([0])\n",
            "Image: 36cd2cde0.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3704cdfd6.jpg | Classes present: tensor([0])\n",
            "Image: 34a5114d6.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [ 3056.     0. 11193.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 34a5114d6.jpg | Classes present: tensor([0])\n",
            "Image: 373c6898f.jpg | Classes present: tensor([0, 2])\n",
            "Validating Epoch 10:  22% 29/134 [00:05<00:23,  4.43it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 5321.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 34ee04d85.jpg | Classes present: tensor([0])\n",
            "Image: 373ebde8b.jpg | Classes present: tensor([0])\n",
            "Image: 34f8faf6d.jpg | Classes present: tensor([0])\n",
            "Image: 374d9c63f.jpg | Classes present: tensor([0])\n",
            "Image: 3520eaa6d.jpg | Classes present: tensor([0])\n",
            "Image: 37acd89d2.jpg | Classes present: tensor([0])\n",
            "Image: 35271f898.jpg | Classes present: tensor([0])\n",
            "Image: 380e3ba93.jpg | Classes present: tensor([0])\n",
            "Image: 353e60eef.jpg | Classes present: tensor([0])\n",
            "Image: 3a96940c6.jpg | Classes present: tensor([0])\n",
            "Image: 35a8b85a8.jpg | Classes present: tensor([0])\n",
            "Image: 3ab1a7324.jpg | Classes present: tensor([0])\n",
            "Image: 35d142883.jpg | Classes present: tensor([0])\n",
            "Image: 3af515180.jpg | Classes present: tensor([0])\n",
            "Image: 35d142883.jpg | Classes present: tensor([0])\n",
            "Image: 3b3df8749.jpg | Classes present: tensor([0])\n",
            "Image: 38698fd76.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Validating Epoch 10:  23% 31/134 [00:06<00:24,  4.16it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 33424.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 3b6f87aed.jpg | Classes present: tensor([0])\n",
            "Image: 3888ec2cd.jpg | Classes present: tensor([0])\n",
            "Image: 38a63550b.jpg | Classes present: tensor([0])\n",
            "Image: 3cb1c14c8.jpg | Classes present: tensor([0])\n",
            "Image: 391b766d3.jpg | Classes present: tensor([0])\n",
            "Image: 3da31ea30.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3964357cd.jpg | Classes present: tensor([0, 3])\n",
            "Image: 3de8f5d88.jpg | Classes present: tensor([0])\n",
            "Image: 39b8cb37a.jpg | Classes present: tensor([0])\n",
            "Image: 3e185a3fe.jpg | Classes present: tensor([0])\n",
            "Image: 39e365d3b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3e1f5caa8.jpg | Classes present: tensor([0])\n",
            "Image: 3a03385b5.jpg | Classes present: tensor([0])\n",
            "Image: 40b724998.jpg | Classes present: tensor([0, 2])\n",
            "Image: 40d766da8.jpg | Classes present: tensor([0, 3])\n",
            "Image: 3a4edbde9.jpg | Classes present: tensor([0])\n",
            "Image: 411377ca3.jpg | Classes present: tensor([0])\n",
            "Image: 412fe7f70.jpg | Classes present: tensor([0])\n",
            "Image: 3a5246d98.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0.  1264. 17206.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Validating Epoch 10:  25% 33/134 [00:06<00:25,  3.96it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 5856.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 3e519e65d.jpg | Classes present: tensor([0])\n",
            "Image: 41333f13c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3e59e0f17.jpg | Classes present: tensor([0])\n",
            "Image: 41411378e.jpg | Classes present: tensor([0, 3])\n",
            "Image: 3f0b1c635.jpg | Classes present: tensor([0])\n",
            "Image: 3f272083c.jpg | Classes present: tensor([0])\n",
            "Image: 41411378e.jpg | Classes present: tensor([0, 3])\n",
            "Image: 3f536622f.jpg | Classes present: tensor([0])\n",
            "Image: 415252307.jpg | Classes present: tensor([0])\n",
            "Image: 3fb68881e.jpg | Classes present: tensor([0])\n",
            "Image: 415dd1efd.jpg | Classes present: tensor([0])\n",
            "Image: 3fdbbf305.jpg | Classes present: tensor([0])\n",
            "Image: 41716714b.jpg | Classes present: tensor([0])\n",
            "Image: 401de199f.jpg | Classes present: tensor([0])\n",
            "Image: 4340e1e42.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4029fea8e.jpg | Classes present: tensor([0])\n",
            "Image: 4345c2b85.jpg | Classes present: tensor([0])\n",
            "Image: 4355ef39b.jpg | Classes present: tensor([0])\n",
            "Image: 40aae2e57.jpg | Classes present: tensor([0, 2])\n",
            "Image: 436398e3b.jpg | Classes present: tensor([0])\n",
            "Image: 418e47222.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 7424.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 436e3f4a0.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  26% 35/134 [00:07<00:26,  3.74it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 34996.  9758.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 419dc2472.jpg | Classes present: tensor([0])\n",
            "Image: 439f1a016.jpg | Classes present: tensor([0])\n",
            "Image: 4243c7476.jpg | Classes present: tensor([0])\n",
            "Image: 43b6618bf.jpg | Classes present: tensor([0])\n",
            "Image: 42695cb60.jpg | Classes present: tensor([0])\n",
            "Image: 43c6a30fa.jpg | Classes present: tensor([0])\n",
            "Image: 43d7e6da0.jpg | Classes present: tensor([0])\n",
            "Image: 427085ef4.jpg | Classes present: tensor([0])\n",
            "Image: 44011d351.jpg | Classes present: tensor([0])\n",
            "Image: 429650b38.jpg | Classes present: tensor([0])\n",
            "Image: 45612bd46.jpg | Classes present: tensor([0])\n",
            "Image: 429951ca7.jpg | Classes present: tensor([0, 2])\n",
            "Image: 42af54b00.jpg | Classes present: tensor([0])\n",
            "Image: 459790d82.jpg | Classes present: tensor([0])\n",
            "Image: 42caf4e12.jpg | Classes present: tensor([0])\n",
            "Image: 42dd20db7.jpg | Classes present: tensor([0])\n",
            "Image: 459cd013a.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 1407.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 441add89c.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  28% 37/134 [00:07<00:24,  3.89it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 21531.     0.]\n",
            "Image: 45a4c0a58.jpg | Classes present: tensor([0])\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 4422bc417.jpg | Classes present: tensor([0])\n",
            "Image: 45cca62e0.jpg | Classes present: tensor([0])\n",
            "Image: 4422bc417.jpg | Classes present: tensor([0])\n",
            "Image: 45d8e1473.jpg | Classes present: tensor([0])\n",
            "Image: 4613bc12c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 445dfb2ce.jpg | Classes present: tensor([0])\n",
            "Image: 4613d520c.jpg | Classes present: tensor([0])\n",
            "Image: 446ba8f9b.jpg | Classes present: tensor([0])\n",
            "Image: 4695c2d2a.jpg | Classes present: tensor([0])\n",
            "Image: 446c4efb5.jpg | Classes present: tensor([0])\n",
            "Image: 4499aaa80.jpg | Classes present: tensor([0])\n",
            "Image: 472407235.jpg | Classes present: tensor([0])\n",
            "Image: 48831ab9e.jpg | Classes present: tensor([0])\n",
            "Image: 44a0d5b55.jpg | Classes present: tensor([0])\n",
            "Image: 44ada0c0b.jpg | Classes present: tensor([0])\n",
            "Image: 488922ac2.jpg | Classes present: tensor([0])\n",
            "Image: 4529ee151.jpg | Classes present: tensor([0])\n",
            "Image: 48c466789.jpg | Classes present: tensor([0])\n",
            "Image: 474c5f34e.jpg | Classes present: tensor([0, 2])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 49c035d7e.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  29% 39/134 [00:08<00:25,  3.70it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 2540.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 47a18bd61.jpg | Classes present: tensor([0])\n",
            "Image: 49cf406c7.jpg | Classes present: tensor([0, 2])\n",
            "Image: 47c24f230.jpg | Classes present: tensor([0])\n",
            "Image: 4a662783b.jpg | Classes present: tensor([0])\n",
            "Image: 47cee01b1.jpg | Classes present: tensor([0])\n",
            "Image: 4aca6c4a7.jpg | Classes present: tensor([0])\n",
            "Image: 483e4b5f7.jpg | Classes present: tensor([0])\n",
            "Image: 4b56df46d.jpg | Classes present: tensor([0])\n",
            "Image: 484439824.jpg | Classes present: tensor([0])\n",
            "Image: 4b56df46d.jpg | Classes present: tensor([0])\n",
            "Image: 48532e006.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4b712bf89.jpg | Classes present: tensor([0])\n",
            "Image: 4854add54.jpg | Classes present: tensor([0])\n",
            "Image: 4d1444a12.jpg | Classes present: tensor([0])\n",
            "Image: 4857d0687.jpg | Classes present: tensor([0])\n",
            "Image: 4d6973926.jpg | Classes present: tensor([0, 2])\n",
            "Image: 48626da29.jpg | Classes present: tensor([0])\n",
            "Image: 4dbadaa3e.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [  797.     0. 14307.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 4b762b230.jpg | Classes present: tensor([0])\n",
            "Image: 4dbadaa3e.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  31% 41/134 [00:08<00:24,  3.72it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 4317.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 4b902c994.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4dd52fc23.jpg | Classes present: tensor([0, 3])\n",
            "Image: 4c12f034c.jpg | Classes present: tensor([0])\n",
            "Image: 4dd52fc23.jpg | Classes present: tensor([0, 3])\n",
            "Image: 4c3100013.jpg | Classes present: tensor([0])\n",
            "Image: 4e1d262fb.jpg | Classes present: tensor([0])\n",
            "Image: 4c770beb5.jpg | Classes present: tensor([0])\n",
            "Image: 4e25cb8e7.jpg | Classes present: tensor([0])\n",
            "Image: 4c770beb5.jpg | Classes present: tensor([0])\n",
            "Image: 4e6514402.jpg | Classes present: tensor([0])\n",
            "Image: 4c7ff2056.jpg | Classes present: tensor([0])\n",
            "Image: 4ec252808.jpg | Classes present: tensor([0, 3])\n",
            "Image: 4c9245dcf.jpg | Classes present: tensor([0])\n",
            "Image: 50ff24e6e.jpg | Classes present: tensor([0])\n",
            "Image: 4ca64717c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 51097aa45.jpg | Classes present: tensor([0])\n",
            "Image: 4d1444a12.jpg | Classes present: tensor([0])\n",
            "Image: 51632c4a4.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [  0.   0. 377.   0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 4ecf05db6.jpg | Classes present: tensor([0, 2])\n",
            "Image: 51b211df9.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  32% 43/134 [00:09<00:22,  4.00it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0.  2046. 34284.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 4ee32c458.jpg | Classes present: tensor([0])\n",
            "Image: 51d092947.jpg | Classes present: tensor([0])\n",
            "Image: 51d7bdfc2.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4eea878dd.jpg | Classes present: tensor([0])\n",
            "Image: 51d7bee0a.jpg | Classes present: tensor([0])\n",
            "Image: 4ef21d9b7.jpg | Classes present: tensor([0])\n",
            "Image: 4ef65d75b.jpg | Classes present: tensor([0])\n",
            "Image: 51f9ccdd2.jpg | Classes present: tensor([0])\n",
            "Image: 4fe777e50.jpg | Classes present: tensor([0])\n",
            "Image: 522d34082.jpg | Classes present: tensor([0])\n",
            "Image: 523fee62c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 504e47cce.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5064ecb6d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5545e4b0f.jpg | Classes present: tensor([0])\n",
            "Image: 509abf323.jpg | Classes present: tensor([0])\n",
            "Image: 554710095.jpg | Classes present: tensor([0])\n",
            "Image: 50bab4d98.jpg | Classes present: tensor([0, 2])\n",
            "Image: 554ee47b6.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 24096.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 5562229c3.jpg | Classes present: tensor([0, 2])\n",
            "Validating Epoch 10:  34% 45/134 [00:09<00:19,  4.46it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 25306.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 5283b3138.jpg | Classes present: tensor([0])\n",
            "Image: 52faeb955.jpg | Classes present: tensor([0])\n",
            "Image: 559bcc411.jpg | Classes present: tensor([0, 2])\n",
            "Image: 53994e13b.jpg | Classes present: tensor([0])\n",
            "Image: 55c30f544.jpg | Classes present: tensor([0, 2])\n",
            "Image: 53f2e3c44.jpg | Classes present: tensor([0])\n",
            "Image: 56553f422.jpg | Classes present: tensor([0])\n",
            "Image: 54738099a.jpg | Classes present: tensor([0])\n",
            "Image: 549613483.jpg | Classes present: tensor([0])\n",
            "Image: 567578f1b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 54bdb0ccf.jpg | Classes present: tensor([0])\n",
            "Image: 567578f1b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 567e1f981.jpg | Classes present: tensor([0])\n",
            "Image: 54c3ce6f0.jpg | Classes present: tensor([0])\n",
            "Image: 54fc1f606.jpg | Classes present: tensor([0])\n",
            "Image: 595373657.jpg | Classes present: tensor([0])\n",
            "Image: 5545e4b0f.jpg | Classes present: tensor([0])\n",
            "Image: 59a1733a9.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 59a2887fd.jpg | Classes present: tensor([0])\n",
            "Image: 56cc8fb98.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  35% 47/134 [00:09<00:17,  4.93it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 14733.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 59b20349b.jpg | Classes present: tensor([0])\n",
            "Image: 5787b6262.jpg | Classes present: tensor([0, 2])\n",
            "Image: 59bcf1693.jpg | Classes present: tensor([0])\n",
            "Image: 579a51c1b.jpg | Classes present: tensor([0])\n",
            "Image: 5a188bcf6.jpg | Classes present: tensor([0])\n",
            "Image: 57a71495a.jpg | Classes present: tensor([0])\n",
            "Image: 5a8203514.jpg | Classes present: tensor([0])\n",
            "Image: 57a71495a.jpg | Classes present: tensor([0])\n",
            "Image: 5ad654fc4.jpg | Classes present: tensor([0])\n",
            "Image: 5810e2d40.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5adb00ee3.jpg | Classes present: tensor([0])\n",
            "Image: 582f0666f.jpg | Classes present: tensor([0])\n",
            "Image: 5b13aedd6.jpg | Classes present: tensor([0])\n",
            "Image: 585904c94.jpg | Classes present: tensor([0])\n",
            "Image: 5ca2ccd75.jpg | Classes present: tensor([0])\n",
            "Image: 58f11e1cb.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5cbfcc4dd.jpg | Classes present: tensor([0])\n",
            "Image: 594e2b83f.jpg | Classes present: tensor([0])\n",
            "Image: 5cc07468d.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 22221.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 5cf1cb974.jpg | Classes present: tensor([0])\n",
            "Image: 5b470a696.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  37% 49/134 [00:10<00:16,  5.14it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 5cf4adf72.jpg | Classes present: tensor([0])\n",
            "Image: 5b5543800.jpg | Classes present: tensor([0])\n",
            "Image: 5d3cbe1fe.jpg | Classes present: tensor([0])\n",
            "Image: 5b5ad8482.jpg | Classes present: tensor([0])\n",
            "Image: 5e29012ca.jpg | Classes present: tensor([0])\n",
            "Image: 5b615bff0.jpg | Classes present: tensor([0])\n",
            "Image: 5e570da14.jpg | Classes present: tensor([0])\n",
            "Image: 5b88d9e1a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5e92f8e11.jpg | Classes present: tensor([0])\n",
            "Image: 5baeac055.jpg | Classes present: tensor([0])\n",
            "Image: 5f121bfff.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5c36982d0.jpg | Classes present: tensor([0])\n",
            "Image: 5c3e81694.jpg | Classes present: tensor([0])\n",
            "Image: 6276bd13c.jpg | Classes present: tensor([0])\n",
            "Image: 5c801ba0c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 62f84c877.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5ca03f4fb.jpg | Classes present: tensor([0])\n",
            "Image: 6308e03ad.jpg | Classes present: tensor([0])\n",
            "Image: 5fa81f2b5.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 9867.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 633701ae3.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  38% 51/134 [00:10<00:16,  5.17it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [  0.   0. 661.   0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 604e200e1.jpg | Classes present: tensor([0])\n",
            "Image: 636700b91.jpg | Classes present: tensor([0])\n",
            "Image: 636bad9bd.jpg | Classes present: tensor([0])\n",
            "Image: 6057916d4.jpg | Classes present: tensor([0])\n",
            "Image: 639c7495a.jpg | Classes present: tensor([0])\n",
            "Image: 63adb88f1.jpg | Classes present: tensor([0])\n",
            "Image: 605ed0050.jpg | Classes present: tensor([0])\n",
            "Image: 63c46a774.jpg | Classes present: tensor([0, 2])\n",
            "Image: 60bc48f6b.jpg | Classes present: tensor([0])\n",
            "Image: 63c46a774.jpg | Classes present: tensor([0, 2])\n",
            "Image: 61204ded5.jpg | Classes present: tensor([0])\n",
            "Image: 61835d07a.jpg | Classes present: tensor([0])\n",
            "Image: 66849c8bd.jpg | Classes present: tensor([0])\n",
            "Image: 61f22bd01.jpg | Classes present: tensor([0])\n",
            "Image: 66ac60af4.jpg | Classes present: tensor([0])\n",
            "Image: 622086df1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 670dc6f72.jpg | Classes present: tensor([0, 3])\n",
            "Image: 624b76e5c.jpg | Classes present: tensor([0])\n",
            "Image: 670dc6f72.jpg | Classes present: tensor([0, 3])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 1028.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 6714ba056.jpg | Classes present: tensor([0])\n",
            "Image: 63cf275e8.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  40% 53/134 [00:11<00:15,  5.16it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 6013.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 6753759e0.jpg | Classes present: tensor([0])\n",
            "Image: 642cfbe74.jpg | Classes present: tensor([0])\n",
            "Image: 67741aee6.jpg | Classes present: tensor([0])\n",
            "Image: 6430ea237.jpg | Classes present: tensor([0])\n",
            "Image: 677828765.jpg | Classes present: tensor([0])\n",
            "Image: 6430ea237.jpg | Classes present: tensor([0])\n",
            "Image: 67a5a06f1.jpg | Classes present: tensor([0])\n",
            "Image: 644f9c71d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 644f9c71d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 67ffa0fc7.jpg | Classes present: tensor([0])\n",
            "Image: 649890305.jpg | Classes present: tensor([0])\n",
            "Image: 69df9d97b.jpg | Classes present: tensor([0])\n",
            "Image: 64b571a9a.jpg | Classes present: tensor([0])\n",
            "Image: 69f723ceb.jpg | Classes present: tensor([0])\n",
            "Image: 65bb052e9.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6a06e0328.jpg | Classes present: tensor([0])\n",
            "Image: 66574a641.jpg | Classes present: tensor([0])\n",
            "Image: 6a567df0b.jpg | Classes present: tensor([0, 2])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 15266.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 6a9ff4b0c.jpg | Classes present: tensor([0, 1])\n",
            "Image: 6812ce51c.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  41% 55/134 [00:11<00:14,  5.55it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0.     0. 11746.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 6abf76aad.jpg | Classes present: tensor([0])\n",
            "Image: 68a931b71.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6ac1c730f.jpg | Classes present: tensor([0])\n",
            "Image: 68d3c7be2.jpg | Classes present: tensor([0])\n",
            "Image: 68ebc581e.jpg | Classes present: tensor([0])\n",
            "Image: 6b226dec1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6b3cdd9d1.jpg | Classes present: tensor([0])\n",
            "Image: 69365fabd.jpg | Classes present: tensor([0])\n",
            "Image: 6b3d02bce.jpg | Classes present: tensor([0])\n",
            "Image: 69403726e.jpg | Classes present: tensor([0])\n",
            "Image: 695a460be.jpg | Classes present: tensor([0])\n",
            "Image: 6caa89d4e.jpg | Classes present: tensor([0])\n",
            "Image: 697427d70.jpg | Classes present: tensor([0])\n",
            "Image: 69d546af3.jpg | Classes present: tensor([0])\n",
            "Image: 6cad486d2.jpg | Classes present: tensor([0])\n",
            "Image: 69d95aeea.jpg | Classes present: tensor([0])\n",
            "Image: 6ce9bf7f7.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 9062.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 6ce9ef450.jpg | Classes present: tensor([0])\n",
            "Image: 6b4d25284.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  43% 57/134 [00:11<00:13,  5.74it/s]Image: 6d6280d5e.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [  345.  2063. 26859.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 6d8835463.jpg | Classes present: tensor([0])\n",
            "Image: 6b634bbe9.jpg | Classes present: tensor([0])\n",
            "Image: 6d8835463.jpg | Classes present: tensor([0])\n",
            "Image: 6b7387486.jpg | Classes present: tensor([0])\n",
            "Image: 6de495da5.jpg | Classes present: tensor([0])\n",
            "Image: 6b7e04658.jpg | Classes present: tensor([0])\n",
            "Image: 6e18bef6b.jpg | Classes present: tensor([0])\n",
            "Image: 6b9b11301.jpg | Classes present: tensor([0])\n",
            "Image: 6e30e4696.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6bc7c35cd.jpg | Classes present: tensor([0])\n",
            "Image: 6c43d55eb.jpg | Classes present: tensor([0])\n",
            "Image: 6fd1ed5aa.jpg | Classes present: tensor([0])\n",
            "Image: 6c43d55eb.jpg | Classes present: tensor([0])\n",
            "Image: 6ff11b744.jpg | Classes present: tensor([0])\n",
            "Image: 7045c2a55.jpg | Classes present: tensor([0])\n",
            "Image: 6c8b1519e.jpg | Classes present: tensor([0])\n",
            "Image: 6ca387398.jpg | Classes present: tensor([0, 2])\n",
            "Image: 7095dc41e.jpg | Classes present: tensor([0])\n",
            "Image: 70b0fb0cd.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [2348.    0. 2757.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Validating Epoch 10:  44% 59/134 [00:11<00:12,  5.91it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 12014.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 6e3f85bb9.jpg | Classes present: tensor([0])\n",
            "Image: 70ce9b55b.jpg | Classes present: tensor([0])\n",
            "Image: 6e4a7cca6.jpg | Classes present: tensor([0])\n",
            "Image: 713e97c97.jpg | Classes present: tensor([0])\n",
            "Image: 6e6f1adb8.jpg | Classes present: tensor([0])\n",
            "Image: 714256911.jpg | Classes present: tensor([0])\n",
            "Image: 6e994b366.jpg | Classes present: tensor([0])\n",
            "Image: 714256911.jpg | Classes present: tensor([0])\n",
            "Image: 7149874c8.jpg | Classes present: tensor([0])\n",
            "Image: 6eb8690cd.jpg | Classes present: tensor([0])\n",
            "Image: 73cdb1d89.jpg | Classes present: tensor([0])\n",
            "Image: 6ec88b7f7.jpg | Classes present: tensor([0])\n",
            "Image: 73d4dae19.jpg | Classes present: tensor([0])\n",
            "Image: 6f0cd5095.jpg | Classes present: tensor([0, 2])\n",
            "Image: 73d4dae19.jpg | Classes present: tensor([0])\n",
            "Image: 6f2357894.jpg | Classes present: tensor([0])\n",
            "Image: 6f490117c.jpg | Classes present: tensor([0])\n",
            "Image: 73e1969d4.jpg | Classes present: tensor([0])\n",
            "Image: 6fabaf589.jpg | Classes present: tensor([0])\n",
            "Image: 74048991c.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 6879.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 722df0394.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  46% 61/134 [00:12<00:12,  6.05it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [995.   0.   0.   0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 74443f387.jpg | Classes present: tensor([0])\n",
            "Image: 74ac88f43.jpg | Classes present: tensor([0])\n",
            "Image: 72a7ff0db.jpg | Classes present: tensor([0])\n",
            "Image: 74bb2c5ff.jpg | Classes present: tensor([0])\n",
            "Image: 75361926d.jpg | Classes present: tensor([0])\n",
            "Image: 72a7ff0db.jpg | Classes present: tensor([0])\n",
            "Image: 763871334.jpg | Classes present: tensor([0])\n",
            "Image: 72b465391.jpg | Classes present: tensor([0])\n",
            "Image: 77e5c398e.jpg | Classes present: tensor([0])\n",
            "Image: 72bb7c7bc.jpg | Classes present: tensor([0])\n",
            "Image: 77ed43ae9.jpg | Classes present: tensor([0])\n",
            "Image: 73472d296.jpg | Classes present: tensor([0])\n",
            "Image: 7806aa75f.jpg | Classes present: tensor([0])\n",
            "Image: 7365300fe.jpg | Classes present: tensor([0, 2])\n",
            "Image: 78416c3d0.jpg | Classes present: tensor([0])\n",
            "Image: 737ae5c95.jpg | Classes present: tensor([0])\n",
            "Image: 7843767e9.jpg | Classes present: tensor([0])\n",
            "Image: 739a0aa20.jpg | Classes present: tensor([0, 1])\n",
            "Image: 786faedc1.jpg | Classes present: tensor([0])\n",
            "Image: 73a4c6d1f.jpg | Classes present: tensor([0])\n",
            "Image: 788a675e7.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0. 3996.   43.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Validating Epoch 10:  47% 63/134 [00:12<00:11,  6.06it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 76a7e1815.jpg | Classes present: tensor([0])\n",
            "Image: 78b5bc846.jpg | Classes present: tensor([0])\n",
            "Image: 76adc6361.jpg | Classes present: tensor([0])\n",
            "Image: 78be7465f.jpg | Classes present: tensor([0])\n",
            "Image: 76b119e36.jpg | Classes present: tensor([0])\n",
            "Image: 76c165a4f.jpg | Classes present: tensor([0])\n",
            "Image: 78d2258f2.jpg | Classes present: tensor([0])\n",
            "Image: 76c20b5af.jpg | Classes present: tensor([0])\n",
            "Image: 7a92f8486.jpg | Classes present: tensor([0])\n",
            "Image: 773948ca6.jpg | Classes present: tensor([0])\n",
            "Image: 7abb5b1b7.jpg | Classes present: tensor([0])\n",
            "Image: 7740cc61d.jpg | Classes present: tensor([0])\n",
            "Image: 7b4bcde18.jpg | Classes present: tensor([0])\n",
            "Image: 778bde2b8.jpg | Classes present: tensor([0, 2])\n",
            "Image: 7b4e8c0d9.jpg | Classes present: tensor([0])\n",
            "Image: 77dc1cea6.jpg | Classes present: tensor([0])\n",
            "Image: 7b547b234.jpg | Classes present: tensor([0])\n",
            "Image: 77e5c398e.jpg | Classes present: tensor([0])\n",
            "Image: 7b5dbe34d.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 11716.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 7ba0bbe30.jpg | Classes present: tensor([0])\n",
            "Image: 79550304c.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  49% 65/134 [00:12<00:11,  6.06it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 7bb3640ce.jpg | Classes present: tensor([0])\n",
            "Image: 795907727.jpg | Classes present: tensor([0])\n",
            "Image: 7bde96c82.jpg | Classes present: tensor([0])\n",
            "Image: 7970f0008.jpg | Classes present: tensor([0])\n",
            "Image: 7c00478a3.jpg | Classes present: tensor([0])\n",
            "Image: 7970f0008.jpg | Classes present: tensor([0])\n",
            "Image: 7f25edc7a.jpg | Classes present: tensor([0])\n",
            "Image: 7971e089f.jpg | Classes present: tensor([0])\n",
            "Image: 7f4bbb940.jpg | Classes present: tensor([0])\n",
            "Image: 79bac6aca.jpg | Classes present: tensor([0])\n",
            "Image: 7f777ba81.jpg | Classes present: tensor([0])\n",
            "Image: 79c106c42.jpg | Classes present: tensor([0])\n",
            "Image: 7f8594d4b.jpg | Classes present: tensor([0])\n",
            "Image: 79dc6e410.jpg | Classes present: tensor([0])\n",
            "Image: 7f8d10098.jpg | Classes present: tensor([0])\n",
            "Image: 7a2908c51.jpg | Classes present: tensor([0])\n",
            "Image: 7fc9cb824.jpg | Classes present: tensor([0, 2])\n",
            "Image: 7a5fae002.jpg | Classes present: tensor([0])\n",
            "Image: 7fd3d58a5.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 7c95cddba.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  50% 67/134 [00:13<00:10,  6.18it/s]Image: 801d299ac.jpg | Classes present: tensor([0, 2])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 810f96801.jpg | Classes present: tensor([0])\n",
            "Image: 7cf7e0fa6.jpg | Classes present: tensor([0])\n",
            "Image: 817c6c7a8.jpg | Classes present: tensor([0])\n",
            "Image: 7da7fdfca.jpg | Classes present: tensor([0, 2])\n",
            "Image: 7dd4d0f90.jpg | Classes present: tensor([0])\n",
            "Image: 848a1b795.jpg | Classes present: tensor([0])\n",
            "Image: 7de37a671.jpg | Classes present: tensor([0])\n",
            "Image: 85294cff9.jpg | Classes present: tensor([0])\n",
            "Image: 7e0e39e4c.jpg | Classes present: tensor([0])\n",
            "Image: 85294cff9.jpg | Classes present: tensor([0])\n",
            "Image: 7e57b31f7.jpg | Classes present: tensor([0])\n",
            "Image: 7e6015fc5.jpg | Classes present: tensor([0])\n",
            "Image: 854baa70c.jpg | Classes present: tensor([0])\n",
            "Image: 7e9c7f52d.jpg | Classes present: tensor([0])\n",
            "Image: 856f0b6bd.jpg | Classes present: tensor([0])\n",
            "Image: 7efadd1c6.jpg | Classes present: tensor([0])\n",
            "Image: 857400707.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 6838.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 81ab8f502.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  51% 69/134 [00:13<00:10,  6.29it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 30418.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 8600decb6.jpg | Classes present: tensor([0])\n",
            "Image: 81b6f3cca.jpg | Classes present: tensor([0])\n",
            "Image: 8611deb61.jpg | Classes present: tensor([0])\n",
            "Image: 81b6f3cca.jpg | Classes present: tensor([0])\n",
            "Image: 862bcc9c0.jpg | Classes present: tensor([0])\n",
            "Image: 81fa665da.jpg | Classes present: tensor([0, 2])\n",
            "Image: 863b300cb.jpg | Classes present: tensor([0])\n",
            "Image: 8266cca81.jpg | Classes present: tensor([0, 2])\n",
            "Image: 87ae117e9.jpg | Classes present: tensor([0])\n",
            "Image: 82e11b4e4.jpg | Classes present: tensor([0])\n",
            "Image: 87f74731f.jpg | Classes present: tensor([0])\n",
            "Image: 82e32c810.jpg | Classes present: tensor([0])\n",
            "Image: 8847458a0.jpg | Classes present: tensor([0])\n",
            "Image: 8344ef24d.jpg | Classes present: tensor([0])\n",
            "Image: 886eebf8c.jpg | Classes present: tensor([0])\n",
            "Image: 846a8ccab.jpg | Classes present: tensor([0])\n",
            "Image: 847b7640a.jpg | Classes present: tensor([0])\n",
            "Image: 8872fe6db.jpg | Classes present: tensor([0])\n",
            "Image: 8645f73f1.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 14954.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 88e1122cb.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  53% 71/134 [00:13<00:10,  6.10it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 8648b2010.jpg | Classes present: tensor([0])\n",
            "Image: 8a2a8a476.jpg | Classes present: tensor([0])\n",
            "Image: 8a35c59f9.jpg | Classes present: tensor([0])\n",
            "Image: 865574894.jpg | Classes present: tensor([0])\n",
            "Image: 8a485f766.jpg | Classes present: tensor([0])\n",
            "Image: 86aae8998.jpg | Classes present: tensor([0])\n",
            "Image: 8a75d73d9.jpg | Classes present: tensor([0])\n",
            "Image: 86cbb2d1f.jpg | Classes present: tensor([0])\n",
            "Image: 8bb208f36.jpg | Classes present: tensor([0])\n",
            "Image: 86e80375f.jpg | Classes present: tensor([0])\n",
            "Image: 8bb5ada5c.jpg | Classes present: tensor([0])\n",
            "Image: 8709ea899.jpg | Classes present: tensor([0])\n",
            "Image: 8bdf6cee5.jpg | Classes present: tensor([0])\n",
            "Image: 873e04ca8.jpg | Classes present: tensor([0])\n",
            "Image: 8c732ade1.jpg | Classes present: tensor([0])\n",
            "Image: 87754d760.jpg | Classes present: tensor([0])\n",
            "Image: 8cc65d1f7.jpg | Classes present: tensor([0])\n",
            "Image: 8ceba5ea5.jpg | Classes present: tensor([0])\n",
            "Image: 87754d760.jpg | Classes present: tensor([0])\n",
            "Image: 8d36899b1.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [991.   0.   0.   0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 8a87b9578.jpg | Classes present: tensor([0])\n",
            "Image: 8d4206f2a.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  54% 73/134 [00:14<00:09,  6.13it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 8a88f573c.jpg | Classes present: tensor([0])\n",
            "Image: 8d5dde91c.jpg | Classes present: tensor([0])\n",
            "Image: 8a993359d.jpg | Classes present: tensor([0])\n",
            "Image: 8d5f90317.jpg | Classes present: tensor([0])\n",
            "Image: 8aa3af3da.jpg | Classes present: tensor([0])\n",
            "Image: 8f0a7e8af.jpg | Classes present: tensor([0])\n",
            "Image: 8afa2aa27.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8f0a7e8af.jpg | Classes present: tensor([0])\n",
            "Image: 8b495e389.jpg | Classes present: tensor([0])\n",
            "Image: 8f0dcad21.jpg | Classes present: tensor([0])\n",
            "Image: 8b4b4d618.jpg | Classes present: tensor([0])\n",
            "Image: 8f6b07e84.jpg | Classes present: tensor([0])\n",
            "Image: 8b4e90080.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8f8a23f39.jpg | Classes present: tensor([0])\n",
            "Image: 8b9c035ec.jpg | Classes present: tensor([0])\n",
            "Image: 8bab4626b.jpg | Classes present: tensor([0])\n",
            "Image: 8fb4575f3.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 3557.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 8d67593de.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  56% 75/134 [00:14<00:09,  6.30it/s]Image: 8fbd70ddf.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 8d938b3e7.jpg | Classes present: tensor([0])\n",
            "Image: 8d9b43515.jpg | Classes present: tensor([0])\n",
            "Image: 904584541.jpg | Classes present: tensor([0, 3])\n",
            "Image: 8e1fb6f5a.jpg | Classes present: tensor([0])\n",
            "Image: 905964016.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8e6f1eb4f.jpg | Classes present: tensor([0])\n",
            "Image: 9087518f1.jpg | Classes present: tensor([0])\n",
            "Image: 8e933231b.jpg | Classes present: tensor([0])\n",
            "Image: 8ebc9cadc.jpg | Classes present: tensor([0])\n",
            "Image: 9236f984c.jpg | Classes present: tensor([0])\n",
            "Image: 8ec0d428d.jpg | Classes present: tensor([0])\n",
            "Image: 9253b216e.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8ed31effd.jpg | Classes present: tensor([0])\n",
            "Image: 930391b64.jpg | Classes present: tensor([0])\n",
            "Image: 8ed6b8054.jpg | Classes present: tensor([0, 1])\n",
            "Image: 930fe8fc7.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [ 0. 54.  0.  0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 90cd42d5b.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  57% 77/134 [00:14<00:08,  6.44it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [  400.     0. 16682.  8208.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 93126606c.jpg | Classes present: tensor([0])\n",
            "Image: 910540b7d.jpg | Classes present: tensor([0])\n",
            "Image: 9121da7fe.jpg | Classes present: tensor([0])\n",
            "Image: 933a9dc8b.jpg | Classes present: tensor([0])\n",
            "Image: 913e2221d.jpg | Classes present: tensor([0])\n",
            "Image: 9341d848d.jpg | Classes present: tensor([0])\n",
            "Image: 9163ec76b.jpg | Classes present: tensor([0])\n",
            "Image: 9378a6f12.jpg | Classes present: tensor([0])\n",
            "Image: 91696aaca.jpg | Classes present: tensor([0])\n",
            "Image: 9426ce32a.jpg | Classes present: tensor([0])\n",
            "Image: 91696aaca.jpg | Classes present: tensor([0])\n",
            "Image: 94753d945.jpg | Classes present: tensor([0])\n",
            "Image: 9169b4f3a.jpg | Classes present: tensor([0])\n",
            "Image: 963f946a9.jpg | Classes present: tensor([0])\n",
            "Image: 918c32419.jpg | Classes present: tensor([0])\n",
            "Image: 92057aa8a.jpg | Classes present: tensor([0])\n",
            "Image: 9663d6a79.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 94bf15000.jpg | Classes present: tensor([0, 3])\n",
            "Image: 967802d76.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  59% 79/134 [00:15<00:08,  6.46it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 13728.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 974f00b13.jpg | Classes present: tensor([0])\n",
            "Image: 94c910b08.jpg | Classes present: tensor([0])\n",
            "Image: 975b2e5fa.jpg | Classes present: tensor([0])\n",
            "Image: 954d4296b.jpg | Classes present: tensor([0])\n",
            "Image: 9789423c2.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9553974f4.jpg | Classes present: tensor([0])\n",
            "Image: 97b77f9e6.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9557969ee.jpg | Classes present: tensor([0])\n",
            "Image: 955feead2.jpg | Classes present: tensor([0])\n",
            "Image: 97eb88e35.jpg | Classes present: tensor([0])\n",
            "Image: 95eaae02e.jpg | Classes present: tensor([0])\n",
            "Image: 982193e49.jpg | Classes present: tensor([0, 3])\n",
            "Image: 96279bbc2.jpg | Classes present: tensor([0, 2])\n",
            "Image: 982193e49.jpg | Classes present: tensor([0, 3])\n",
            "Image: 963b7a441.jpg | Classes present: tensor([0])\n",
            "Image: 963b7a441.jpg | Classes present: tensor([0])\n",
            "Image: 9aa721852.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [ 682.    0. 3524. 5239.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 98c0127d3.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  60% 81/134 [00:15<00:08,  6.51it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 17607.   786.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 98c634937.jpg | Classes present: tensor([0])\n",
            "Image: 9aa721852.jpg | Classes present: tensor([0])\n",
            "Image: 9ab57a2fa.jpg | Classes present: tensor([0])\n",
            "Image: 991e0dfdf.jpg | Classes present: tensor([0])\n",
            "Image: 9ad1ad629.jpg | Classes present: tensor([0])\n",
            "Image: 9962acd22.jpg | Classes present: tensor([0])\n",
            "Image: 99855ae32.jpg | Classes present: tensor([0])\n",
            "Image: 9af9dc45b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9b09b2a38.jpg | Classes present: tensor([0])\n",
            "Image: 99a9163bc.jpg | Classes present: tensor([0])\n",
            "Image: 99d359803.jpg | Classes present: tensor([0])\n",
            "Image: 9b72243dc.jpg | Classes present: tensor([0])\n",
            "Image: 9ba68fdaa.jpg | Classes present: tensor([0])\n",
            "Image: 99d359803.jpg | Classes present: tensor([0])\n",
            "Image: 9bc62ca61.jpg | Classes present: tensor([0])\n",
            "Image: 99d47e124.jpg | Classes present: tensor([0])\n",
            "Image: 9bd5122c0.jpg | Classes present: tensor([0])\n",
            "Image: 9a064450d.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 9c005a770.jpg | Classes present: tensor([0])\n",
            "Image: 9e1f9aaaf.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9c1c7f69c.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  62% 83/134 [00:15<00:08,  6.18it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 1230.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: 9ea3ea37b.jpg | Classes present: tensor([0])\n",
            "Image: 9ead58088.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9c42e727c.jpg | Classes present: tensor([0])\n",
            "Image: 9ec897b68.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9c4ed4726.jpg | Classes present: tensor([0])\n",
            "Image: 9ed6f9c81.jpg | Classes present: tensor([0])\n",
            "Image: 9c7a6cf21.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9eed09712.jpg | Classes present: tensor([0])\n",
            "Image: 9cfa7be25.jpg | Classes present: tensor([0])\n",
            "Image: 9eed09712.jpg | Classes present: tensor([0])\n",
            "Image: 9d0b3a0f7.jpg | Classes present: tensor([0])\n",
            "Image: 9ef683a79.jpg | Classes present: tensor([0])\n",
            "Image: 9d22ddbf2.jpg | Classes present: tensor([0])\n",
            "Image: 9fed72af4.jpg | Classes present: tensor([0])\n",
            "Image: 9d9020e1d.jpg | Classes present: tensor([0, 2])\n",
            "Image: a0155346d.jpg | Classes present: tensor([0])\n",
            "Image: 9dbb7b85c.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 6158.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Validating Epoch 10:  63% 85/134 [00:16<00:07,  6.44it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 33592.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: a14eeb75d.jpg | Classes present: tensor([0, 2])\n",
            "Image: a02fe46b6.jpg | Classes present: tensor([0])\n",
            "Image: a152690b6.jpg | Classes present: tensor([0])\n",
            "Image: a056c104a.jpg | Classes present: tensor([0])\n",
            "Image: a152690b6.jpg | Classes present: tensor([0])\n",
            "Image: a05708135.jpg | Classes present: tensor([0])\n",
            "Image: a154fdcfd.jpg | Classes present: tensor([0])\n",
            "Image: a0709a1e6.jpg | Classes present: tensor([0])\n",
            "Image: a187d1897.jpg | Classes present: tensor([0])\n",
            "Image: a09a889b2.jpg | Classes present: tensor([0])\n",
            "Image: a18bdb241.jpg | Classes present: tensor([0])\n",
            "Image: a0de93374.jpg | Classes present: tensor([0])\n",
            "Image: a1982cad5.jpg | Classes present: tensor([0])\n",
            "Image: a10c18895.jpg | Classes present: tensor([0])\n",
            "Image: a1bede9b1.jpg | Classes present: tensor([0, 2])\n",
            "Image: a135808ff.jpg | Classes present: tensor([0])\n",
            "Image: a1f5481df.jpg | Classes present: tensor([0])\n",
            "Image: a13c52c08.jpg | Classes present: tensor([0])\n",
            "Image: a21bfa25a.jpg | Classes present: tensor([0])\n",
            "Image: a14e96726.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: a21fa9b86.jpg | Classes present: tensor([0])\n",
            "Image: a316898ca.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  65% 87/134 [00:16<00:07,  6.27it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [ 1850.     0. 11242.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: a22639daa.jpg | Classes present: tensor([0])\n",
            "Image: a335fc5cc.jpg | Classes present: tensor([0])\n",
            "Image: a231b46ec.jpg | Classes present: tensor([0])\n",
            "Image: a33d86440.jpg | Classes present: tensor([0])\n",
            "Image: a239718e1.jpg | Classes present: tensor([0])\n",
            "Image: a37447f04.jpg | Classes present: tensor([0, 2])\n",
            "Image: a2889c2fa.jpg | Classes present: tensor([0])\n",
            "Image: a37447f04.jpg | Classes present: tensor([0, 2])\n",
            "Image: a2889c2fa.jpg | Classes present: tensor([0])\n",
            "Image: a3d5e7319.jpg | Classes present: tensor([0])\n",
            "Image: a28a7b7be.jpg | Classes present: tensor([0])\n",
            "Image: a471d7877.jpg | Classes present: tensor([0])\n",
            "Image: a28a7b7be.jpg | Classes present: tensor([0])\n",
            "Image: a485b97e7.jpg | Classes present: tensor([0])\n",
            "Image: a2bdcd021.jpg | Classes present: tensor([0])\n",
            "Image: a485d538c.jpg | Classes present: tensor([0])\n",
            "Image: a2e328f50.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Validating Epoch 10:  66% 89/134 [00:16<00:06,  6.45it/s]Image: a4c93ac65.jpg | Classes present: tensor([0, 2])\n",
            "Image: a4a648cf6.jpg | Classes present: tensor([0, 3])\n",
            "Image: a4d9a97f6.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 6532. 6016.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: a5b23c751.jpg | Classes present: tensor([0, 2])\n",
            "Image: a4d9a97f6.jpg | Classes present: tensor([0])\n",
            "Image: a5cb0256f.jpg | Classes present: tensor([0, 3])\n",
            "Image: a4dff615e.jpg | Classes present: tensor([0])\n",
            "Image: a67df9196.jpg | Classes present: tensor([0])\n",
            "Image: a5092043e.jpg | Classes present: tensor([0])\n",
            "Image: a68dcc7d2.jpg | Classes present: tensor([0])\n",
            "Image: a52f36666.jpg | Classes present: tensor([0])\n",
            "Image: a6b00abd7.jpg | Classes present: tensor([0])\n",
            "Image: a559091c5.jpg | Classes present: tensor([0])\n",
            "Image: a6b3d554a.jpg | Classes present: tensor([0])\n",
            "Image: a56c8f958.jpg | Classes present: tensor([0])\n",
            "Image: a753532d6.jpg | Classes present: tensor([0])\n",
            "Image: a56c8f958.jpg | Classes present: tensor([0])\n",
            "Image: a753532d6.jpg | Classes present: tensor([0])\n",
            "Image: a56df9123.jpg | Classes present: tensor([0])\n",
            "Image: a7655a8d3.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 1099.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: a7d5ae972.jpg | Classes present: tensor([0])\n",
            "Image: a76b26d44.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  68% 91/134 [00:16<00:06,  6.41it/s]Image: a835a0e50.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 3090. 5694.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: a9378655a.jpg | Classes present: tensor([0])\n",
            "Image: aa4b29d91.jpg | Classes present: tensor([0])\n",
            "Image: a94abfda7.jpg | Classes present: tensor([0, 2])\n",
            "Image: aa7a0bcf3.jpg | Classes present: tensor([0])\n",
            "Image: a9a5ac063.jpg | Classes present: tensor([0])\n",
            "Image: aa9a7363b.jpg | Classes present: tensor([0])\n",
            "Image: a9b1abf48.jpg | Classes present: tensor([0])\n",
            "Image: aae6bc5be.jpg | Classes present: tensor([0, 2])\n",
            "Image: a9c5e9f1e.jpg | Classes present: tensor([0, 2])\n",
            "Image: aaf12ddee.jpg | Classes present: tensor([0])\n",
            "Image: a9e2530ed.jpg | Classes present: tensor([0])\n",
            "Image: ab13f368e.jpg | Classes present: tensor([0])\n",
            "Image: a9f5f9806.jpg | Classes present: tensor([0])\n",
            "Image: ab16f0e09.jpg | Classes present: tensor([0])\n",
            "Image: aa394081e.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 27350.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Validating Epoch 10:  69% 93/134 [00:17<00:06,  6.62it/s]Image: ab1dda536.jpg | Classes present: tensor([0])\n",
            "Image: ab4fab99e.jpg | Classes present: tensor([0, 3])\n",
            "Image: ab2300506.jpg | Classes present: tensor([0])\n",
            "Image: ab6530468.jpg | Classes present: tensor([0])\n",
            "Image: ab70f8ba6.jpg | Classes present: tensor([0, 2])\n",
            "Image: ab2b3d3d9.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 1146.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: ad6aed3f4.jpg | Classes present: tensor([0])\n",
            "Image: abe8e7faf.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  70% 94/134 [00:17<00:05,  6.72it/s]Image: ad6fb4fab.jpg | Classes present: tensor([0])\n",
            "Image: ac15719f1.jpg | Classes present: tensor([0, 2])\n",
            "Image: ad9ad21f4.jpg | Classes present: tensor([0])\n",
            "Image: ac461b596.jpg | Classes present: tensor([0])\n",
            "Image: add980018.jpg | Classes present: tensor([0, 2])\n",
            "Image: ac504079d.jpg | Classes present: tensor([0])\n",
            "Image: adf5fdfe2.jpg | Classes present: tensor([0])\n",
            "Image: ac9c592aa.jpg | Classes present: tensor([0])\n",
            "Image: adf93f9bf.jpg | Classes present: tensor([0])\n",
            "Image: acd30bd6a.jpg | Classes present: tensor([0])\n",
            "Image: adff445fd.jpg | Classes present: tensor([0, 2])\n",
            "Image: ad6506c7b.jpg | Classes present: tensor([0])\n",
            "Image: ae4555b5b.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 15900. 24641.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: aea51e93f.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  71% 95/134 [00:17<00:06,  6.20it/s]Image: aebbc40a6.jpg | Classes present: tensor([0, 2])\n",
            "Image: aeb34560d.jpg | Classes present: tensor([0])\n",
            "Image: aeda5b216.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 24442.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: aee116071.jpg | Classes present: tensor([0])\n",
            "Image: afd3f856d.jpg | Classes present: tensor([0])\n",
            "Image: af4cdefaa.jpg | Classes present: tensor([0])\n",
            "Image: b04b907b2.jpg | Classes present: tensor([0, 2])\n",
            "Image: b0bd510db.jpg | Classes present: tensor([0])\n",
            "Image: af4d2ee24.jpg | Classes present: tensor([0])\n",
            "Image: b107bf5bd.jpg | Classes present: tensor([0])\n",
            "Image: af5c06a20.jpg | Classes present: tensor([0])\n",
            "Image: b10ca1dc4.jpg | Classes present: tensor([0])\n",
            "Image: af7c08f36.jpg | Classes present: tensor([0])\n",
            "Image: b147f0f0f.jpg | Classes present: tensor([0])\n",
            "Image: af7c08f36.jpg | Classes present: tensor([0])\n",
            "Image: b162a9cb2.jpg | Classes present: tensor([0])\n",
            "Image: af7db8470.jpg | Classes present: tensor([0])\n",
            "Image: b1639af61.jpg | Classes present: tensor([0])\n",
            "Image: afb854388.jpg | Classes present: tensor([0])\n",
            "Image: b17fcb164.jpg | Classes present: tensor([0, 2])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [  56.    0. 1869.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: b1bbea81b.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  72% 97/134 [00:17<00:06,  5.98it/s]Image: b1c4d3872.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 9835.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: b37a57736.jpg | Classes present: tensor([0])\n",
            "Image: b1d3f12b6.jpg | Classes present: tensor([0])\n",
            "Image: b3920826e.jpg | Classes present: tensor([0])\n",
            "Image: b3b8f0c9e.jpg | Classes present: tensor([0, 2])\n",
            "Image: b1d3f12b6.jpg | Classes present: tensor([0])\n",
            "Image: b1f5ce725.jpg | Classes present: tensor([0])\n",
            "Image: b3f7ae992.jpg | Classes present: tensor([0])\n",
            "Image: b20fb15ff.jpg | Classes present: tensor([0])\n",
            "Image: b40abdab2.jpg | Classes present: tensor([0])\n",
            "Image: b23e854e8.jpg | Classes present: tensor([0])\n",
            "Image: b41747a10.jpg | Classes present: tensor([0, 2])\n",
            "Image: b2854eaff.jpg | Classes present: tensor([0])\n",
            "Image: b442ff31d.jpg | Classes present: tensor([0])\n",
            "Image: b2c9fde17.jpg | Classes present: tensor([0])\n",
            "Image: b44cfa5ba.jpg | Classes present: tensor([0])\n",
            "Image: b2cbd553f.jpg | Classes present: tensor([0])\n",
            "Image: b46dafae2.jpg | Classes present: tensor([0])\n",
            "Image: b2e59bdaa.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: b4cc6a4ed.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  74% 99/134 [00:18<00:05,  5.99it/s]Image: b54038841.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 22283.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: b64f0985f.jpg | Classes present: tensor([0])\n",
            "Image: b56de2940.jpg | Classes present: tensor([0])\n",
            "Image: b66721b1f.jpg | Classes present: tensor([0])\n",
            "Image: b5804f43f.jpg | Classes present: tensor([0, 2])\n",
            "Image: b68c95b87.jpg | Classes present: tensor([0])\n",
            "Image: b58132808.jpg | Classes present: tensor([0, 2])\n",
            "Image: b69aaf096.jpg | Classes present: tensor([0])\n",
            "Image: b5b48f9f3.jpg | Classes present: tensor([0])\n",
            "Image: b5b99c878.jpg | Classes present: tensor([0])\n",
            "Image: b6b66ca8c.jpg | Classes present: tensor([0, 2])\n",
            "Image: b6f61c6b0.jpg | Classes present: tensor([0])\n",
            "Image: b5b99c878.jpg | Classes present: tensor([0])\n",
            "Image: b6fc52f4e.jpg | Classes present: tensor([0])\n",
            "Image: b5cda37bc.jpg | Classes present: tensor([0])\n",
            "Image: b71ee7bd0.jpg | Classes present: tensor([0, 3])\n",
            "Image: b64b9969e.jpg | Classes present: tensor([0, 2])\n",
            "Image: b72d341bf.jpg | Classes present: tensor([0])\n",
            "Image: b64b9969e.jpg | Classes present: tensor([0, 2])\n",
            "Image: b733d1672.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 23140.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: b733d1672.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  75% 101/134 [00:18<00:05,  5.85it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 2304. 1730.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: b941eeaa7.jpg | Classes present: tensor([0, 2])\n",
            "Image: b799d56cd.jpg | Classes present: tensor([0])\n",
            "Image: b9752d783.jpg | Classes present: tensor([0])\n",
            "Image: b7a1d89ae.jpg | Classes present: tensor([0])\n",
            "Image: b99b4abea.jpg | Classes present: tensor([0])\n",
            "Image: b7b6fd4ed.jpg | Classes present: tensor([0])\n",
            "Image: b99b4abea.jpg | Classes present: tensor([0])\n",
            "Image: b87571cc4.jpg | Classes present: tensor([0])\n",
            "Image: b9b5cb6f5.jpg | Classes present: tensor([0])\n",
            "Image: b8b03dcfe.jpg | Classes present: tensor([0, 2])\n",
            "Image: b9fa8b135.jpg | Classes present: tensor([0])\n",
            "Image: b8ba151b1.jpg | Classes present: tensor([0, 2])\n",
            "Image: ba4284649.jpg | Classes present: tensor([0])\n",
            "Image: b925ef3b7.jpg | Classes present: tensor([0])\n",
            "Image: b933f4591.jpg | Classes present: tensor([0])\n",
            "Image: b93f5fdc0.jpg | Classes present: tensor([0, 2])\n",
            "Image: ba4ac3636.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [ 1257.     0. 12924.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Validating Epoch 10:  77% 103/134 [00:18<00:04,  6.24it/s]Image: ba4ac3636.jpg | Classes present: tensor([0])\n",
            "Image: bab5271b6.jpg | Classes present: tensor([0])\n",
            "Image: bab5271b6.jpg | Classes present: tensor([0])\n",
            "Image: bac68f2c3.jpg | Classes present: tensor([0, 2])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [4158.    0. 1638.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: bacb738d3.jpg | Classes present: tensor([0])\n",
            "Image: bbfdbc490.jpg | Classes present: tensor([0])\n",
            "Image: badc586ae.jpg | Classes present: tensor([0])\n",
            "Image: bc0a90164.jpg | Classes present: tensor([0, 3])\n",
            "Image: bb2975da4.jpg | Classes present: tensor([0])\n",
            "Image: bc72a7548.jpg | Classes present: tensor([0])\n",
            "Image: bc751c15d.jpg | Classes present: tensor([0])\n",
            "Image: bb3421ee8.jpg | Classes present: tensor([0])\n",
            "Image: bb371f33d.jpg | Classes present: tensor([0, 2])\n",
            "Image: bc7ce8f4d.jpg | Classes present: tensor([0])\n",
            "Image: bb4e89121.jpg | Classes present: tensor([0])\n",
            "Image: bcb794eed.jpg | Classes present: tensor([0])\n",
            "Image: bbb96273d.jpg | Classes present: tensor([0])\n",
            "Image: bd0e26062.jpg | Classes present: tensor([0])\n",
            "Image: bdbf5535f.jpg | Classes present: tensor([0])\n",
            "Image: bbec1ee47.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 8561.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: bdce84e23.jpg | Classes present: tensor([0])\n",
            "Image: bea7ff137.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  78% 105/134 [00:19<00:04,  5.81it/s]Image: be65d7bb7.jpg | Classes present: tensor([0])\n",
            "Image: bf3db21e9.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0.    0. 2745.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: c0e34b64b.jpg | Classes present: tensor([0])\n",
            "Image: bfa17327e.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  79% 106/134 [00:19<00:04,  6.09it/s]Image: c12bbdec9.jpg | Classes present: tensor([0])\n",
            "Image: bfa249587.jpg | Classes present: tensor([0])\n",
            "Image: c232eea0c.jpg | Classes present: tensor([0])\n",
            "Image: bfd24be30.jpg | Classes present: tensor([0, 2])\n",
            "Image: c24caa9be.jpg | Classes present: tensor([0])\n",
            "Image: bfd24be30.jpg | Classes present: tensor([0, 2])\n",
            "Image: bfd56c3d2.jpg | Classes present: tensor([0])\n",
            "Image: c25e12747.jpg | Classes present: tensor([0])\n",
            "Image: c01fd972f.jpg | Classes present: tensor([0])\n",
            "Image: c2760fc1a.jpg | Classes present: tensor([0, 3])\n",
            "Image: c038c0588.jpg | Classes present: tensor([0])\n",
            "Image: c2760fc1a.jpg | Classes present: tensor([0, 3])\n",
            "Image: c04b0d160.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 13538.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: c27ce861d.jpg | Classes present: tensor([0])\n",
            "Image: c2b446019.jpg | Classes present: tensor([0])\n",
            "Image: c30805f9e.jpg | Classes present: tensor([0])\n",
            "Image: c319a0d11.jpg | Classes present: tensor([0, 2])\n",
            "Validating Epoch 10:  80% 107/134 [00:19<00:05,  4.66it/s]Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [  0.   0.   0. 186.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: c319a0d11.jpg | Classes present: tensor([0, 2])\n",
            "Image: c44c93192.jpg | Classes present: tensor([0])\n",
            "Image: c46065903.jpg | Classes present: tensor([0])\n",
            "Image: c34f14586.jpg | Classes present: tensor([0])\n",
            "Image: c495e234e.jpg | Classes present: tensor([0])\n",
            "Image: c34f14586.jpg | Classes present: tensor([0])\n",
            "Image: c34fc79b6.jpg | Classes present: tensor([0])\n",
            "Image: c4aeca424.jpg | Classes present: tensor([0])\n",
            "Image: c37633c03.jpg | Classes present: tensor([0])\n",
            "Image: c3c091454.jpg | Classes present: tensor([0, 3])\n",
            "Image: c4dc92ef9.jpg | Classes present: tensor([0])\n",
            "Image: c3cae8972.jpg | Classes present: tensor([0])\n",
            "Image: c4dc92ef9.jpg | Classes present: tensor([0])\n",
            "Image: c3ff6937c.jpg | Classes present: tensor([0])\n",
            "Image: c4f5ebbb2.jpg | Classes present: tensor([0])\n",
            "Image: c40a05198.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 24288.  6118.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: c5af9872c.jpg | Classes present: tensor([0])\n",
            "Image: c53423923.jpg | Classes present: tensor([0, 2])\n",
            "Validating Epoch 10:  81% 109/134 [00:20<00:05,  4.28it/s]Image: c54db71af.jpg | Classes present: tensor([0, 3])\n",
            "Image: c5b08d4e3.jpg | Classes present: tensor([0])\n",
            "Image: c5a41d53c.jpg | Classes present: tensor([0])\n",
            "Image: c5b08d4e3.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 4140.  254.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Validating Epoch 10:  82% 110/134 [00:20<00:05,  4.44it/s]Image: c5da9e8c7.jpg | Classes present: tensor([0])\n",
            "Image: c746f473d.jpg | Classes present: tensor([0, 2])\n",
            "Image: c74abe00a.jpg | Classes present: tensor([0])\n",
            "Image: c5e69fd8f.jpg | Classes present: tensor([0])\n",
            "Image: c795455ba.jpg | Classes present: tensor([0])\n",
            "Image: c5fa2923b.jpg | Classes present: tensor([0])\n",
            "Image: c7aeb9c82.jpg | Classes present: tensor([0])\n",
            "Image: c63e60886.jpg | Classes present: tensor([0])\n",
            "Image: c63e60886.jpg | Classes present: tensor([0])\n",
            "Image: c7aeb9c82.jpg | Classes present: tensor([0])\n",
            "Image: c6afe1599.jpg | Classes present: tensor([0])\n",
            "Image: c7d002c29.jpg | Classes present: tensor([0, 2])\n",
            "Image: c7f93d8bd.jpg | Classes present: tensor([0])\n",
            "Image: c6d3371a8.jpg | Classes present: tensor([0])\n",
            "Image: c7fb9db8c.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: c89e96115.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  83% 111/134 [00:21<00:06,  3.74it/s]Image: c8216657a.jpg | Classes present: tensor([0])\n",
            "Image: c8c0e5b9d.jpg | Classes present: tensor([0])\n",
            "Image: c85251430.jpg | Classes present: tensor([0])\n",
            "Image: c8ed5e8ab.jpg | Classes present: tensor([0, 2])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 7863.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: c916658f1.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  84% 112/134 [00:21<00:05,  4.30it/s]Image: ca492d6f1.jpg | Classes present: tensor([0])\n",
            "Image: ca82d646f.jpg | Classes present: tensor([0])\n",
            "Image: c94bd179c.jpg | Classes present: tensor([0])\n",
            "Image: ca9d7749b.jpg | Classes present: tensor([0])\n",
            "Image: c94f78afa.jpg | Classes present: tensor([0])\n",
            "Image: c9ae4cb29.jpg | Classes present: tensor([0, 2])\n",
            "Image: cac001c04.jpg | Classes present: tensor([0])\n",
            "Image: c9ae4cb29.jpg | Classes present: tensor([0, 2])\n",
            "Image: c9cd221c5.jpg | Classes present: tensor([0])\n",
            "Image: cb094c2cb.jpg | Classes present: tensor([0])\n",
            "Image: c9d24ef83.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 11387.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: cbd27127f.jpg | Classes present: tensor([0])\n",
            "Image: cb37fc190.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  84% 113/134 [00:21<00:05,  4.03it/s]Image: cc0bf97cf.jpg | Classes present: tensor([0])\n",
            "Image: cb383b2f7.jpg | Classes present: tensor([0])\n",
            "Image: cc3b99f17.jpg | Classes present: tensor([0])\n",
            "Image: cb43d7be5.jpg | Classes present: tensor([0])\n",
            "Image: cc5bae861.jpg | Classes present: tensor([0])\n",
            "Image: cb53b96ce.jpg | Classes present: tensor([0])\n",
            "Image: ccbd751f2.jpg | Classes present: tensor([0])\n",
            "Image: cb9fe5699.jpg | Classes present: tensor([0])\n",
            "Image: ccd94dc85.jpg | Classes present: tensor([0])\n",
            "Image: cd14c73db.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: ccf39a604.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  85% 114/134 [00:21<00:05,  3.77it/s]Image: cd23d4841.jpg | Classes present: tensor([0])\n",
            "Image: cd04164a0.jpg | Classes present: tensor([0])\n",
            "Image: cd0c2417f.jpg | Classes present: tensor([0])\n",
            "Image: cd14c73db.jpg | Classes present: tensor([0])\n",
            "Image: cd465dc7d.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [1005.    0.    0.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: ceba9dc16.jpg | Classes present: tensor([0])\n",
            "Image: cd475d2a3.jpg | Classes present: tensor([0, 2])\n",
            "Validating Epoch 10:  86% 115/134 [00:21<00:04,  4.06it/s]Image: ceba9dc16.jpg | Classes present: tensor([0])\n",
            "Image: ce02c322e.jpg | Classes present: tensor([0])\n",
            "Image: ced4439da.jpg | Classes present: tensor([0])\n",
            "Image: ce05c2c3f.jpg | Classes present: tensor([0])\n",
            "Image: cede14189.jpg | Classes present: tensor([0])\n",
            "Image: ce11ffd78.jpg | Classes present: tensor([0])\n",
            "Image: cef5ff47d.jpg | Classes present: tensor([0])\n",
            "Image: ce43bdd06.jpg | Classes present: tensor([0, 2])\n",
            "Image: cf0641053.jpg | Classes present: tensor([0])\n",
            "Image: ce7b7ac0b.jpg | Classes present: tensor([0])\n",
            "Image: cea2ea962.jpg | Classes present: tensor([0])\n",
            "Image: cf0641053.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 10325.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: cff387e60.jpg | Classes present: tensor([0])\n",
            "Image: cf1f3345c.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  87% 116/134 [00:22<00:05,  3.38it/s]Image: d000d7ef5.jpg | Classes present: tensor([0])\n",
            "Image: cf5231a23.jpg | Classes present: tensor([0])\n",
            "Image: d02f1b229.jpg | Classes present: tensor([0])\n",
            "Image: d04e02d1f.jpg | Classes present: tensor([0])\n",
            "Image: cf8e21964.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: d0578ca87.jpg | Classes present: tensor([0])\n",
            "Image: d1886af80.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  87% 117/134 [00:22<00:04,  3.99it/s]Image: d0befd683.jpg | Classes present: tensor([0])\n",
            "Image: d1e1bf13e.jpg | Classes present: tensor([0])\n",
            "Image: d1023fa39.jpg | Classes present: tensor([0, 2])\n",
            "Image: d11130898.jpg | Classes present: tensor([0])\n",
            "Image: d1ed49385.jpg | Classes present: tensor([0])\n",
            "Image: d2291de5c.jpg | Classes present: tensor([0])\n",
            "Image: d129fe51e.jpg | Classes present: tensor([0])\n",
            "Image: d2291de5c.jpg | Classes present: tensor([0])\n",
            "Image: d169e1b81.jpg | Classes present: tensor([0, 3])\n",
            "Image: d239a83c4.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 5348.  854.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: d283f3744.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  88% 118/134 [00:22<00:04,  3.76it/s]Image: d2454fd68.jpg | Classes present: tensor([0])\n",
            "Image: d2a854e69.jpg | Classes present: tensor([0])\n",
            "Image: d245c4e7f.jpg | Classes present: tensor([0])\n",
            "Image: d25356a51.jpg | Classes present: tensor([0])\n",
            "Image: d2670190d.jpg | Classes present: tensor([0])\n",
            "Image: d2bbde0a4.jpg | Classes present: tensor([0, 2])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Validating Epoch 10:  89% 119/134 [00:22<00:03,  4.06it/s]Image: d31e0200c.jpg | Classes present: tensor([0])\n",
            "Image: d5353adfc.jpg | Classes present: tensor([0, 2])\n",
            "Image: d37c88411.jpg | Classes present: tensor([0])\n",
            "Image: d535c41bf.jpg | Classes present: tensor([0])\n",
            "Image: d3d6d9b6a.jpg | Classes present: tensor([0])\n",
            "Image: d57629343.jpg | Classes present: tensor([0])\n",
            "Image: d4387afd3.jpg | Classes present: tensor([0])\n",
            "Image: d59b4476a.jpg | Classes present: tensor([0])\n",
            "Image: d46866225.jpg | Classes present: tensor([0])\n",
            "Image: d5bdfa378.jpg | Classes present: tensor([0])\n",
            "Image: d4af6d206.jpg | Classes present: tensor([0])\n",
            "Image: d5f7cde8a.jpg | Classes present: tensor([0, 2])\n",
            "Image: d52b35e0e.jpg | Classes present: tensor([0])\n",
            "Image: d60ae28dc.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [ 682.    0. 7363.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: d6ef360e3.jpg | Classes present: tensor([0, 3])\n",
            "Image: d66e4eb3f.jpg | Classes present: tensor([0, 2])\n",
            "Validating Epoch 10:  90% 120/134 [00:23<00:03,  3.53it/s]Image: d6777d642.jpg | Classes present: tensor([0, 3])\n",
            "Image: d6ef360e3.jpg | Classes present: tensor([0, 3])\n",
            "Image: d6d71b8ec.jpg | Classes present: tensor([0])\n",
            "Image: d6ff87222.jpg | Classes present: tensor([0, 3])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 14214. 13325.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: d7e3d3784.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  90% 121/134 [00:23<00:03,  4.15it/s]Image: d70e75dca.jpg | Classes present: tensor([0])\n",
            "Image: d7221e8ce.jpg | Classes present: tensor([0])\n",
            "Image: d7e693160.jpg | Classes present: tensor([0, 3])\n",
            "Image: d81eb8a93.jpg | Classes present: tensor([0])\n",
            "Image: d7686d307.jpg | Classes present: tensor([0])\n",
            "Image: d849d7a48.jpg | Classes present: tensor([0])\n",
            "Image: d77e9ff45.jpg | Classes present: tensor([0])\n",
            "Image: d860da430.jpg | Classes present: tensor([0])\n",
            "Image: d78e97810.jpg | Classes present: tensor([0])\n",
            "Image: d8d851749.jpg | Classes present: tensor([0])\n",
            "Image: d7a43c6f6.jpg | Classes present: tensor([0, 2])\n",
            "Image: d8e21a2ae.jpg | Classes present: tensor([0])\n",
            "Image: d7ae2c9be.jpg | Classes present: tensor([0])\n",
            "Image: d96baa2ce.jpg | Classes present: tensor([0, 2])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 23551. 16039.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: d9bfea1ea.jpg | Classes present: tensor([0, 2])\n",
            "Image: da6fb7dc1.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  91% 122/134 [00:23<00:02,  4.11it/s]Image: da20fe743.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [    0.     0. 11896. 21037.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: dac8bf38a.jpg | Classes present: tensor([0])\n",
            "Image: dc46bd374.jpg | Classes present: tensor([0, 2])\n",
            "Image: dc499be11.jpg | Classes present: tensor([0])\n",
            "Image: daeea39b1.jpg | Classes present: tensor([0, 2])\n",
            "Image: db0547371.jpg | Classes present: tensor([0])\n",
            "Image: dc58fa33b.jpg | Classes present: tensor([0])\n",
            "Image: db064ce4a.jpg | Classes present: tensor([0])\n",
            "Image: dc636ab48.jpg | Classes present: tensor([0])\n",
            "Image: db17f3e99.jpg | Classes present: tensor([0])\n",
            "Image: dd2c992b2.jpg | Classes present: tensor([0])\n",
            "Image: db3d85bc9.jpg | Classes present: tensor([0])\n",
            "Image: dd441d6a0.jpg | Classes present: tensor([0])\n",
            "Image: db5aabcb0.jpg | Classes present: tensor([0, 2])\n",
            "Image: dd441d6a0.jpg | Classes present: tensor([0])\n",
            "Image: db62a970a.jpg | Classes present: tensor([0])\n",
            "Image: dd8af6471.jpg | Classes present: tensor([0])\n",
            "Image: db6b86601.jpg | Classes present: tensor([0])\n",
            "Image: dd97d4b45.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 5014.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Validating Epoch 10:  93% 124/134 [00:24<00:02,  4.90it/s]Image: de1983d54.jpg | Classes present: tensor([0])\n",
            "Image: ddf1692c2.jpg | Classes present: tensor([0])\n",
            "Image: de5a08726.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 3248.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: de85c63cb.jpg | Classes present: tensor([0])\n",
            "Image: df656b199.jpg | Classes present: tensor([0])\n",
            "Image: de85c63cb.jpg | Classes present: tensor([0])\n",
            "Image: df70a7e07.jpg | Classes present: tensor([0])\n",
            "Image: de9ce7271.jpg | Classes present: tensor([0])\n",
            "Image: df983abed.jpg | Classes present: tensor([0, 2])\n",
            "Image: dea277f4a.jpg | Classes present: tensor([0, 2])\n",
            "Image: dfc4b8d29.jpg | Classes present: tensor([0])\n",
            "Image: def2e3f57.jpg | Classes present: tensor([0])\n",
            "Image: e003d691f.jpg | Classes present: tensor([0])\n",
            "Image: defee8509.jpg | Classes present: tensor([0])\n",
            "Image: e03bf53d8.jpg | Classes present: tensor([0])\n",
            "Image: deff23782.jpg | Classes present: tensor([0])\n",
            "Image: df0168063.jpg | Classes present: tensor([0])\n",
            "Image: e0490b7cf.jpg | Classes present: tensor([0])\n",
            "Image: e0ad8fed3.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [  0.   0. 288.   0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: e04f5c163.jpg | Classes present: tensor([0, 2])\n",
            "Validating Epoch 10:  94% 126/134 [00:24<00:01,  5.45it/s]Image: e0b3e7b3f.jpg | Classes present: tensor([0])\n",
            "Image: e055a603c.jpg | Classes present: tensor([0])\n",
            "Image: e0b3e7b3f.jpg | Classes present: tensor([0])\n",
            "Image: e07c94229.jpg | Classes present: tensor([0])\n",
            "Image: e0cc2a416.jpg | Classes present: tensor([0])\n",
            "Image: e1662a8c3.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 5197.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: e2d64c010.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  95% 127/134 [00:24<00:01,  5.94it/s]Image: e21fd95ad.jpg | Classes present: tensor([0, 3])\n",
            "Image: e2f004578.jpg | Classes present: tensor([0])\n",
            "Image: e29d6c141.jpg | Classes present: tensor([0])\n",
            "Image: e30ea20d9.jpg | Classes present: tensor([0, 2])\n",
            "Image: e2c4275d6.jpg | Classes present: tensor([0])\n",
            "Image: e32bb7b41.jpg | Classes present: tensor([0])\n",
            "Image: e36a70d40.jpg | Classes present: tensor([0])\n",
            "Image: e2d02393b.jpg | Classes present: tensor([0, 2])\n",
            "Image: e2d64c010.jpg | Classes present: tensor([0])\n",
            "Image: e401b6539.jpg | Classes present: tensor([0])\n",
            "Image: e45010a6a.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [ 682.    0. 8811. 1039.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Validating Epoch 10:  96% 128/134 [00:24<00:01,  5.72it/s]Image: e495d5456.jpg | Classes present: tensor([0])\n",
            "Image: e461fe709.jpg | Classes present: tensor([0])\n",
            "Image: e495d5456.jpg | Classes present: tensor([0])\n",
            "Image: e479a2e88.jpg | Classes present: tensor([0])\n",
            "Image: e51c76beb.jpg | Classes present: tensor([0])\n",
            "Image: e55bc715f.jpg | Classes present: tensor([0])\n",
            "Image: e4911993d.jpg | Classes present: tensor([0])\n",
            "Image: e56c928ee.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [  682.     0. 10028.     0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: e5b65b5ec.jpg | Classes present: tensor([0])\n",
            "Image: e56d5dfde.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  96% 129/134 [00:24<00:00,  5.91it/s]Image: e5c50b997.jpg | Classes present: tensor([0])\n",
            "Image: e56f52c1e.jpg | Classes present: tensor([0])\n",
            "Image: e5cc898b6.jpg | Classes present: tensor([0])\n",
            "Image: e573ac857.jpg | Classes present: tensor([0])\n",
            "Image: e5e0fe470.jpg | Classes present: tensor([0])\n",
            "Image: e573ac857.jpg | Classes present: tensor([0])\n",
            "Image: e5ea04944.jpg | Classes present: tensor([0])\n",
            "Image: e57efd4b4.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: e5f1d5a38.jpg | Classes present: tensor([0])\n",
            "Image: e6bf58db7.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  97% 130/134 [00:24<00:00,  6.05it/s]Image: e6c32de72.jpg | Classes present: tensor([0])\n",
            "Image: e658a2891.jpg | Classes present: tensor([0])\n",
            "Image: e70c4768b.jpg | Classes present: tensor([0])\n",
            "Image: e665a434f.jpg | Classes present: tensor([0])\n",
            "Image: e7268620b.jpg | Classes present: tensor([0, 2])\n",
            "Image: e667de6f9.jpg | Classes present: tensor([0])\n",
            "Image: e77d57652.jpg | Classes present: tensor([0])\n",
            "Image: e6a44cda3.jpg | Classes present: tensor([0])\n",
            "Image: e7c915edc.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [0. 0. 0. 0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Image: ea13e9557.jpg | Classes present: tensor([0])\n",
            "Validating Epoch 10:  98% 131/134 [00:25<00:00,  5.90it/s]Image: e91814529.jpg | Classes present: tensor([0])\n",
            "Image: ea8acd661.jpg | Classes present: tensor([0])\n",
            "Image: e9463eb04.jpg | Classes present: tensor([0])\n",
            "Image: eaaa61b15.jpg | Classes present: tensor([0])\n",
            "Image: e9b77950e.jpg | Classes present: tensor([0])\n",
            "Image: eab9d667f.jpg | Classes present: tensor([0])\n",
            "Image: e9b77950e.jpg | Classes present: tensor([0])\n",
            "Image: eae840b74.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [  0.   0. 823.   0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Validating Epoch 10:  99% 132/134 [00:25<00:00,  6.52it/s]Image: eb4225311.jpg | Classes present: tensor([0])\n",
            "Image: eca0aa4ff.jpg | Classes present: tensor([0])\n",
            "Image: eb6983d21.jpg | Classes present: tensor([0])\n",
            "Image: eb7ec1f85.jpg | Classes present: tensor([0, 2])\n",
            "Image: ed1c6be8d.jpg | Classes present: tensor([0])\n",
            "Image: ec52fac2d.jpg | Classes present: tensor([0])\n",
            "Image: ed22af554.jpg | Classes present: tensor([0, 2])\n",
            "Image: ec6a951ba.jpg | Classes present: tensor([0])\n",
            "Image: ed861754e.jpg | Classes present: tensor([0])\n",
            "Validation Batch - Image shape: torch.Size([10, 3, 160, 160]), Mask shape: torch.Size([10, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 4362.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Validating Epoch 10:  99% 133/134 [00:25<00:00,  6.45it/s]Validation Batch - Image shape: torch.Size([4, 3, 160, 160]), Mask shape: torch.Size([4, 4, 160, 160])\n",
            "Validation Batch - Positive pixels per class: [   0.    0. 1757.    0.]\n",
            "Correcting device mismatch: cpu -> cuda\n",
            "Validating Epoch 10: 100% 134/134 [00:25<00:00,  5.23it/s]\n",
            "GPU Memory After: 0.09GB\n",
            "\n",
            "Validation F1 Scores:\n",
            "Class 1: 0.0015 | Class 2: 0.0000\n",
            "Class 3: 0.0649 | Class 4: 0.0151\n",
            "Macro Avg F1: 0.0204\n",
            "\n",
            "=== Pipeline completed in 2735.64 seconds ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMYOEpBMUPP5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7611a52f-0a8d-40f5-fb8a-8e825240bd35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "=== Verifying dataset paths ===\n",
            "Found 5506 test images\n",
            "\n",
            "=== Testing DRAEM model ===\n",
            "Running: python test_DRAEM.py --data_path /content/drive/MyDrive/severstal-steel-defect-detection --checkpoint_path /content/Severstal_Steel_DRAEM_implementation/checkpoints/severstal/model_best.pth --test_samples 0 --img_size 160\n",
            "Using device: cuda\n",
            "True Class Weights: {1: 7.909698995773724, 2: 28.724696344645874, 3: 1.3776699028858705, 4: 8.857677901515896}\n",
            "Class distribution:\n",
            "ClassId\n",
            "3    1037\n",
            "1     180\n",
            "4     160\n",
            "2      50\n",
            "Name: count, dtype: int64\n",
            "Loaded 1334 validation samples.\n",
            "\n",
            "Loading checkpoint...\n",
            "\n",
            "=== Calculating Optimal Thresholds ===\n",
            "Threshold Optimization:   0% 0/334 [00:00<?, ?it/s]Image: 0025bde0c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 000a4bcdd.jpg | Classes present: tensor([0])\n",
            "Image: 000f6bf48.jpg | Classes present: tensor([0])\n",
            "Image: 0095cd374.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0014fce06.jpg | Classes present: tensor([0])\n",
            "Image: 00ac8372f.jpg | Classes present: tensor([0])\n",
            "Image: 00ac8372f.jpg | Classes present: tensor([0])\n",
            "Image: 0025bde0c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0139dd004.jpg | Classes present: tensor([0])\n",
            "Image: 00af2671f.jpg | Classes present: tensor([0])\n",
            "Image: 01764ee81.jpg | Classes present: tensor([0, 2])\n",
            "Image: 00bf8497a.jpg | Classes present: tensor([0])\n",
            "Image: 01919944c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 00d639396.jpg | Classes present: tensor([0])\n",
            "Image: 01cfacf80.jpg | Classes present: tensor([0, 3])\n",
            "Image: 01338c0ea.jpg | Classes present: tensor([0])\n",
            "Image: 01cfacf80.jpg | Classes present: tensor([0, 3])\n",
            "Image: 01df77e59.jpg | Classes present: tensor([0])\n",
            "Image: 01e020dc5.jpg | Classes present: tensor([0])\n",
            "Image: 01fd320c9.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:   0% 1/334 [00:01<07:02,  1.27s/it]Image: 020ff3106.jpg | Classes present: tensor([0])\n",
            "Image: 02c79bfcb.jpg | Classes present: tensor([0])\n",
            "Image: 02d18b8a4.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:   1% 4/334 [00:01<01:30,  3.66it/s]Image: 034941f9d.jpg | Classes present: tensor([0])\n",
            "Image: 02291e913.jpg | Classes present: tensor([0])\n",
            "Image: 0386ce84b.jpg | Classes present: tensor([0])\n",
            "Image: 02701c239.jpg | Classes present: tensor([0])\n",
            "Image: 04e23e414.jpg | Classes present: tensor([0])\n",
            "Image: 056e34021.jpg | Classes present: tensor([0])\n",
            "Image: 02b2d3aa4.jpg | Classes present: tensor([0])\n",
            "Image: 05d6bccf8.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:   2% 6/334 [00:01<01:07,  4.88it/s]Image: 038f14456.jpg | Classes present: tensor([0])\n",
            "Image: 03faf7462.jpg | Classes present: tensor([0])\n",
            "Image: 060964105.jpg | Classes present: tensor([0])\n",
            "Image: 04072b39a.jpg | Classes present: tensor([0])\n",
            "Image: 06e7b157a.jpg | Classes present: tensor([0])\n",
            "Image: 04d49c95d.jpg | Classes present: tensor([0])\n",
            "Image: 06eb2151d.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:   2% 8/334 [00:01<00:58,  5.61it/s]Image: 068c6c4a9.jpg | Classes present: tensor([0])\n",
            "Image: 06f52f4dd.jpg | Classes present: tensor([0])\n",
            "Image: 0696cfa05.jpg | Classes present: tensor([0, 2])\n",
            "Image: 06fb3a6e5.jpg | Classes present: tensor([0])\n",
            "Image: 06ad83bac.jpg | Classes present: tensor([0, 2])\n",
            "Image: 06e6e7a8c.jpg | Classes present: tensor([0])\n",
            "Image: 08193cfc8.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:   3% 10/334 [00:02<00:52,  6.18it/s]Image: 0841074c1.jpg | Classes present: tensor([0])\n",
            "Image: 0712fbd90.jpg | Classes present: tensor([0])\n",
            "Image: 07ac7620c.jpg | Classes present: tensor([0])\n",
            "Image: 085bcd104.jpg | Classes present: tensor([0, 2])\n",
            "Image: 07c917711.jpg | Classes present: tensor([0])\n",
            "Image: 088aee82e.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0808a098b.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:   4% 12/334 [00:02<00:52,  6.11it/s]Image: 08a1a079b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 08de8df60.jpg | Classes present: tensor([0])\n",
            "Image: 08a1a079b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 08e3aadde.jpg | Classes present: tensor([0])\n",
            "Image: 08de8621d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 08f9c685f.jpg | Classes present: tensor([0])\n",
            "Image: 08de8df60.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:   4% 14/334 [00:02<00:50,  6.29it/s]Image: 08f9c685f.jpg | Classes present: tensor([0])\n",
            "Image: 092145f0c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 099e4e39a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0a4ad45a5.jpg | Classes present: tensor([0])\n",
            "Image: 09f1605ee.jpg | Classes present: tensor([0])\n",
            "Image: 0aa4399a4.jpg | Classes present: tensor([0])\n",
            "Image: 0a37f0a29.jpg | Classes present: tensor([0])\n",
            "Image: 0af6b34a8.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:   5% 16/334 [00:03<00:48,  6.49it/s]Image: 0b1993a49.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0b56da4ff.jpg | Classes present: tensor([0])\n",
            "Image: 0ce6ef153.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0bfcf7a71.jpg | Classes present: tensor([0])\n",
            "Image: 0db535c8c.jpg | Classes present: tensor([0])\n",
            "Image: 0dc953a31.jpg | Classes present: tensor([0])\n",
            "Image: 0c59df320.jpg | Classes present: tensor([0])\n",
            "Image: 0dd8c9f61.jpg | Classes present: tensor([0])\n",
            "Image: 0e71cd651.jpg | Classes present: tensor([0])\n",
            "Image: 0caf53aba.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:   5% 18/334 [00:03<00:49,  6.37it/s]Image: 0e71cd651.jpg | Classes present: tensor([0])\n",
            "Image: 0ddbc9fb5.jpg | Classes present: tensor([0, 3])\n",
            "Image: 0e86dea5b.jpg | Classes present: tensor([0])\n",
            "Image: 0eae06feb.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0e0d5004d.jpg | Classes present: tensor([0])\n",
            "Image: 0ff13bf69.jpg | Classes present: tensor([0])\n",
            "Image: 0e1925eb6.jpg | Classes present: tensor([0])\n",
            "Image: 1013a0b6e.jpg | Classes present: tensor([0])\n",
            "Image: 0e650e720.jpg | Classes present: tensor([0])\n",
            "Image: 101bc8aa5.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:   6% 20/334 [00:03<00:46,  6.82it/s]Image: 0eb09950a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 106fd7aad.jpg | Classes present: tensor([0])\n",
            "Image: 0ef465b25.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0f9f79a88.jpg | Classes present: tensor([0])\n",
            "Image: 11192bc94.jpg | Classes present: tensor([0])\n",
            "Image: 0fc3d194a.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:   7% 22/334 [00:03<00:42,  7.35it/s]Image: 11418b1c5.jpg | Classes present: tensor([0])\n",
            "Image: 1082cfe08.jpg | Classes present: tensor([0])\n",
            "Image: 1086196e1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 118b71091.jpg | Classes present: tensor([0])\n",
            "Image: 10d98c2be.jpg | Classes present: tensor([0, 2])\n",
            "Image: 11b37e4d7.jpg | Classes present: tensor([0])\n",
            "Image: 10d9f85be.jpg | Classes present: tensor([0])\n",
            "Image: 135fe211d.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:   7% 24/334 [00:04<00:38,  8.06it/s]Image: 11ff6a6f4.jpg | Classes present: tensor([0, 2])\n",
            "Image: 137b5546d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 124204a30.jpg | Classes present: tensor([0])\n",
            "Image: 1387583da.jpg | Classes present: tensor([0, 2])\n",
            "Image: 12d38a1d4.jpg | Classes present: tensor([0])\n",
            "Image: 140e212df.jpg | Classes present: tensor([0])\n",
            "Image: 12dd3899c.jpg | Classes present: tensor([0])\n",
            "Image: 1501f53a2.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:   8% 26/334 [00:04<00:40,  7.59it/s]Image: 1422b7da0.jpg | Classes present: tensor([0])\n",
            "Image: 153b56c43.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1561eb657.jpg | Classes present: tensor([0])\n",
            "Image: 1435cd970.jpg | Classes present: tensor([0])\n",
            "Image: 15796b4d5.jpg | Classes present: tensor([0])\n",
            "Image: 147ca5516.jpg | Classes present: tensor([0])\n",
            "Image: 163cc2750.jpg | Classes present: tensor([0, 3])\n",
            "Image: 14e4da366.jpg | Classes present: tensor([0])\n",
            "Image: 166818755.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:   8% 28/334 [00:04<00:52,  5.88it/s]Image: 159b43d49.jpg | Classes present: tensor([0])\n",
            "Image: 167d6930a.jpg | Classes present: tensor([0])\n",
            "Image: 15ce9e5cf.jpg | Classes present: tensor([0])\n",
            "Image: 16d0b11ff.jpg | Classes present: tensor([0])\n",
            "Image: 17e7cd5c6.jpg | Classes present: tensor([0, 2])\n",
            "Image: 15e8d5e3d.jpg | Classes present: tensor([0])\n",
            "Image: 161ca82bf.jpg | Classes present: tensor([0])\n",
            "Image: 17f611256.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:   9% 30/334 [00:05<01:00,  5.02it/s]Image: 16d0b11ff.jpg | Classes present: tensor([0])\n",
            "Image: 17f9f952a.jpg | Classes present: tensor([0])\n",
            "Image: 171c64a72.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1809bcad9.jpg | Classes present: tensor([0])\n",
            "Image: 172b72353.jpg | Classes present: tensor([0])\n",
            "Image: 192e256ba.jpg | Classes present: tensor([0])\n",
            "Image: 174af9fd6.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  10% 32/334 [00:05<01:02,  4.83it/s]Image: 195e36565.jpg | Classes present: tensor([0])\n",
            "Image: 180bb19f9.jpg | Classes present: tensor([0])\n",
            "Image: 196e624f5.jpg | Classes present: tensor([0])\n",
            "Image: 189659389.jpg | Classes present: tensor([0])\n",
            "Image: 198252b95.jpg | Classes present: tensor([0])\n",
            "Image: 18ace9a9a.jpg | Classes present: tensor([0, 3])\n",
            "Image: 18c14f720.jpg | Classes present: tensor([0])\n",
            "Image: 1a075e075.jpg | Classes present: tensor([0])\n",
            "Image: 1a4039711.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  10% 34/334 [00:06<01:12,  4.13it/s]Image: 19ab4c335.jpg | Classes present: tensor([0, 3])\n",
            "Image: 1a9c38991.jpg | Classes present: tensor([0])\n",
            "Image: 19ab4c335.jpg | Classes present: tensor([0, 3])\n",
            "Image: 1abb621ee.jpg | Classes present: tensor([0])\n",
            "Image: 19c645c25.jpg | Classes present: tensor([0])\n",
            "Image: 1b7e426bc.jpg | Classes present: tensor([0])\n",
            "Image: 19d892dd9.jpg | Classes present: tensor([0, 3])\n",
            "Image: 1b8ef5392.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  11% 36/334 [00:06<01:06,  4.47it/s]Image: 1b213d816.jpg | Classes present: tensor([0])\n",
            "Image: 1bc37a6f4.jpg | Classes present: tensor([0])\n",
            "Image: 1b2c029b8.jpg | Classes present: tensor([0])\n",
            "Image: 1bd394dd6.jpg | Classes present: tensor([0])\n",
            "Image: 1b4642fd5.jpg | Classes present: tensor([0])\n",
            "Image: 1cac6e1f3.jpg | Classes present: tensor([0])\n",
            "Image: 1b52ec552.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  11% 38/334 [00:07<01:05,  4.49it/s]Image: 1cac6e1f3.jpg | Classes present: tensor([0])\n",
            "Image: 1bdb7f26f.jpg | Classes present: tensor([0])\n",
            "Image: 1d28002da.jpg | Classes present: tensor([0])\n",
            "Image: 1be49cb6f.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1d56ccf70.jpg | Classes present: tensor([0])\n",
            "Image: 1c18acd30.jpg | Classes present: tensor([0])\n",
            "Image: 1e0980950.jpg | Classes present: tensor([0])\n",
            "Image: 1c97d1861.jpg | Classes present: tensor([0])\n",
            "Image: 1e7b96509.jpg | Classes present: tensor([0])\n",
            "Image: 1d71764d0.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  12% 40/334 [00:07<01:14,  3.95it/s]Image: 1e979fb66.jpg | Classes present: tensor([0])\n",
            "Image: 1d718ddb9.jpg | Classes present: tensor([0])\n",
            "Image: 1ea25d4fa.jpg | Classes present: tensor([0])\n",
            "Image: 1dd8107e9.jpg | Classes present: tensor([0])\n",
            "Image: 1fd098a38.jpg | Classes present: tensor([0])\n",
            "Image: 1e0220d5c.jpg | Classes present: tensor([0])\n",
            "Image: 1ff3214db.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  13% 42/334 [00:08<01:12,  4.05it/s]Image: 1ea40df0e.jpg | Classes present: tensor([0])\n",
            "Image: 2012a6d02.jpg | Classes present: tensor([0])\n",
            "Image: 1f3e0b337.jpg | Classes present: tensor([0])\n",
            "Image: 206c8bb0c.jpg | Classes present: tensor([0])\n",
            "Image: 1f8ea6702.jpg | Classes present: tensor([0])\n",
            "Image: 1fc4c5a4b.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  13% 44/334 [00:08<01:00,  4.78it/s]Image: 207e88d4a.jpg | Classes present: tensor([0])\n",
            "Image: 20964a4f0.jpg | Classes present: tensor([0, 3])\n",
            "Image: 207f33325.jpg | Classes present: tensor([0])\n",
            "Image: 20a894ca5.jpg | Classes present: tensor([0])\n",
            "Image: 208825e67.jpg | Classes present: tensor([0])\n",
            "Image: 2122b99c0.jpg | Classes present: tensor([0])\n",
            "Image: 214465021.jpg | Classes present: tensor([0])\n",
            "Image: 20964a4f0.jpg | Classes present: tensor([0, 3])\n",
            "Threshold Optimization:  14% 46/334 [00:08<00:53,  5.35it/s]Image: 2188f5429.jpg | Classes present: tensor([0])\n",
            "Image: 2222a03b3.jpg | Classes present: tensor([0])\n",
            "Image: 225ef7f0d.jpg | Classes present: tensor([0])\n",
            "Image: 21af0ec58.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2395db536.jpg | Classes present: tensor([0])\n",
            "Image: 21bf9d854.jpg | Classes present: tensor([0])\n",
            "Image: 23bb4d637.jpg | Classes present: tensor([0])\n",
            "Image: 22123f29f.jpg | Classes present: tensor([0])\n",
            "Image: 248220d45.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  14% 48/334 [00:09<00:53,  5.34it/s]Image: 23c450c03.jpg | Classes present: tensor([0])\n",
            "Image: 248585a26.jpg | Classes present: tensor([0, 3])\n",
            "Image: 23db57033.jpg | Classes present: tensor([0])\n",
            "Image: 248585a26.jpg | Classes present: tensor([0, 3])\n",
            "Image: 23e4a530a.jpg | Classes present: tensor([0])\n",
            "Image: 242894fc4.jpg | Classes present: tensor([0])\n",
            "Image: 2491d607d.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  15% 50/334 [00:09<00:47,  6.00it/s]Image: 2527831fa.jpg | Classes present: tensor([0])\n",
            "Image: 24a91d324.jpg | Classes present: tensor([0])\n",
            "Image: 24debd5d7.jpg | Classes present: tensor([0, 2])\n",
            "Image: 25515c2f6.jpg | Classes present: tensor([0])\n",
            "Image: 24e21e85a.jpg | Classes present: tensor([0])\n",
            "Image: 24e249331.jpg | Classes present: tensor([0])\n",
            "Image: 2558c43bf.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  16% 52/334 [00:09<00:40,  6.93it/s]Image: 2558c43bf.jpg | Classes present: tensor([0, 2])\n",
            "Image: 25c940a74.jpg | Classes present: tensor([0])\n",
            "Image: 268446e17.jpg | Classes present: tensor([0])\n",
            "Image: 25f9a8622.jpg | Classes present: tensor([0, 3])\n",
            "Image: 26f6f4c72.jpg | Classes present: tensor([0])\n",
            "Image: 270f5361d.jpg | Classes present: tensor([0])\n",
            "Image: 25fc987a1.jpg | Classes present: tensor([0])\n",
            "Image: 26272c2a7.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  16% 54/334 [00:10<00:40,  6.89it/s]Image: 27207fb2e.jpg | Classes present: tensor([0])\n",
            "Image: 275e3bca6.jpg | Classes present: tensor([0])\n",
            "Image: 282cd397d.jpg | Classes present: tensor([0])\n",
            "Image: 279af89c7.jpg | Classes present: tensor([0])\n",
            "Image: 282cd397d.jpg | Classes present: tensor([0])\n",
            "Image: 279b82aaf.jpg | Classes present: tensor([0])\n",
            "Image: 27faa1de7.jpg | Classes present: tensor([0, 2])\n",
            "Image: 29124169b.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  17% 56/334 [00:10<00:36,  7.66it/s]Image: 2930b4f52.jpg | Classes present: tensor([0])\n",
            "Image: 2912df978.jpg | Classes present: tensor([0])\n",
            "Image: 2930b4f52.jpg | Classes present: tensor([0])\n",
            "Image: 294d6d5f8.jpg | Classes present: tensor([0])\n",
            "Image: 29c39b183.jpg | Classes present: tensor([0])\n",
            "Image: 299d06031.jpg | Classes present: tensor([0])\n",
            "Image: 29c39b183.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  17% 58/334 [00:10<00:33,  8.29it/s]Image: 2a6669d9a.jpg | Classes present: tensor([0])\n",
            "Image: 29d83d9ce.jpg | Classes present: tensor([0])\n",
            "Image: 2a74520ed.jpg | Classes present: tensor([0])\n",
            "Image: 2a07798b5.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  18% 59/334 [00:10<00:35,  7.83it/s]Image: 2a95756e7.jpg | Classes present: tensor([0])\n",
            "Image: 2ae658a56.jpg | Classes present: tensor([0])\n",
            "Image: 2a9e93a87.jpg | Classes present: tensor([0])\n",
            "Image: 2b0055ed4.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  18% 60/334 [00:10<00:33,  8.10it/s]Image: 2b8dfbe0b.jpg | Classes present: tensor([0])\n",
            "Image: 2b15517b1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2bdb48c91.jpg | Classes present: tensor([0])\n",
            "Image: 2b449bdcf.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  18% 61/334 [00:10<00:34,  7.84it/s]Image: 2c56741a3.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2c7e26f0d.jpg | Classes present: tensor([0])\n",
            "Image: 2c63f60e3.jpg | Classes present: tensor([0])\n",
            "Image: 2d26b9dda.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  19% 62/334 [00:10<00:33,  8.02it/s]Image: 2d37a1ebe.jpg | Classes present: tensor([0])\n",
            "Image: 2e4fefc28.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2e55a1149.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2e4da1fd1.jpg | Classes present: tensor([0])\n",
            "Image: 2e84c0c34.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  19% 63/334 [00:11<00:36,  7.45it/s]Image: 2e8733afa.jpg | Classes present: tensor([0])\n",
            "Image: 2e8f2ddb8.jpg | Classes present: tensor([0])\n",
            "Image: 2e97e0251.jpg | Classes present: tensor([0])\n",
            "Image: 2eff528e8.jpg | Classes present: tensor([0])\n",
            "Image: 2ede3bc01.jpg | Classes present: tensor([0])\n",
            "Image: 2f5690028.jpg | Classes present: tensor([0])\n",
            "Image: 2ef5b3de1.jpg | Classes present: tensor([0])\n",
            "Image: 2f8cf11d3.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  19% 65/334 [00:11<00:36,  7.45it/s]Image: 2fa996a4c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2fa3a9f3e.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  20% 66/334 [00:11<00:35,  7.48it/s]Image: 2fe9f78c9.jpg | Classes present: tensor([0])\n",
            "Image: 2fbdc1244.jpg | Classes present: tensor([0])\n",
            "Image: 3071e65a5.jpg | Classes present: tensor([0])\n",
            "Image: 2fcfb108a.jpg | Classes present: tensor([0])\n",
            "Image: 30799f11c.jpg | Classes present: tensor([0])\n",
            "Image: 2fcfb108a.jpg | Classes present: tensor([0])\n",
            "Image: 308c978a7.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  20% 67/334 [00:11<00:52,  5.08it/s]Image: 30ba0b89a.jpg | Classes present: tensor([0])\n",
            "Image: 31262e8f9.jpg | Classes present: tensor([0])\n",
            "Image: 30c2d753f.jpg | Classes present: tensor([0, 2])\n",
            "Image: 31433d3b4.jpg | Classes present: tensor([0])\n",
            "Image: 30d00096d.jpg | Classes present: tensor([0])\n",
            "Image: 3159ee27a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3116edfe6.jpg | Classes present: tensor([0])\n",
            "Image: 316f0cc50.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  21% 69/334 [00:12<00:50,  5.28it/s]Image: 320557243.jpg | Classes present: tensor([0])\n",
            "Image: 31716f6ae.jpg | Classes present: tensor([0, 2])\n",
            "Image: 321975fb3.jpg | Classes present: tensor([0])\n",
            "Image: 31a43a534.jpg | Classes present: tensor([0, 2])\n",
            "Image: 32578d3e5.jpg | Classes present: tensor([0])\n",
            "Image: 31dee4189.jpg | Classes present: tensor([0])\n",
            "Image: 326d25e8c.jpg | Classes present: tensor([0])\n",
            "Image: 31eda6a87.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  21% 71/334 [00:12<00:48,  5.42it/s]Image: 335be17fa.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3294c9bd1.jpg | Classes present: tensor([0])\n",
            "Image: 33754aa9b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3294c9bd1.jpg | Classes present: tensor([0])\n",
            "Image: 3377332c0.jpg | Classes present: tensor([0, 2])\n",
            "Image: 32eca38d5.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3385f9e14.jpg | Classes present: tensor([0])\n",
            "Image: 33514c0b1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 34a5114d6.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  22% 73/334 [00:12<00:44,  5.85it/s]Image: 338d3b828.jpg | Classes present: tensor([0])\n",
            "Image: 34a5114d6.jpg | Classes present: tensor([0])\n",
            "Image: 338d3b828.jpg | Classes present: tensor([0])\n",
            "Image: 34ee04d85.jpg | Classes present: tensor([0])\n",
            "Image: 33a4b4335.jpg | Classes present: tensor([0])\n",
            "Image: 34f8faf6d.jpg | Classes present: tensor([0])\n",
            "Image: 345cf1dc3.jpg | Classes present: tensor([0])\n",
            "Image: 35d142883.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  22% 75/334 [00:13<00:45,  5.71it/s]Image: 35d142883.jpg | Classes present: tensor([0])\n",
            "Image: 3520eaa6d.jpg | Classes present: tensor([0])\n",
            "Image: 36789516a.jpg | Classes present: tensor([0])\n",
            "Image: 35271f898.jpg | Classes present: tensor([0])\n",
            "Image: 369ac4b0a.jpg | Classes present: tensor([0])\n",
            "Image: 373ebde8b.jpg | Classes present: tensor([0])\n",
            "Image: 374d9c63f.jpg | Classes present: tensor([0])\n",
            "Image: 353e60eef.jpg | Classes present: tensor([0, 2])\n",
            "Image: 37acd89d2.jpg | Classes present: tensor([0])\n",
            "Image: 35a8b85a8.jpg | Classes present: tensor([0])\n",
            "Image: 380e3ba93.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  23% 77/334 [00:13<00:49,  5.18it/s]Image: 36a804181.jpg | Classes present: tensor([0])\n",
            "Image: 3964357cd.jpg | Classes present: tensor([0, 3])\n",
            "Image: 36cd2cde0.jpg | Classes present: tensor([0, 2])\n",
            "Image: 39b8cb37a.jpg | Classes present: tensor([0])\n",
            "Image: 3704cdfd6.jpg | Classes present: tensor([0])\n",
            "Image: 39e365d3b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 373c6898f.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3a03385b5.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  24% 79/334 [00:14<00:52,  4.90it/s]Image: 38698fd76.jpg | Classes present: tensor([0])\n",
            "Image: 3af515180.jpg | Classes present: tensor([0])\n",
            "Image: 3888ec2cd.jpg | Classes present: tensor([0])\n",
            "Image: 3b3df8749.jpg | Classes present: tensor([0])\n",
            "Image: 38a63550b.jpg | Classes present: tensor([0])\n",
            "Image: 391b766d3.jpg | Classes present: tensor([0])\n",
            "Image: 3b6f87aed.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  24% 81/334 [00:14<00:51,  4.89it/s]Image: 3a4edbde9.jpg | Classes present: tensor([0])\n",
            "Image: 3a5246d98.jpg | Classes present: tensor([0])\n",
            "Image: 3cb1c14c8.jpg | Classes present: tensor([0])\n",
            "Image: 3a96940c6.jpg | Classes present: tensor([0])\n",
            "Image: 3e519e65d.jpg | Classes present: tensor([0])\n",
            "Image: 3ab1a7324.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  25% 83/334 [00:15<00:53,  4.68it/s]Image: 3da31ea30.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3e59e0f17.jpg | Classes present: tensor([0])\n",
            "Image: 3de8f5d88.jpg | Classes present: tensor([0])\n",
            "Image: 3f0b1c635.jpg | Classes present: tensor([0])\n",
            "Image: 3e185a3fe.jpg | Classes present: tensor([0])\n",
            "Image: 3f272083c.jpg | Classes present: tensor([0])\n",
            "Image: 3e1f5caa8.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  25% 85/334 [00:16<01:12,  3.42it/s]Image: 4029fea8e.jpg | Classes present: tensor([0])\n",
            "Image: 3f536622f.jpg | Classes present: tensor([0])\n",
            "Image: 40aae2e57.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3fb68881e.jpg | Classes present: tensor([0])\n",
            "Image: 3fdbbf305.jpg | Classes present: tensor([0])\n",
            "Image: 40b724998.jpg | Classes present: tensor([0, 2])\n",
            "Image: 401de199f.jpg | Classes present: tensor([0])\n",
            "Image: 40d766da8.jpg | Classes present: tensor([0, 3])\n",
            "Threshold Optimization:  26% 87/334 [00:16<01:06,  3.73it/s]Image: 41411378e.jpg | Classes present: tensor([0, 3])\n",
            "Image: 411377ca3.jpg | Classes present: tensor([0])\n",
            "Image: 415252307.jpg | Classes present: tensor([0])\n",
            "Image: 412fe7f70.jpg | Classes present: tensor([0])\n",
            "Image: 415dd1efd.jpg | Classes present: tensor([0])\n",
            "Image: 41333f13c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 41716714b.jpg | Classes present: tensor([0])\n",
            "Image: 41411378e.jpg | Classes present: tensor([0, 3])\n",
            "Image: 427085ef4.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  27% 89/334 [00:16<01:03,  3.87it/s]Image: 429650b38.jpg | Classes present: tensor([0])\n",
            "Image: 418e47222.jpg | Classes present: tensor([0])\n",
            "Image: 429951ca7.jpg | Classes present: tensor([0, 2])\n",
            "Image: 419dc2472.jpg | Classes present: tensor([0])\n",
            "Image: 4243c7476.jpg | Classes present: tensor([0])\n",
            "Image: 42af54b00.jpg | Classes present: tensor([0])\n",
            "Image: 42695cb60.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  27% 91/334 [00:17<00:56,  4.28it/s]Image: 42caf4e12.jpg | Classes present: tensor([0])\n",
            "Image: 4355ef39b.jpg | Classes present: tensor([0])\n",
            "Image: 42dd20db7.jpg | Classes present: tensor([0])\n",
            "Image: 436398e3b.jpg | Classes present: tensor([0])\n",
            "Image: 4340e1e42.jpg | Classes present: tensor([0, 2])\n",
            "Image: 436e3f4a0.jpg | Classes present: tensor([0])\n",
            "Image: 439f1a016.jpg | Classes present: tensor([0])\n",
            "Image: 4345c2b85.jpg | Classes present: tensor([0])\n",
            "Image: 441add89c.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  28% 93/334 [00:17<00:49,  4.82it/s]Image: 43b6618bf.jpg | Classes present: tensor([0])\n",
            "Image: 4422bc417.jpg | Classes present: tensor([0])\n",
            "Image: 43c6a30fa.jpg | Classes present: tensor([0])\n",
            "Image: 4422bc417.jpg | Classes present: tensor([0])\n",
            "Image: 43d7e6da0.jpg | Classes present: tensor([0])\n",
            "Image: 445dfb2ce.jpg | Classes present: tensor([0])\n",
            "Image: 44011d351.jpg | Classes present: tensor([0])\n",
            "Image: 44ada0c0b.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  28% 95/334 [00:17<00:50,  4.75it/s]Image: 446ba8f9b.jpg | Classes present: tensor([0])\n",
            "Image: 4529ee151.jpg | Classes present: tensor([0])\n",
            "Image: 446c4efb5.jpg | Classes present: tensor([0])\n",
            "Image: 45612bd46.jpg | Classes present: tensor([0])\n",
            "Image: 4499aaa80.jpg | Classes present: tensor([0])\n",
            "Image: 459790d82.jpg | Classes present: tensor([0])\n",
            "Image: 44a0d5b55.jpg | Classes present: tensor([0])\n",
            "Image: 4613bc12c.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  29% 97/334 [00:18<00:56,  4.19it/s]Image: 4613d520c.jpg | Classes present: tensor([0])\n",
            "Image: 459cd013a.jpg | Classes present: tensor([0])\n",
            "Image: 4695c2d2a.jpg | Classes present: tensor([0])\n",
            "Image: 45a4c0a58.jpg | Classes present: tensor([0])\n",
            "Image: 472407235.jpg | Classes present: tensor([0])\n",
            "Image: 45cca62e0.jpg | Classes present: tensor([0])\n",
            "Image: 483e4b5f7.jpg | Classes present: tensor([0])\n",
            "Image: 45d8e1473.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  30% 99/334 [00:19<01:10,  3.34it/s]Image: 484439824.jpg | Classes present: tensor([0])\n",
            "Image: 474c5f34e.jpg | Classes present: tensor([0, 2])\n",
            "Image: 48532e006.jpg | Classes present: tensor([0, 2])\n",
            "Image: 47a18bd61.jpg | Classes present: tensor([0])\n",
            "Image: 4854add54.jpg | Classes present: tensor([0])\n",
            "Image: 47c24f230.jpg | Classes present: tensor([0])\n",
            "Image: 47cee01b1.jpg | Classes present: tensor([0])\n",
            "Image: 48c466789.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  30% 101/334 [00:20<01:12,  3.20it/s]Image: 49c035d7e.jpg | Classes present: tensor([0])\n",
            "Image: 4857d0687.jpg | Classes present: tensor([0])\n",
            "Image: 49cf406c7.jpg | Classes present: tensor([0, 2])\n",
            "Image: 48626da29.jpg | Classes present: tensor([0])\n",
            "Image: 4a662783b.jpg | Classes present: tensor([0])\n",
            "Image: 48831ab9e.jpg | Classes present: tensor([0])\n",
            "Image: 4b762b230.jpg | Classes present: tensor([0])\n",
            "Image: 488922ac2.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  31% 103/334 [00:20<01:09,  3.33it/s]Image: 4b902c994.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4aca6c4a7.jpg | Classes present: tensor([0])\n",
            "Image: 4c12f034c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4b56df46d.jpg | Classes present: tensor([0])\n",
            "Image: 4c3100013.jpg | Classes present: tensor([0])\n",
            "Image: 4b56df46d.jpg | Classes present: tensor([0])\n",
            "Image: 4ca64717c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4b712bf89.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  31% 105/334 [00:21<01:14,  3.09it/s]Image: 4d1444a12.jpg | Classes present: tensor([0])\n",
            "Image: 4c770beb5.jpg | Classes present: tensor([0])\n",
            "Image: 4c770beb5.jpg | Classes present: tensor([0])\n",
            "Image: 4d1444a12.jpg | Classes present: tensor([0])\n",
            "Image: 4c7ff2056.jpg | Classes present: tensor([0])\n",
            "Image: 4d6973926.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4e1d262fb.jpg | Classes present: tensor([0])\n",
            "Image: 4c9245dcf.jpg | Classes present: tensor([0])\n",
            "Image: 4e25cb8e7.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  32% 107/334 [00:21<01:08,  3.30it/s]Image: 4dbadaa3e.jpg | Classes present: tensor([0])\n",
            "Image: 4e6514402.jpg | Classes present: tensor([0])\n",
            "Image: 4ec252808.jpg | Classes present: tensor([0, 3])\n",
            "Image: 4dbadaa3e.jpg | Classes present: tensor([0])\n",
            "Image: 4dd52fc23.jpg | Classes present: tensor([0, 3])\n",
            "Image: 4ef65d75b.jpg | Classes present: tensor([0])\n",
            "Image: 4fe777e50.jpg | Classes present: tensor([0])\n",
            "Image: 4dd52fc23.jpg | Classes present: tensor([0, 3])\n",
            "Threshold Optimization:  33% 109/334 [00:22<01:13,  3.04it/s]Image: 504e47cce.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4ecf05db6.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5064ecb6d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4ee32c458.jpg | Classes present: tensor([0])\n",
            "Image: 4eea878dd.jpg | Classes present: tensor([0])\n",
            "Image: 51632c4a4.jpg | Classes present: tensor([0])\n",
            "Image: 4ef21d9b7.jpg | Classes present: tensor([0])\n",
            "Image: 51b211df9.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  33% 111/334 [00:23<01:01,  3.60it/s]Image: 509abf323.jpg | Classes present: tensor([0])\n",
            "Image: 51d092947.jpg | Classes present: tensor([0])\n",
            "Image: 50bab4d98.jpg | Classes present: tensor([0, 2])\n",
            "Image: 50ff24e6e.jpg | Classes present: tensor([0])\n",
            "Image: 51d7bdfc2.jpg | Classes present: tensor([0, 2])\n",
            "Image: 51097aa45.jpg | Classes present: tensor([0])\n",
            "Image: 5283b3138.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  34% 113/334 [00:23<00:53,  4.14it/s]Image: 52faeb955.jpg | Classes present: tensor([0])\n",
            "Image: 53994e13b.jpg | Classes present: tensor([0])\n",
            "Image: 51d7bee0a.jpg | Classes present: tensor([0])\n",
            "Image: 53f2e3c44.jpg | Classes present: tensor([0])\n",
            "Image: 54fc1f606.jpg | Classes present: tensor([0])\n",
            "Image: 51f9ccdd2.jpg | Classes present: tensor([0])\n",
            "Image: 5545e4b0f.jpg | Classes present: tensor([0])\n",
            "Image: 522d34082.jpg | Classes present: tensor([0])\n",
            "Image: 5545e4b0f.jpg | Classes present: tensor([0])\n",
            "Image: 523fee62c.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  34% 115/334 [00:23<00:48,  4.54it/s]Image: 554710095.jpg | Classes present: tensor([0])\n",
            "Image: 54738099a.jpg | Classes present: tensor([0])\n",
            "Image: 56553f422.jpg | Classes present: tensor([0])\n",
            "Image: 549613483.jpg | Classes present: tensor([0])\n",
            "Image: 54bdb0ccf.jpg | Classes present: tensor([0])\n",
            "Image: 567578f1b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 567578f1b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 54c3ce6f0.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  35% 117/334 [00:24<00:44,  4.85it/s]Image: 554ee47b6.jpg | Classes present: tensor([0])\n",
            "Image: 567e1f981.jpg | Classes present: tensor([0])\n",
            "Image: 5562229c3.jpg | Classes present: tensor([0, 2])\n",
            "Image: 57a71495a.jpg | Classes present: tensor([0])\n",
            "Image: 559bcc411.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5810e2d40.jpg | Classes present: tensor([0, 2])\n",
            "Image: 55c30f544.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  36% 119/334 [00:24<00:39,  5.45it/s]Image: 582f0666f.jpg | Classes present: tensor([0])\n",
            "Image: 56cc8fb98.jpg | Classes present: tensor([0])\n",
            "Image: 585904c94.jpg | Classes present: tensor([0])\n",
            "Image: 5787b6262.jpg | Classes present: tensor([0, 2])\n",
            "Image: 59a2887fd.jpg | Classes present: tensor([0])\n",
            "Image: 579a51c1b.jpg | Classes present: tensor([0])\n",
            "Image: 57a71495a.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  36% 121/334 [00:24<00:34,  6.13it/s]Image: 59b20349b.jpg | Classes present: tensor([0])\n",
            "Image: 58f11e1cb.jpg | Classes present: tensor([0, 2])\n",
            "Image: 594e2b83f.jpg | Classes present: tensor([0])\n",
            "Image: 595373657.jpg | Classes present: tensor([0, 2])\n",
            "Image: 59bcf1693.jpg | Classes present: tensor([0])\n",
            "Image: 59a1733a9.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5a188bcf6.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  37% 123/334 [00:24<00:30,  6.96it/s]Image: 5b470a696.jpg | Classes present: tensor([0])\n",
            "Image: 5a8203514.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5ad654fc4.jpg | Classes present: tensor([0])\n",
            "Image: 5b5543800.jpg | Classes present: tensor([0])\n",
            "Image: 5adb00ee3.jpg | Classes present: tensor([0])\n",
            "Image: 5b5ad8482.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5b13aedd6.jpg | Classes present: tensor([0])\n",
            "Image: 5b615bff0.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  37% 125/334 [00:24<00:27,  7.52it/s]Image: 5c801ba0c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5b88d9e1a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5ca03f4fb.jpg | Classes present: tensor([0])\n",
            "Image: 5baeac055.jpg | Classes present: tensor([0])\n",
            "Image: 5ca2ccd75.jpg | Classes present: tensor([0])\n",
            "Image: 5c36982d0.jpg | Classes present: tensor([0])\n",
            "Image: 5cbfcc4dd.jpg | Classes present: tensor([0])\n",
            "Image: 5c3e81694.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  38% 127/334 [00:25<00:29,  7.10it/s]Image: 5e29012ca.jpg | Classes present: tensor([0])\n",
            "Image: 5cc07468d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5e570da14.jpg | Classes present: tensor([0])\n",
            "Image: 5e92f8e11.jpg | Classes present: tensor([0])\n",
            "Image: 5cf1cb974.jpg | Classes present: tensor([0])\n",
            "Image: 5cf4adf72.jpg | Classes present: tensor([0])\n",
            "Image: 5f121bfff.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5d3cbe1fe.jpg | Classes present: tensor([0])\n",
            "Image: 60bc48f6b.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  39% 129/334 [00:25<00:29,  6.85it/s]Image: 5fa81f2b5.jpg | Classes present: tensor([0])\n",
            "Image: 61204ded5.jpg | Classes present: tensor([0])\n",
            "Image: 604e200e1.jpg | Classes present: tensor([0])\n",
            "Image: 61835d07a.jpg | Classes present: tensor([0])\n",
            "Image: 6057916d4.jpg | Classes present: tensor([0])\n",
            "Image: 61f22bd01.jpg | Classes present: tensor([0])\n",
            "Image: 605ed0050.jpg | Classes present: tensor([0])\n",
            "Image: 6308e03ad.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  39% 131/334 [00:25<00:29,  6.87it/s]Image: 622086df1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 633701ae3.jpg | Classes present: tensor([0])\n",
            "Image: 636700b91.jpg | Classes present: tensor([0])\n",
            "Image: 624b76e5c.jpg | Classes present: tensor([0])\n",
            "Image: 636bad9bd.jpg | Classes present: tensor([0])\n",
            "Image: 6276bd13c.jpg | Classes present: tensor([0])\n",
            "Image: 62f84c877.jpg | Classes present: tensor([0, 2])\n",
            "Image: 63cf275e8.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  40% 133/334 [00:26<00:30,  6.66it/s]Image: 639c7495a.jpg | Classes present: tensor([0])\n",
            "Image: 642cfbe74.jpg | Classes present: tensor([0])\n",
            "Image: 63adb88f1.jpg | Classes present: tensor([0])\n",
            "Image: 6430ea237.jpg | Classes present: tensor([0])\n",
            "Image: 63c46a774.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6430ea237.jpg | Classes present: tensor([0])\n",
            "Image: 65bb052e9.jpg | Classes present: tensor([0, 2])\n",
            "Image: 63c46a774.jpg | Classes present: tensor([0, 2])\n",
            "Image: 66574a641.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  40% 135/334 [00:26<00:31,  6.41it/s]Image: 644f9c71d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 66849c8bd.jpg | Classes present: tensor([0])\n",
            "Image: 644f9c71d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 66ac60af4.jpg | Classes present: tensor([0])\n",
            "Image: 649890305.jpg | Classes present: tensor([0])\n",
            "Image: 67741aee6.jpg | Classes present: tensor([0])\n",
            "Image: 64b571a9a.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  41% 137/334 [00:26<00:30,  6.39it/s]Image: 677828765.jpg | Classes present: tensor([0])\n",
            "Image: 670dc6f72.jpg | Classes present: tensor([0, 3])\n",
            "Image: 67a5a06f1.jpg | Classes present: tensor([0])\n",
            "Image: 670dc6f72.jpg | Classes present: tensor([0, 3])\n",
            "Image: 67ffa0fc7.jpg | Classes present: tensor([0])\n",
            "Image: 6714ba056.jpg | Classes present: tensor([0])\n",
            "Image: 69365fabd.jpg | Classes present: tensor([0])\n",
            "Image: 6753759e0.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  42% 139/334 [00:27<00:28,  6.95it/s]Image: 69403726e.jpg | Classes present: tensor([0])\n",
            "Image: 6812ce51c.jpg | Classes present: tensor([0])\n",
            "Image: 68a931b71.jpg | Classes present: tensor([0, 2])\n",
            "Image: 695a460be.jpg | Classes present: tensor([0])\n",
            "Image: 68d3c7be2.jpg | Classes present: tensor([0])\n",
            "Image: 697427d70.jpg | Classes present: tensor([0])\n",
            "Image: 68ebc581e.jpg | Classes present: tensor([0])\n",
            "Image: 6a06e0328.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  42% 141/334 [00:27<00:30,  6.41it/s]Image: 6a567df0b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 69d546af3.jpg | Classes present: tensor([0])\n",
            "Image: 6a9ff4b0c.jpg | Classes present: tensor([0, 1])\n",
            "Image: 69d95aeea.jpg | Classes present: tensor([0])\n",
            "Image: 6abf76aad.jpg | Classes present: tensor([0])\n",
            "Image: 69df9d97b.jpg | Classes present: tensor([0])\n",
            "Image: 6b4d25284.jpg | Classes present: tensor([0])\n",
            "Image: 69f723ceb.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  43% 143/334 [00:27<00:29,  6.53it/s]Image: 6b634bbe9.jpg | Classes present: tensor([0])\n",
            "Image: 6ac1c730f.jpg | Classes present: tensor([0])\n",
            "Image: 6b7387486.jpg | Classes present: tensor([0])\n",
            "Image: 6b226dec1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6b7e04658.jpg | Classes present: tensor([0])\n",
            "Image: 6b3cdd9d1.jpg | Classes present: tensor([0])\n",
            "Image: 6c8b1519e.jpg | Classes present: tensor([0])\n",
            "Image: 6b3d02bce.jpg | Classes present: tensor([0])\n",
            "Image: 6ca387398.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  43% 145/334 [00:28<00:28,  6.69it/s]Image: 6caa89d4e.jpg | Classes present: tensor([0])\n",
            "Image: 6b9b11301.jpg | Classes present: tensor([0])\n",
            "Image: 6cad486d2.jpg | Classes present: tensor([0])\n",
            "Image: 6bc7c35cd.jpg | Classes present: tensor([0])\n",
            "Image: 6d8835463.jpg | Classes present: tensor([0])\n",
            "Image: 6c43d55eb.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6de495da5.jpg | Classes present: tensor([0])\n",
            "Image: 6c43d55eb.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6e18bef6b.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  44% 147/334 [00:28<00:27,  6.73it/s]Image: 6ce9bf7f7.jpg | Classes present: tensor([0])\n",
            "Image: 6e30e4696.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6ce9ef450.jpg | Classes present: tensor([0])\n",
            "Image: 6eb8690cd.jpg | Classes present: tensor([0])\n",
            "Image: 6ec88b7f7.jpg | Classes present: tensor([0])\n",
            "Image: 6d6280d5e.jpg | Classes present: tensor([0])\n",
            "Image: 6f0cd5095.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6f2357894.jpg | Classes present: tensor([0])\n",
            "Image: 6d8835463.jpg | Classes present: tensor([0])\n",
            "Image: 6e3f85bb9.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  45% 149/334 [00:28<00:27,  6.64it/s]Image: 7045c2a55.jpg | Classes present: tensor([0])\n",
            "Image: 6e4a7cca6.jpg | Classes present: tensor([0])\n",
            "Image: 7095dc41e.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6e6f1adb8.jpg | Classes present: tensor([0])\n",
            "Image: 70b0fb0cd.jpg | Classes present: tensor([0])\n",
            "Image: 70ce9b55b.jpg | Classes present: tensor([0])\n",
            "Image: 6e994b366.jpg | Classes present: tensor([0])\n",
            "Image: 6f490117c.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  45% 151/334 [00:28<00:25,  7.08it/s]Image: 722df0394.jpg | Classes present: tensor([0])\n",
            "Image: 6fabaf589.jpg | Classes present: tensor([0])\n",
            "Image: 72a7ff0db.jpg | Classes present: tensor([0])\n",
            "Image: 6fd1ed5aa.jpg | Classes present: tensor([0])\n",
            "Image: 72a7ff0db.jpg | Classes present: tensor([0])\n",
            "Image: 6ff11b744.jpg | Classes present: tensor([0])\n",
            "Image: 72b465391.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  46% 153/334 [00:29<00:24,  7.28it/s]Image: 713e97c97.jpg | Classes present: tensor([0])\n",
            "Image: 739a0aa20.jpg | Classes present: tensor([0, 1])\n",
            "Image: 714256911.jpg | Classes present: tensor([0])\n",
            "Image: 73a4c6d1f.jpg | Classes present: tensor([0])\n",
            "Image: 714256911.jpg | Classes present: tensor([0])\n",
            "Image: 73cdb1d89.jpg | Classes present: tensor([0])\n",
            "Image: 7149874c8.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  46% 155/334 [00:29<00:26,  6.87it/s]Image: 73d4dae19.jpg | Classes present: tensor([0])\n",
            "Image: 72bb7c7bc.jpg | Classes present: tensor([0])\n",
            "Image: 74ac88f43.jpg | Classes present: tensor([0])\n",
            "Image: 73472d296.jpg | Classes present: tensor([0])\n",
            "Image: 7365300fe.jpg | Classes present: tensor([0, 2])\n",
            "Image: 74bb2c5ff.jpg | Classes present: tensor([0])\n",
            "Image: 737ae5c95.jpg | Classes present: tensor([0])\n",
            "Image: 75361926d.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  47% 157/334 [00:29<00:25,  6.98it/s]Image: 73d4dae19.jpg | Classes present: tensor([0])\n",
            "Image: 763871334.jpg | Classes present: tensor([0])\n",
            "Image: 76c20b5af.jpg | Classes present: tensor([0])\n",
            "Image: 73e1969d4.jpg | Classes present: tensor([0])\n",
            "Image: 74048991c.jpg | Classes present: tensor([0])\n",
            "Image: 773948ca6.jpg | Classes present: tensor([0])\n",
            "Image: 74443f387.jpg | Classes present: tensor([0])\n",
            "Image: 7740cc61d.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  48% 159/334 [00:30<00:25,  6.95it/s]Image: 76a7e1815.jpg | Classes present: tensor([0])\n",
            "Image: 76adc6361.jpg | Classes present: tensor([0])\n",
            "Image: 778bde2b8.jpg | Classes present: tensor([0, 2])\n",
            "Image: 76b119e36.jpg | Classes present: tensor([0])\n",
            "Image: 7806aa75f.jpg | Classes present: tensor([0])\n",
            "Image: 78416c3d0.jpg | Classes present: tensor([0])\n",
            "Image: 76c165a4f.jpg | Classes present: tensor([0])\n",
            "Image: 7843767e9.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  48% 161/334 [00:30<00:23,  7.46it/s]Image: 77dc1cea6.jpg | Classes present: tensor([0])\n",
            "Image: 786faedc1.jpg | Classes present: tensor([0])\n",
            "Image: 79550304c.jpg | Classes present: tensor([0])\n",
            "Image: 77e5c398e.jpg | Classes present: tensor([0])\n",
            "Image: 795907727.jpg | Classes present: tensor([0])\n",
            "Image: 77e5c398e.jpg | Classes present: tensor([0])\n",
            "Image: 7970f0008.jpg | Classes present: tensor([0])\n",
            "Image: 77ed43ae9.jpg | Classes present: tensor([0])\n",
            "Image: 7970f0008.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  49% 163/334 [00:30<00:22,  7.48it/s]Image: 7a2908c51.jpg | Classes present: tensor([0])\n",
            "Image: 788a675e7.jpg | Classes present: tensor([0])\n",
            "Image: 7a5fae002.jpg | Classes present: tensor([0])\n",
            "Image: 78b5bc846.jpg | Classes present: tensor([0])\n",
            "Image: 7a92f8486.jpg | Classes present: tensor([0])\n",
            "Image: 78be7465f.jpg | Classes present: tensor([0])\n",
            "Image: 7abb5b1b7.jpg | Classes present: tensor([0])\n",
            "Image: 78d2258f2.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  49% 165/334 [00:30<00:23,  7.11it/s]Image: 7971e089f.jpg | Classes present: tensor([0])\n",
            "Image: 7ba0bbe30.jpg | Classes present: tensor([0])\n",
            "Image: 79bac6aca.jpg | Classes present: tensor([0])\n",
            "Image: 7bb3640ce.jpg | Classes present: tensor([0])\n",
            "Image: 79c106c42.jpg | Classes present: tensor([0])\n",
            "Image: 7bde96c82.jpg | Classes present: tensor([0])\n",
            "Image: 79dc6e410.jpg | Classes present: tensor([0])\n",
            "Image: 7c00478a3.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  50% 167/334 [00:31<00:23,  6.99it/s]Image: 7b4bcde18.jpg | Classes present: tensor([0])\n",
            "Image: 7de37a671.jpg | Classes present: tensor([0])\n",
            "Image: 7b4e8c0d9.jpg | Classes present: tensor([0])\n",
            "Image: 7e0e39e4c.jpg | Classes present: tensor([0])\n",
            "Image: 7b547b234.jpg | Classes present: tensor([0])\n",
            "Image: 7e57b31f7.jpg | Classes present: tensor([0])\n",
            "Image: 7b5dbe34d.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  51% 169/334 [00:31<00:25,  6.58it/s]Image: 7e6015fc5.jpg | Classes present: tensor([0])\n",
            "Image: 7c95cddba.jpg | Classes present: tensor([0])\n",
            "Image: 7cf7e0fa6.jpg | Classes present: tensor([0])\n",
            "Image: 7f777ba81.jpg | Classes present: tensor([0])\n",
            "Image: 7da7fdfca.jpg | Classes present: tensor([0, 2])\n",
            "Image: 7f8594d4b.jpg | Classes present: tensor([0])\n",
            "Image: 7dd4d0f90.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  51% 171/334 [00:31<00:23,  6.86it/s]Image: 7f8d10098.jpg | Classes present: tensor([0])\n",
            "Image: 7e9c7f52d.jpg | Classes present: tensor([0])\n",
            "Image: 7fc9cb824.jpg | Classes present: tensor([0, 2])\n",
            "Image: 7efadd1c6.jpg | Classes present: tensor([0])\n",
            "Image: 81ab8f502.jpg | Classes present: tensor([0])\n",
            "Image: 7f25edc7a.jpg | Classes present: tensor([0])\n",
            "Image: 7f4bbb940.jpg | Classes present: tensor([0])\n",
            "Image: 81b6f3cca.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  52% 173/334 [00:31<00:22,  7.25it/s]Image: 7fd3d58a5.jpg | Classes present: tensor([0])\n",
            "Image: 81b6f3cca.jpg | Classes present: tensor([0])\n",
            "Image: 801d299ac.jpg | Classes present: tensor([0, 2])\n",
            "Image: 81fa665da.jpg | Classes present: tensor([0, 2])\n",
            "Image: 810f96801.jpg | Classes present: tensor([0])\n",
            "Image: 846a8ccab.jpg | Classes present: tensor([0])\n",
            "Image: 817c6c7a8.jpg | Classes present: tensor([0, 2])\n",
            "Image: 847b7640a.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  52% 175/334 [00:32<00:24,  6.61it/s]Image: 8266cca81.jpg | Classes present: tensor([0, 2])\n",
            "Image: 848a1b795.jpg | Classes present: tensor([0, 2])\n",
            "Image: 85294cff9.jpg | Classes present: tensor([0])\n",
            "Image: 82e11b4e4.jpg | Classes present: tensor([0])\n",
            "Image: 82e32c810.jpg | Classes present: tensor([0])\n",
            "Image: 8600decb6.jpg | Classes present: tensor([0])\n",
            "Image: 8344ef24d.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  53% 177/334 [00:32<00:22,  6.84it/s]Image: 85294cff9.jpg | Classes present: tensor([0])\n",
            "Image: 8611deb61.jpg | Classes present: tensor([0])\n",
            "Image: 854baa70c.jpg | Classes present: tensor([0])\n",
            "Image: 862bcc9c0.jpg | Classes present: tensor([0])\n",
            "Image: 856f0b6bd.jpg | Classes present: tensor([0])\n",
            "Image: 863b300cb.jpg | Classes present: tensor([0])\n",
            "Image: 857400707.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  54% 179/334 [00:33<00:26,  5.96it/s]Image: 86cbb2d1f.jpg | Classes present: tensor([0])\n",
            "Image: 8645f73f1.jpg | Classes present: tensor([0])\n",
            "Image: 86e80375f.jpg | Classes present: tensor([0])\n",
            "Image: 8648b2010.jpg | Classes present: tensor([0])\n",
            "Image: 8709ea899.jpg | Classes present: tensor([0])\n",
            "Image: 865574894.jpg | Classes present: tensor([0])\n",
            "Image: 873e04ca8.jpg | Classes present: tensor([0])\n",
            "Image: 86aae8998.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  54% 181/334 [00:33<00:22,  6.73it/s]Image: 8847458a0.jpg | Classes present: tensor([0])\n",
            "Image: 87754d760.jpg | Classes present: tensor([0])\n",
            "Image: 886eebf8c.jpg | Classes present: tensor([0])\n",
            "Image: 87754d760.jpg | Classes present: tensor([0])\n",
            "Image: 87ae117e9.jpg | Classes present: tensor([0])\n",
            "Image: 8872fe6db.jpg | Classes present: tensor([0, 2])\n",
            "Image: 87f74731f.jpg | Classes present: tensor([0])\n",
            "Image: 88e1122cb.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  55% 183/334 [00:33<00:21,  6.87it/s]Image: 8a2a8a476.jpg | Classes present: tensor([0])\n",
            "Image: 8a87b9578.jpg | Classes present: tensor([0])\n",
            "Image: 8a35c59f9.jpg | Classes present: tensor([0])\n",
            "Image: 8a88f573c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8a485f766.jpg | Classes present: tensor([0])\n",
            "Image: 8a993359d.jpg | Classes present: tensor([0])\n",
            "Image: 8aa3af3da.jpg | Classes present: tensor([0])\n",
            "Image: 8a75d73d9.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  55% 185/334 [00:33<00:20,  7.20it/s]Image: 8afa2aa27.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8b9c035ec.jpg | Classes present: tensor([0])\n",
            "Image: 8b495e389.jpg | Classes present: tensor([0])\n",
            "Image: 8bab4626b.jpg | Classes present: tensor([0])\n",
            "Image: 8b4b4d618.jpg | Classes present: tensor([0])\n",
            "Image: 8bb208f36.jpg | Classes present: tensor([0])\n",
            "Image: 8b4e90080.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  56% 187/334 [00:34<00:20,  7.26it/s]Image: 8bb5ada5c.jpg | Classes present: tensor([0])\n",
            "Image: 8bdf6cee5.jpg | Classes present: tensor([0])\n",
            "Image: 8d36899b1.jpg | Classes present: tensor([0])\n",
            "Image: 8c732ade1.jpg | Classes present: tensor([0])\n",
            "Image: 8d4206f2a.jpg | Classes present: tensor([0])\n",
            "Image: 8cc65d1f7.jpg | Classes present: tensor([0])\n",
            "Image: 8d5dde91c.jpg | Classes present: tensor([0])\n",
            "Image: 8d5f90317.jpg | Classes present: tensor([0])\n",
            "Image: 8ceba5ea5.jpg | Classes present: tensor([0])\n",
            "Image: 8e6f1eb4f.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  57% 189/334 [00:34<00:20,  7.11it/s]Image: 8d67593de.jpg | Classes present: tensor([0])\n",
            "Image: 8e933231b.jpg | Classes present: tensor([0])\n",
            "Image: 8d938b3e7.jpg | Classes present: tensor([0])\n",
            "Image: 8ebc9cadc.jpg | Classes present: tensor([0])\n",
            "Image: 8d9b43515.jpg | Classes present: tensor([0])\n",
            "Image: 8ec0d428d.jpg | Classes present: tensor([0])\n",
            "Image: 8e1fb6f5a.jpg | Classes present: tensor([0])\n",
            "Image: 8f0dcad21.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  57% 191/334 [00:34<00:19,  7.18it/s]Image: 8ed31effd.jpg | Classes present: tensor([0])\n",
            "Image: 8f6b07e84.jpg | Classes present: tensor([0])\n",
            "Image: 8ed6b8054.jpg | Classes present: tensor([0, 1])\n",
            "Image: 8f8a23f39.jpg | Classes present: tensor([0])\n",
            "Image: 8f0a7e8af.jpg | Classes present: tensor([0])\n",
            "Image: 8fb4575f3.jpg | Classes present: tensor([0])\n",
            "Image: 8f0a7e8af.jpg | Classes present: tensor([0])\n",
            "Image: 90cd42d5b.jpg | Classes present: tensor([0])\n",
            "Image: 8fbd70ddf.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  58% 193/334 [00:34<00:19,  7.09it/s]Image: 910540b7d.jpg | Classes present: tensor([0])\n",
            "Image: 904584541.jpg | Classes present: tensor([0, 3])\n",
            "Image: 9121da7fe.jpg | Classes present: tensor([0])\n",
            "Image: 905964016.jpg | Classes present: tensor([0, 2])\n",
            "Image: 913e2221d.jpg | Classes present: tensor([0])\n",
            "Image: 9087518f1.jpg | Classes present: tensor([0])\n",
            "Image: 918c32419.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  58% 195/334 [00:35<00:19,  7.16it/s]Image: 9163ec76b.jpg | Classes present: tensor([0])\n",
            "Image: 92057aa8a.jpg | Classes present: tensor([0])\n",
            "Image: 9236f984c.jpg | Classes present: tensor([0])\n",
            "Image: 91696aaca.jpg | Classes present: tensor([0])\n",
            "Image: 9253b216e.jpg | Classes present: tensor([0, 2])\n",
            "Image: 91696aaca.jpg | Classes present: tensor([0])\n",
            "Image: 9341d848d.jpg | Classes present: tensor([0])\n",
            "Image: 9169b4f3a.jpg | Classes present: tensor([0])\n",
            "Image: 9378a6f12.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  59% 197/334 [00:35<00:18,  7.26it/s]Image: 930391b64.jpg | Classes present: tensor([0])\n",
            "Image: 9426ce32a.jpg | Classes present: tensor([0])\n",
            "Image: 930fe8fc7.jpg | Classes present: tensor([0])\n",
            "Image: 94753d945.jpg | Classes present: tensor([0])\n",
            "Image: 93126606c.jpg | Classes present: tensor([0])\n",
            "Image: 9557969ee.jpg | Classes present: tensor([0])\n",
            "Image: 933a9dc8b.jpg | Classes present: tensor([0])\n",
            "Image: 955feead2.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  60% 199/334 [00:35<00:18,  7.27it/s]Image: 94bf15000.jpg | Classes present: tensor([0, 3])\n",
            "Image: 95eaae02e.jpg | Classes present: tensor([0])\n",
            "Image: 96279bbc2.jpg | Classes present: tensor([0, 2])\n",
            "Image: 94c910b08.jpg | Classes present: tensor([0])\n",
            "Image: 967802d76.jpg | Classes present: tensor([0])\n",
            "Image: 954d4296b.jpg | Classes present: tensor([0])\n",
            "Image: 974f00b13.jpg | Classes present: tensor([0])\n",
            "Image: 9553974f4.jpg | Classes present: tensor([0])\n",
            "Image: 975b2e5fa.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  60% 201/334 [00:36<00:18,  7.19it/s]Image: 9789423c2.jpg | Classes present: tensor([0, 2])\n",
            "Image: 963b7a441.jpg | Classes present: tensor([0])\n",
            "Image: 98c0127d3.jpg | Classes present: tensor([0])\n",
            "Image: 963b7a441.jpg | Classes present: tensor([0])\n",
            "Image: 98c634937.jpg | Classes present: tensor([0])\n",
            "Image: 963f946a9.jpg | Classes present: tensor([0])\n",
            "Image: 991e0dfdf.jpg | Classes present: tensor([0])\n",
            "Image: 9663d6a79.jpg | Classes present: tensor([0])\n",
            "Image: 9962acd22.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  61% 203/334 [00:36<00:18,  6.96it/s]Image: 99d47e124.jpg | Classes present: tensor([0])\n",
            "Image: 97b77f9e6.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9a064450d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 97eb88e35.jpg | Classes present: tensor([0])\n",
            "Image: 9aa721852.jpg | Classes present: tensor([0])\n",
            "Image: 982193e49.jpg | Classes present: tensor([0, 3])\n",
            "Image: 982193e49.jpg | Classes present: tensor([0, 3])\n",
            "Image: 9aa721852.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  61% 205/334 [00:36<00:18,  6.98it/s]Image: 99855ae32.jpg | Classes present: tensor([0])\n",
            "Image: 9b72243dc.jpg | Classes present: tensor([0])\n",
            "Image: 99a9163bc.jpg | Classes present: tensor([0])\n",
            "Image: 9ba68fdaa.jpg | Classes present: tensor([0])\n",
            "Image: 99d359803.jpg | Classes present: tensor([0])\n",
            "Image: 9bc62ca61.jpg | Classes present: tensor([0])\n",
            "Image: 99d359803.jpg | Classes present: tensor([0])\n",
            "Image: 9bd5122c0.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  62% 207/334 [00:36<00:16,  7.53it/s]Image: 9ab57a2fa.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9c7a6cf21.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9ad1ad629.jpg | Classes present: tensor([0])\n",
            "Image: 9cfa7be25.jpg | Classes present: tensor([0])\n",
            "Image: 9af9dc45b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9d0b3a0f7.jpg | Classes present: tensor([0])\n",
            "Image: 9b09b2a38.jpg | Classes present: tensor([0])\n",
            "Image: 9d22ddbf2.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  63% 209/334 [00:36<00:14,  8.89it/s]Image: 9ead58088.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9c005a770.jpg | Classes present: tensor([0])\n",
            "Image: 9ec897b68.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9c1c7f69c.jpg | Classes present: tensor([0])\n",
            "Image: 9ed6f9c81.jpg | Classes present: tensor([0])\n",
            "Image: 9c42e727c.jpg | Classes present: tensor([0])\n",
            "Image: 9eed09712.jpg | Classes present: tensor([0])\n",
            "Image: 9c4ed4726.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  63% 211/334 [00:37<00:12,  9.87it/s]Image: 9d9020e1d.jpg | Classes present: tensor([0, 2])\n",
            "Image: a02fe46b6.jpg | Classes present: tensor([0])\n",
            "Image: 9dbb7b85c.jpg | Classes present: tensor([0])\n",
            "Image: a056c104a.jpg | Classes present: tensor([0])\n",
            "Image: 9e1f9aaaf.jpg | Classes present: tensor([0, 2])\n",
            "Image: a05708135.jpg | Classes present: tensor([0])\n",
            "Image: 9ea3ea37b.jpg | Classes present: tensor([0])\n",
            "Image: a0709a1e6.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  64% 213/334 [00:37<00:11, 10.75it/s]Image: 9eed09712.jpg | Classes present: tensor([0])\n",
            "Image: a13c52c08.jpg | Classes present: tensor([0])\n",
            "Image: 9ef683a79.jpg | Classes present: tensor([0])\n",
            "Image: a14e96726.jpg | Classes present: tensor([0])\n",
            "Image: 9fed72af4.jpg | Classes present: tensor([0])\n",
            "Image: a14eeb75d.jpg | Classes present: tensor([0, 2])\n",
            "Image: a0155346d.jpg | Classes present: tensor([0])\n",
            "Image: a152690b6.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  64% 215/334 [00:37<00:10, 11.76it/s]Image: a09a889b2.jpg | Classes present: tensor([0])\n",
            "Image: a1982cad5.jpg | Classes present: tensor([0])\n",
            "Image: a0de93374.jpg | Classes present: tensor([0])\n",
            "Image: a1bede9b1.jpg | Classes present: tensor([0, 2])\n",
            "Image: a1f5481df.jpg | Classes present: tensor([0])\n",
            "Image: a10c18895.jpg | Classes present: tensor([0])\n",
            "Image: a21bfa25a.jpg | Classes present: tensor([0])\n",
            "Image: a135808ff.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  65% 217/334 [00:37<00:10, 11.69it/s]Image: a152690b6.jpg | Classes present: tensor([0])\n",
            "Image: a2889c2fa.jpg | Classes present: tensor([0])\n",
            "Image: a154fdcfd.jpg | Classes present: tensor([0])\n",
            "Image: a2889c2fa.jpg | Classes present: tensor([0])\n",
            "Image: a187d1897.jpg | Classes present: tensor([0])\n",
            "Image: a28a7b7be.jpg | Classes present: tensor([0])\n",
            "Image: a18bdb241.jpg | Classes present: tensor([0])\n",
            "Image: a28a7b7be.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  66% 219/334 [00:37<00:09, 12.65it/s]Image: a21fa9b86.jpg | Classes present: tensor([0])\n",
            "Image: a33d86440.jpg | Classes present: tensor([0])\n",
            "Image: a22639daa.jpg | Classes present: tensor([0])\n",
            "Image: a37447f04.jpg | Classes present: tensor([0, 2])\n",
            "Image: a231b46ec.jpg | Classes present: tensor([0])\n",
            "Image: a37447f04.jpg | Classes present: tensor([0, 2])\n",
            "Image: a3d5e7319.jpg | Classes present: tensor([0])\n",
            "Image: a239718e1.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  66% 221/334 [00:37<00:09, 12.24it/s]Image: a2bdcd021.jpg | Classes present: tensor([0])\n",
            "Image: a4c93ac65.jpg | Classes present: tensor([0, 2])\n",
            "Image: a2e328f50.jpg | Classes present: tensor([0])\n",
            "Image: a4d9a97f6.jpg | Classes present: tensor([0])\n",
            "Image: a316898ca.jpg | Classes present: tensor([0])\n",
            "Image: a335fc5cc.jpg | Classes present: tensor([0])\n",
            "Image: a4d9a97f6.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  67% 223/334 [00:37<00:08, 13.40it/s]Image: a4dff615e.jpg | Classes present: tensor([0])\n",
            "Image: a471d7877.jpg | Classes present: tensor([0, 2])\n",
            "Image: a485b97e7.jpg | Classes present: tensor([0])\n",
            "Image: a56c8f958.jpg | Classes present: tensor([0])\n",
            "Image: a56df9123.jpg | Classes present: tensor([0])\n",
            "Image: a485d538c.jpg | Classes present: tensor([0])\n",
            "Image: a4a648cf6.jpg | Classes present: tensor([0, 3])\n",
            "Threshold Optimization:  67% 225/334 [00:38<00:08, 13.37it/s]Image: a5b23c751.jpg | Classes present: tensor([0, 2])\n",
            "Image: a5092043e.jpg | Classes present: tensor([0])\n",
            "Image: a5cb0256f.jpg | Classes present: tensor([0, 3])\n",
            "Image: a52f36666.jpg | Classes present: tensor([0])\n",
            "Image: a753532d6.jpg | Classes present: tensor([0, 2])\n",
            "Image: a559091c5.jpg | Classes present: tensor([0])\n",
            "Image: a753532d6.jpg | Classes present: tensor([0, 2])\n",
            "Image: a56c8f958.jpg | Classes present: tensor([0])\n",
            "Image: a7655a8d3.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  68% 227/334 [00:38<00:08, 13.20it/s]Image: a67df9196.jpg | Classes present: tensor([0])\n",
            "Image: a76b26d44.jpg | Classes present: tensor([0, 2])\n",
            "Image: a68dcc7d2.jpg | Classes present: tensor([0])\n",
            "Image: a9a5ac063.jpg | Classes present: tensor([0])\n",
            "Image: a6b00abd7.jpg | Classes present: tensor([0])\n",
            "Image: a9b1abf48.jpg | Classes present: tensor([0])\n",
            "Image: a6b3d554a.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  69% 229/334 [00:38<00:07, 13.73it/s]Image: a9c5e9f1e.jpg | Classes present: tensor([0, 2])\n",
            "Image: a7d5ae972.jpg | Classes present: tensor([0])\n",
            "Image: a9e2530ed.jpg | Classes present: tensor([0])\n",
            "Image: a835a0e50.jpg | Classes present: tensor([0])\n",
            "Image: aa9a7363b.jpg | Classes present: tensor([0])\n",
            "Image: a9378655a.jpg | Classes present: tensor([0])\n",
            "Image: aae6bc5be.jpg | Classes present: tensor([0, 2])\n",
            "Image: a94abfda7.jpg | Classes present: tensor([0, 2])\n",
            "Image: aaf12ddee.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  69% 231/334 [00:38<00:07, 13.54it/s]Image: a9f5f9806.jpg | Classes present: tensor([0])\n",
            "Image: ab13f368e.jpg | Classes present: tensor([0])\n",
            "Image: aa394081e.jpg | Classes present: tensor([0])\n",
            "Image: ab4fab99e.jpg | Classes present: tensor([0, 3])\n",
            "Image: aa4b29d91.jpg | Classes present: tensor([0])\n",
            "Image: ab6530468.jpg | Classes present: tensor([0])\n",
            "Image: aa7a0bcf3.jpg | Classes present: tensor([0])\n",
            "Image: ab70f8ba6.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  70% 233/334 [00:38<00:07, 13.77it/s]Image: ab16f0e09.jpg | Classes present: tensor([0])\n",
            "Image: abe8e7faf.jpg | Classes present: tensor([0])\n",
            "Image: ab1dda536.jpg | Classes present: tensor([0])\n",
            "Image: acd30bd6a.jpg | Classes present: tensor([0])\n",
            "Image: ab2300506.jpg | Classes present: tensor([0])\n",
            "Image: ad6506c7b.jpg | Classes present: tensor([0, 2])\n",
            "Image: ab2b3d3d9.jpg | Classes present: tensor([0])\n",
            "Image: ad6aed3f4.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  70% 235/334 [00:38<00:07, 13.36it/s]Image: ad6fb4fab.jpg | Classes present: tensor([0])\n",
            "Image: ac15719f1.jpg | Classes present: tensor([0, 2])\n",
            "Image: adff445fd.jpg | Classes present: tensor([0, 2])\n",
            "Image: ac461b596.jpg | Classes present: tensor([0])\n",
            "Image: ac504079d.jpg | Classes present: tensor([0])\n",
            "Image: ae4555b5b.jpg | Classes present: tensor([0])\n",
            "Image: aea51e93f.jpg | Classes present: tensor([0])\n",
            "Image: ac9c592aa.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  71% 237/334 [00:39<00:07, 12.93it/s]Image: ad9ad21f4.jpg | Classes present: tensor([0])\n",
            "Image: aeb34560d.jpg | Classes present: tensor([0])\n",
            "Image: add980018.jpg | Classes present: tensor([0, 2])\n",
            "Image: af4d2ee24.jpg | Classes present: tensor([0])\n",
            "Image: adf5fdfe2.jpg | Classes present: tensor([0])\n",
            "Image: af5c06a20.jpg | Classes present: tensor([0])\n",
            "Image: adf93f9bf.jpg | Classes present: tensor([0])\n",
            "Image: af7c08f36.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  72% 239/334 [00:39<00:07, 13.18it/s]Image: af7c08f36.jpg | Classes present: tensor([0])\n",
            "Image: aebbc40a6.jpg | Classes present: tensor([0, 2])\n",
            "Image: b0bd510db.jpg | Classes present: tensor([0])\n",
            "Image: aeda5b216.jpg | Classes present: tensor([0])\n",
            "Image: aee116071.jpg | Classes present: tensor([0])\n",
            "Image: b107bf5bd.jpg | Classes present: tensor([0])\n",
            "Image: b10ca1dc4.jpg | Classes present: tensor([0])\n",
            "Image: af4cdefaa.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  72% 241/334 [00:39<00:07, 13.23it/s]Image: b147f0f0f.jpg | Classes present: tensor([0])\n",
            "Image: af7db8470.jpg | Classes present: tensor([0])\n",
            "Image: b1c4d3872.jpg | Classes present: tensor([0])\n",
            "Image: afb854388.jpg | Classes present: tensor([0, 2])\n",
            "Image: b1d3f12b6.jpg | Classes present: tensor([0])\n",
            "Image: afd3f856d.jpg | Classes present: tensor([0])\n",
            "Image: b04b907b2.jpg | Classes present: tensor([0, 2])\n",
            "Image: b1d3f12b6.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  73% 243/334 [00:39<00:06, 13.34it/s]Image: b1f5ce725.jpg | Classes present: tensor([0])\n",
            "Image: b162a9cb2.jpg | Classes present: tensor([0])\n",
            "Image: b1639af61.jpg | Classes present: tensor([0])\n",
            "Image: b2cbd553f.jpg | Classes present: tensor([0])\n",
            "Image: b17fcb164.jpg | Classes present: tensor([0, 2])\n",
            "Image: b2e59bdaa.jpg | Classes present: tensor([0])\n",
            "Image: b1bbea81b.jpg | Classes present: tensor([0])\n",
            "Image: b37a57736.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  73% 245/334 [00:39<00:06, 13.19it/s]Image: b3920826e.jpg | Classes present: tensor([0])\n",
            "Image: b20fb15ff.jpg | Classes present: tensor([0])\n",
            "Image: b442ff31d.jpg | Classes present: tensor([0])\n",
            "Image: b23e854e8.jpg | Classes present: tensor([0])\n",
            "Image: b2854eaff.jpg | Classes present: tensor([0])\n",
            "Image: b44cfa5ba.jpg | Classes present: tensor([0])\n",
            "Image: b2c9fde17.jpg | Classes present: tensor([0])\n",
            "Image: b46dafae2.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  74% 247/334 [00:39<00:06, 13.24it/s]Image: b3b8f0c9e.jpg | Classes present: tensor([0, 2])\n",
            "Image: b4cc6a4ed.jpg | Classes present: tensor([0])\n",
            "Image: b3f7ae992.jpg | Classes present: tensor([0])\n",
            "Image: b5b48f9f3.jpg | Classes present: tensor([0])\n",
            "Image: b40abdab2.jpg | Classes present: tensor([0])\n",
            "Image: b5b99c878.jpg | Classes present: tensor([0, 2])\n",
            "Image: b41747a10.jpg | Classes present: tensor([0, 2])\n",
            "Image: b5b99c878.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  75% 249/334 [00:39<00:06, 13.28it/s]Image: b54038841.jpg | Classes present: tensor([0])\n",
            "Image: b5cda37bc.jpg | Classes present: tensor([0])\n",
            "Image: b56de2940.jpg | Classes present: tensor([0])\n",
            "Image: b68c95b87.jpg | Classes present: tensor([0])\n",
            "Image: b5804f43f.jpg | Classes present: tensor([0, 2])\n",
            "Image: b69aaf096.jpg | Classes present: tensor([0])\n",
            "Image: b58132808.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  75% 251/334 [00:40<00:06, 13.20it/s]Image: b6b66ca8c.jpg | Classes present: tensor([0, 2])\n",
            "Image: b64b9969e.jpg | Classes present: tensor([0, 2])\n",
            "Image: b6f61c6b0.jpg | Classes present: tensor([0])\n",
            "Image: b64b9969e.jpg | Classes present: tensor([0, 2])\n",
            "Image: b733d1672.jpg | Classes present: tensor([0])\n",
            "Image: b64f0985f.jpg | Classes present: tensor([0])\n",
            "Image: b799d56cd.jpg | Classes present: tensor([0])\n",
            "Image: b66721b1f.jpg | Classes present: tensor([0])\n",
            "Image: b7a1d89ae.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  76% 253/334 [00:40<00:06, 13.32it/s]Image: b7b6fd4ed.jpg | Classes present: tensor([0])\n",
            "Image: b6fc52f4e.jpg | Classes present: tensor([0])\n",
            "Image: b933f4591.jpg | Classes present: tensor([0])\n",
            "Image: b71ee7bd0.jpg | Classes present: tensor([0, 3])\n",
            "Image: b93f5fdc0.jpg | Classes present: tensor([0, 2])\n",
            "Image: b72d341bf.jpg | Classes present: tensor([0])\n",
            "Image: b941eeaa7.jpg | Classes present: tensor([0, 2])\n",
            "Image: b733d1672.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  76% 255/334 [00:40<00:05, 13.18it/s]Image: b9752d783.jpg | Classes present: tensor([0])\n",
            "Image: b87571cc4.jpg | Classes present: tensor([0])\n",
            "Image: ba4284649.jpg | Classes present: tensor([0])\n",
            "Image: b8b03dcfe.jpg | Classes present: tensor([0, 2])\n",
            "Image: ba4ac3636.jpg | Classes present: tensor([0])\n",
            "Image: b8ba151b1.jpg | Classes present: tensor([0, 2])\n",
            "Image: ba4ac3636.jpg | Classes present: tensor([0])\n",
            "Image: b925ef3b7.jpg | Classes present: tensor([0])\n",
            "Image: bab5271b6.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  77% 257/334 [00:40<00:06, 12.66it/s]Image: b99b4abea.jpg | Classes present: tensor([0])\n",
            "Image: bb2975da4.jpg | Classes present: tensor([0])\n",
            "Image: bb3421ee8.jpg | Classes present: tensor([0])\n",
            "Image: b99b4abea.jpg | Classes present: tensor([0])\n",
            "Image: bb371f33d.jpg | Classes present: tensor([0, 2])\n",
            "Image: b9b5cb6f5.jpg | Classes present: tensor([0])\n",
            "Image: bb4e89121.jpg | Classes present: tensor([0])\n",
            "Image: b9fa8b135.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  78% 259/334 [00:40<00:05, 12.55it/s]Image: bab5271b6.jpg | Classes present: tensor([0])\n",
            "Image: bc72a7548.jpg | Classes present: tensor([0])\n",
            "Image: bac68f2c3.jpg | Classes present: tensor([0, 2])\n",
            "Image: bc751c15d.jpg | Classes present: tensor([0])\n",
            "Image: bacb738d3.jpg | Classes present: tensor([0])\n",
            "Image: bc7ce8f4d.jpg | Classes present: tensor([0])\n",
            "Image: badc586ae.jpg | Classes present: tensor([0])\n",
            "Image: bcb794eed.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  78% 261/334 [00:40<00:05, 12.87it/s]Image: bbb96273d.jpg | Classes present: tensor([0])\n",
            "Image: bea7ff137.jpg | Classes present: tensor([0])\n",
            "Image: bbec1ee47.jpg | Classes present: tensor([0])\n",
            "Image: bf3db21e9.jpg | Classes present: tensor([0])\n",
            "Image: bbfdbc490.jpg | Classes present: tensor([0])\n",
            "Image: bfa17327e.jpg | Classes present: tensor([0])\n",
            "Image: bc0a90164.jpg | Classes present: tensor([0, 3])\n",
            "Image: bfa249587.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  79% 263/334 [00:41<00:05, 12.37it/s]Image: c038c0588.jpg | Classes present: tensor([0])\n",
            "Image: bd0e26062.jpg | Classes present: tensor([0])\n",
            "Image: c04b0d160.jpg | Classes present: tensor([0])\n",
            "Image: bdbf5535f.jpg | Classes present: tensor([0])\n",
            "Image: c0e34b64b.jpg | Classes present: tensor([0])\n",
            "Image: bdce84e23.jpg | Classes present: tensor([0])\n",
            "Image: c12bbdec9.jpg | Classes present: tensor([0])\n",
            "Image: be65d7bb7.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  79% 265/334 [00:41<00:05, 12.86it/s]Image: bfd24be30.jpg | Classes present: tensor([0, 2])\n",
            "Image: c2760fc1a.jpg | Classes present: tensor([0, 3])\n",
            "Image: bfd24be30.jpg | Classes present: tensor([0, 2])\n",
            "Image: c27ce861d.jpg | Classes present: tensor([0])\n",
            "Image: bfd56c3d2.jpg | Classes present: tensor([0])\n",
            "Image: c2b446019.jpg | Classes present: tensor([0])\n",
            "Image: c01fd972f.jpg | Classes present: tensor([0])\n",
            "Image: c30805f9e.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  80% 267/334 [00:41<00:05, 13.21it/s]Image: c232eea0c.jpg | Classes present: tensor([0])\n",
            "Image: c34fc79b6.jpg | Classes present: tensor([0])\n",
            "Image: c24caa9be.jpg | Classes present: tensor([0])\n",
            "Image: c37633c03.jpg | Classes present: tensor([0])\n",
            "Image: c25e12747.jpg | Classes present: tensor([0])\n",
            "Image: c3c091454.jpg | Classes present: tensor([0, 3])\n",
            "Image: c2760fc1a.jpg | Classes present: tensor([0, 3])\n",
            "Image: c3cae8972.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  81% 269/334 [00:41<00:04, 13.85it/s]Image: c319a0d11.jpg | Classes present: tensor([0, 2])\n",
            "Image: c495e234e.jpg | Classes present: tensor([0])\n",
            "Image: c319a0d11.jpg | Classes present: tensor([0, 2])\n",
            "Image: c4aeca424.jpg | Classes present: tensor([0])\n",
            "Image: c34f14586.jpg | Classes present: tensor([0])\n",
            "Image: c4dc92ef9.jpg | Classes present: tensor([0])\n",
            "Image: c34f14586.jpg | Classes present: tensor([0])\n",
            "Image: c4dc92ef9.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  81% 271/334 [00:41<00:04, 13.41it/s]Image: c5af9872c.jpg | Classes present: tensor([0])\n",
            "Image: c3ff6937c.jpg | Classes present: tensor([0])\n",
            "Image: c5b08d4e3.jpg | Classes present: tensor([0])\n",
            "Image: c40a05198.jpg | Classes present: tensor([0])\n",
            "Image: c5b08d4e3.jpg | Classes present: tensor([0])\n",
            "Image: c44c93192.jpg | Classes present: tensor([0])\n",
            "Image: c5da9e8c7.jpg | Classes present: tensor([0])\n",
            "Image: c46065903.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  82% 273/334 [00:41<00:04, 12.79it/s]Image: c4f5ebbb2.jpg | Classes present: tensor([0])\n",
            "Image: c6afe1599.jpg | Classes present: tensor([0])\n",
            "Image: c53423923.jpg | Classes present: tensor([0, 2])\n",
            "Image: c6d3371a8.jpg | Classes present: tensor([0])\n",
            "Image: c54db71af.jpg | Classes present: tensor([0, 3])\n",
            "Image: c746f473d.jpg | Classes present: tensor([0, 2])\n",
            "Image: c5a41d53c.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  82% 275/334 [00:41<00:04, 13.21it/s]Image: c74abe00a.jpg | Classes present: tensor([0])\n",
            "Image: c5e69fd8f.jpg | Classes present: tensor([0])\n",
            "Image: c7f93d8bd.jpg | Classes present: tensor([0])\n",
            "Image: c5fa2923b.jpg | Classes present: tensor([0])\n",
            "Image: c7fb9db8c.jpg | Classes present: tensor([0])\n",
            "Image: c63e60886.jpg | Classes present: tensor([0])\n",
            "Image: c8216657a.jpg | Classes present: tensor([0])\n",
            "Image: c63e60886.jpg | Classes present: tensor([0])\n",
            "Image: c85251430.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  83% 277/334 [00:42<00:04, 13.36it/s]Image: c795455ba.jpg | Classes present: tensor([0])\n",
            "Image: c94bd179c.jpg | Classes present: tensor([0])\n",
            "Image: c94f78afa.jpg | Classes present: tensor([0])\n",
            "Image: c7aeb9c82.jpg | Classes present: tensor([0, 3])\n",
            "Image: c9ae4cb29.jpg | Classes present: tensor([0, 2])\n",
            "Image: c7aeb9c82.jpg | Classes present: tensor([0, 3])\n",
            "Image: c9ae4cb29.jpg | Classes present: tensor([0, 2])\n",
            "Image: c7d002c29.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  84% 279/334 [00:42<00:04, 13.11it/s]Image: c89e96115.jpg | Classes present: tensor([0])\n",
            "Image: ca9d7749b.jpg | Classes present: tensor([0])\n",
            "Image: c8c0e5b9d.jpg | Classes present: tensor([0])\n",
            "Image: cac001c04.jpg | Classes present: tensor([0])\n",
            "Image: c8ed5e8ab.jpg | Classes present: tensor([0, 2])\n",
            "Image: cb094c2cb.jpg | Classes present: tensor([0])\n",
            "Image: c916658f1.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  84% 281/334 [00:42<00:03, 13.40it/s]Image: cb37fc190.jpg | Classes present: tensor([0])\n",
            "Image: c9cd221c5.jpg | Classes present: tensor([0])\n",
            "Image: cbd27127f.jpg | Classes present: tensor([0])\n",
            "Image: c9d24ef83.jpg | Classes present: tensor([0])\n",
            "Image: cc0bf97cf.jpg | Classes present: tensor([0])\n",
            "Image: ca492d6f1.jpg | Classes present: tensor([0])\n",
            "Image: cc3b99f17.jpg | Classes present: tensor([0])\n",
            "Image: ca82d646f.jpg | Classes present: tensor([0])\n",
            "Image: cc5bae861.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  85% 283/334 [00:42<00:03, 13.35it/s]Image: cb383b2f7.jpg | Classes present: tensor([0])\n",
            "Image: cd0c2417f.jpg | Classes present: tensor([0])\n",
            "Image: cb43d7be5.jpg | Classes present: tensor([0])\n",
            "Image: cd14c73db.jpg | Classes present: tensor([0])\n",
            "Image: cd14c73db.jpg | Classes present: tensor([0])\n",
            "Image: cb53b96ce.jpg | Classes present: tensor([0])\n",
            "Image: cd23d4841.jpg | Classes present: tensor([0])\n",
            "Image: cb9fe5699.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  85% 285/334 [00:42<00:03, 13.07it/s]Image: ccbd751f2.jpg | Classes present: tensor([0])\n",
            "Image: ccd94dc85.jpg | Classes present: tensor([0])\n",
            "Image: ce11ffd78.jpg | Classes present: tensor([0])\n",
            "Image: ccf39a604.jpg | Classes present: tensor([0])\n",
            "Image: ce43bdd06.jpg | Classes present: tensor([0, 2])\n",
            "Image: cd04164a0.jpg | Classes present: tensor([0])\n",
            "Image: ce7b7ac0b.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  86% 287/334 [00:42<00:03, 14.14it/s]Image: cea2ea962.jpg | Classes present: tensor([0])\n",
            "Image: cd465dc7d.jpg | Classes present: tensor([0])\n",
            "Image: cef5ff47d.jpg | Classes present: tensor([0])\n",
            "Image: cd475d2a3.jpg | Classes present: tensor([0, 2])\n",
            "Image: cf0641053.jpg | Classes present: tensor([0])\n",
            "Image: ce02c322e.jpg | Classes present: tensor([0])\n",
            "Image: cf0641053.jpg | Classes present: tensor([0])\n",
            "Image: ce05c2c3f.jpg | Classes present: tensor([0])\n",
            "Image: cf1f3345c.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  87% 289/334 [00:42<00:03, 13.21it/s]Image: d02f1b229.jpg | Classes present: tensor([0])\n",
            "Image: ceba9dc16.jpg | Classes present: tensor([0])\n",
            "Image: d04e02d1f.jpg | Classes present: tensor([0])\n",
            "Image: ceba9dc16.jpg | Classes present: tensor([0])\n",
            "Image: d0578ca87.jpg | Classes present: tensor([0])\n",
            "Image: ced4439da.jpg | Classes present: tensor([0])\n",
            "Image: d0befd683.jpg | Classes present: tensor([0])\n",
            "Image: cede14189.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  87% 291/334 [00:43<00:03, 13.24it/s]Image: cf5231a23.jpg | Classes present: tensor([0])\n",
            "Image: d1886af80.jpg | Classes present: tensor([0])\n",
            "Image: cf8e21964.jpg | Classes present: tensor([0])\n",
            "Image: d1e1bf13e.jpg | Classes present: tensor([0])\n",
            "Image: cff387e60.jpg | Classes present: tensor([0])\n",
            "Image: d1ed49385.jpg | Classes present: tensor([0])\n",
            "Image: d000d7ef5.jpg | Classes present: tensor([0])\n",
            "Image: d2291de5c.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  88% 293/334 [00:43<00:03, 13.60it/s]Image: d25356a51.jpg | Classes present: tensor([0])\n",
            "Image: d1023fa39.jpg | Classes present: tensor([0, 2])\n",
            "Image: d2670190d.jpg | Classes present: tensor([0])\n",
            "Image: d11130898.jpg | Classes present: tensor([0])\n",
            "Image: d283f3744.jpg | Classes present: tensor([0])\n",
            "Image: d129fe51e.jpg | Classes present: tensor([0])\n",
            "Image: d2a854e69.jpg | Classes present: tensor([0])\n",
            "Image: d169e1b81.jpg | Classes present: tensor([0, 3])\n",
            "Threshold Optimization:  88% 295/334 [00:43<00:02, 13.38it/s]Image: d2291de5c.jpg | Classes present: tensor([0])\n",
            "Image: d4387afd3.jpg | Classes present: tensor([0])\n",
            "Image: d239a83c4.jpg | Classes present: tensor([0])\n",
            "Image: d46866225.jpg | Classes present: tensor([0])\n",
            "Image: d2454fd68.jpg | Classes present: tensor([0])\n",
            "Image: d4af6d206.jpg | Classes present: tensor([0])\n",
            "Image: d245c4e7f.jpg | Classes present: tensor([0])\n",
            "Image: d52b35e0e.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  89% 297/334 [00:43<00:02, 13.74it/s]Image: d2bbde0a4.jpg | Classes present: tensor([0, 2])\n",
            "Image: d5bdfa378.jpg | Classes present: tensor([0])\n",
            "Image: d31e0200c.jpg | Classes present: tensor([0])\n",
            "Image: d5f7cde8a.jpg | Classes present: tensor([0, 2])\n",
            "Image: d37c88411.jpg | Classes present: tensor([0])\n",
            "Image: d60ae28dc.jpg | Classes present: tensor([0])\n",
            "Image: d3d6d9b6a.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  90% 299/334 [00:43<00:02, 13.42it/s]Image: d66e4eb3f.jpg | Classes present: tensor([0, 2])\n",
            "Image: d5353adfc.jpg | Classes present: tensor([0, 2])\n",
            "Image: d6ff87222.jpg | Classes present: tensor([0, 3])\n",
            "Image: d535c41bf.jpg | Classes present: tensor([0])\n",
            "Image: d70e75dca.jpg | Classes present: tensor([0])\n",
            "Image: d57629343.jpg | Classes present: tensor([0])\n",
            "Image: d7221e8ce.jpg | Classes present: tensor([0])\n",
            "Image: d59b4476a.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  90% 301/334 [00:43<00:02, 13.50it/s]Image: d7686d307.jpg | Classes present: tensor([0])\n",
            "Image: d6777d642.jpg | Classes present: tensor([0, 3])\n",
            "Image: d7e3d3784.jpg | Classes present: tensor([0])\n",
            "Image: d6d71b8ec.jpg | Classes present: tensor([0, 2])\n",
            "Image: d7e693160.jpg | Classes present: tensor([0, 3])\n",
            "Image: d6ef360e3.jpg | Classes present: tensor([0, 3])\n",
            "Image: d81eb8a93.jpg | Classes present: tensor([0, 2])\n",
            "Image: d6ef360e3.jpg | Classes present: tensor([0, 3])\n",
            "Image: d849d7a48.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  91% 303/334 [00:44<00:02, 12.74it/s]Image: d77e9ff45.jpg | Classes present: tensor([0])\n",
            "Image: d78e97810.jpg | Classes present: tensor([0])\n",
            "Image: d9bfea1ea.jpg | Classes present: tensor([0, 2])\n",
            "Image: d7a43c6f6.jpg | Classes present: tensor([0, 2])\n",
            "Image: da20fe743.jpg | Classes present: tensor([0])\n",
            "Image: d7ae2c9be.jpg | Classes present: tensor([0])\n",
            "Image: da6fb7dc1.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  91% 305/334 [00:44<00:02, 13.21it/s]Image: d860da430.jpg | Classes present: tensor([0])\n",
            "Image: dac8bf38a.jpg | Classes present: tensor([0])\n",
            "Image: d8d851749.jpg | Classes present: tensor([0])\n",
            "Image: db3d85bc9.jpg | Classes present: tensor([0])\n",
            "Image: d8e21a2ae.jpg | Classes present: tensor([0])\n",
            "Image: db5aabcb0.jpg | Classes present: tensor([0, 2])\n",
            "Image: d96baa2ce.jpg | Classes present: tensor([0, 2])\n",
            "Image: db62a970a.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  92% 307/334 [00:44<00:02, 13.30it/s]Image: db6b86601.jpg | Classes present: tensor([0])\n",
            "Image: daeea39b1.jpg | Classes present: tensor([0, 2])\n",
            "Image: dd2c992b2.jpg | Classes present: tensor([0])\n",
            "Image: db0547371.jpg | Classes present: tensor([0])\n",
            "Image: dd441d6a0.jpg | Classes present: tensor([0])\n",
            "Image: db064ce4a.jpg | Classes present: tensor([0])\n",
            "Image: dd441d6a0.jpg | Classes present: tensor([0])\n",
            "Image: db17f3e99.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  93% 309/334 [00:44<00:01, 13.55it/s]Image: dd8af6471.jpg | Classes present: tensor([0])\n",
            "Image: dc46bd374.jpg | Classes present: tensor([0, 2])\n",
            "Image: de85c63cb.jpg | Classes present: tensor([0])\n",
            "Image: dc499be11.jpg | Classes present: tensor([0])\n",
            "Image: de85c63cb.jpg | Classes present: tensor([0])\n",
            "Image: dc58fa33b.jpg | Classes present: tensor([0])\n",
            "Image: de9ce7271.jpg | Classes present: tensor([0])\n",
            "Image: dc636ab48.jpg | Classes present: tensor([0])\n",
            "Image: dea277f4a.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  93% 311/334 [00:44<00:01, 13.51it/s]Image: dd97d4b45.jpg | Classes present: tensor([0])\n",
            "Image: df656b199.jpg | Classes present: tensor([0])\n",
            "Image: ddf1692c2.jpg | Classes present: tensor([0])\n",
            "Image: df70a7e07.jpg | Classes present: tensor([0])\n",
            "Image: de1983d54.jpg | Classes present: tensor([0, 2])\n",
            "Image: de5a08726.jpg | Classes present: tensor([0])\n",
            "Image: df983abed.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  94% 313/334 [00:44<00:01, 13.76it/s]Image: def2e3f57.jpg | Classes present: tensor([0, 2])\n",
            "Image: dfc4b8d29.jpg | Classes present: tensor([0])\n",
            "Image: defee8509.jpg | Classes present: tensor([0])\n",
            "Image: deff23782.jpg | Classes present: tensor([0])\n",
            "Image: e055a603c.jpg | Classes present: tensor([0])\n",
            "Image: e07c94229.jpg | Classes present: tensor([0])\n",
            "Image: df0168063.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  94% 315/334 [00:44<00:01, 13.79it/s]Image: e003d691f.jpg | Classes present: tensor([0])\n",
            "Image: e0ad8fed3.jpg | Classes present: tensor([0])\n",
            "Image: e03bf53d8.jpg | Classes present: tensor([0])\n",
            "Image: e0b3e7b3f.jpg | Classes present: tensor([0])\n",
            "Image: e0490b7cf.jpg | Classes present: tensor([0, 2])\n",
            "Image: e29d6c141.jpg | Classes present: tensor([0])\n",
            "Image: e04f5c163.jpg | Classes present: tensor([0, 2])\n",
            "Threshold Optimization:  95% 317/334 [00:45<00:01, 13.71it/s]Image: e2c4275d6.jpg | Classes present: tensor([0])\n",
            "Image: e0b3e7b3f.jpg | Classes present: tensor([0])\n",
            "Image: e2d02393b.jpg | Classes present: tensor([0, 2])\n",
            "Image: e0cc2a416.jpg | Classes present: tensor([0])\n",
            "Image: e1662a8c3.jpg | Classes present: tensor([0])\n",
            "Image: e2d64c010.jpg | Classes present: tensor([0])\n",
            "Image: e21fd95ad.jpg | Classes present: tensor([0, 3])\n",
            "Image: e36a70d40.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  96% 319/334 [00:45<00:01, 13.65it/s]Image: e2d64c010.jpg | Classes present: tensor([0])\n",
            "Image: e401b6539.jpg | Classes present: tensor([0])\n",
            "Image: e2f004578.jpg | Classes present: tensor([0])\n",
            "Image: e45010a6a.jpg | Classes present: tensor([0])\n",
            "Image: e30ea20d9.jpg | Classes present: tensor([0, 2])\n",
            "Image: e461fe709.jpg | Classes present: tensor([0])\n",
            "Image: e32bb7b41.jpg | Classes present: tensor([0])\n",
            "Image: e51c76beb.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  96% 321/334 [00:45<00:00, 14.05it/s]Image: e479a2e88.jpg | Classes present: tensor([0])\n",
            "Image: e55bc715f.jpg | Classes present: tensor([0])\n",
            "Image: e56c928ee.jpg | Classes present: tensor([0])\n",
            "Image: e4911993d.jpg | Classes present: tensor([0])\n",
            "Image: e56d5dfde.jpg | Classes present: tensor([0])\n",
            "Image: e495d5456.jpg | Classes present: tensor([0])\n",
            "Image: e495d5456.jpg | Classes present: tensor([0])\n",
            "Image: e5b65b5ec.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  97% 323/334 [00:45<00:00, 13.76it/s]Image: e5c50b997.jpg | Classes present: tensor([0])\n",
            "Image: e56f52c1e.jpg | Classes present: tensor([0])\n",
            "Image: e5cc898b6.jpg | Classes present: tensor([0])\n",
            "Image: e573ac857.jpg | Classes present: tensor([0])\n",
            "Image: e5e0fe470.jpg | Classes present: tensor([0])\n",
            "Image: e573ac857.jpg | Classes present: tensor([0])\n",
            "Image: e57efd4b4.jpg | Classes present: tensor([0])\n",
            "Image: e667de6f9.jpg | Classes present: tensor([0])\n",
            "Image: e6a44cda3.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  97% 325/334 [00:45<00:00, 13.68it/s]Image: e5ea04944.jpg | Classes present: tensor([0, 2])\n",
            "Image: e6bf58db7.jpg | Classes present: tensor([0])\n",
            "Image: e6c32de72.jpg | Classes present: tensor([0])\n",
            "Image: e5f1d5a38.jpg | Classes present: tensor([0])\n",
            "Image: e91814529.jpg | Classes present: tensor([0])\n",
            "Image: e658a2891.jpg | Classes present: tensor([0, 2])\n",
            "Image: e9463eb04.jpg | Classes present: tensor([0])\n",
            "Image: e665a434f.jpg | Classes present: tensor([0])\n",
            "Image: e9b77950e.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  98% 327/334 [00:45<00:00, 13.18it/s]Image: e70c4768b.jpg | Classes present: tensor([0])\n",
            "Image: e9b77950e.jpg | Classes present: tensor([0])\n",
            "Image: e7268620b.jpg | Classes present: tensor([0, 2])\n",
            "Image: e77d57652.jpg | Classes present: tensor([0])\n",
            "Image: eae840b74.jpg | Classes present: tensor([0])\n",
            "Image: e7c915edc.jpg | Classes present: tensor([0])\n",
            "Image: eb4225311.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  99% 329/334 [00:45<00:00, 13.69it/s]Image: ea13e9557.jpg | Classes present: tensor([0])\n",
            "Image: eb6983d21.jpg | Classes present: tensor([0])\n",
            "Image: ea8acd661.jpg | Classes present: tensor([0])\n",
            "Image: eb7ec1f85.jpg | Classes present: tensor([0, 2])\n",
            "Image: eaaa61b15.jpg | Classes present: tensor([0])\n",
            "Image: ed22af554.jpg | Classes present: tensor([0, 2])\n",
            "Image: eab9d667f.jpg | Classes present: tensor([0])\n",
            "Image: ed861754e.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization:  99% 331/334 [00:46<00:00, 11.94it/s]Image: ec52fac2d.jpg | Classes present: tensor([0])\n",
            "Image: ec6a951ba.jpg | Classes present: tensor([0])\n",
            "Image: eca0aa4ff.jpg | Classes present: tensor([0])\n",
            "Image: ed1c6be8d.jpg | Classes present: tensor([0])\n",
            "Threshold Optimization: 100% 334/334 [00:46<00:00,  7.21it/s]\n",
            "Optimal Class Thresholds: [-3.35546875, -6.17578125, -0.7470703125, -2.990234375]\n",
            "\n",
            "Running inference...\n",
            "Processing batches:   0% 0/334 [00:00<?, ?it/s]Image: 000a4bcdd.jpg | Classes present: tensor([0])\n",
            "Image: 0025bde0c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 000f6bf48.jpg | Classes present: tensor([0])\n",
            "Image: 0095cd374.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0014fce06.jpg | Classes present: tensor([0])\n",
            "Image: 00ac8372f.jpg | Classes present: tensor([0])\n",
            "Image: 0025bde0c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 00af2671f.jpg | Classes present: tensor([0])\n",
            "Image: 00ac8372f.jpg | Classes present: tensor([0])\n",
            "Image: 0139dd004.jpg | Classes present: tensor([0])\n",
            "Image: 00bf8497a.jpg | Classes present: tensor([0])\n",
            "Image: 00d639396.jpg | Classes present: tensor([0])\n",
            "Image: 01764ee81.jpg | Classes present: tensor([0, 2])\n",
            "Image: 01338c0ea.jpg | Classes present: tensor([0])\n",
            "Image: 01919944c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 01cfacf80.jpg | Classes present: tensor([0, 3])\n",
            "Image: 01df77e59.jpg | Classes present: tensor([0])\n",
            "Image: 01cfacf80.jpg | Classes present: tensor([0, 3])\n",
            "Memory usage: 42.6%\n",
            "Processing batches:   0% 1/334 [00:00<02:52,  1.93it/s]Memory usage: 42.6%\n",
            "Image: 01e020dc5.jpg | Classes present: tensor([0])\n",
            "Image: 020ff3106.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.6%\n",
            "Memory usage: 42.6%\n",
            "Image: 01fd320c9.jpg | Classes present: tensor([0])\n",
            "Image: 02291e913.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.6%\n",
            "Image: 02701c239.jpg | Classes present: tensor([0])\n",
            "Image: 02c79bfcb.jpg | Classes present: tensor([0])\n",
            "Image: 02b2d3aa4.jpg | Classes present: tensor([0])\n",
            "Image: 02d18b8a4.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.6%\n",
            "Processing batches:   2% 6/334 [00:00<00:30, 10.93it/s]Image: 038f14456.jpg | Classes present: tensor([0])\n",
            "Image: 034941f9d.jpg | Classes present: tensor([0])\n",
            "Image: 03faf7462.jpg | Classes present: tensor([0])\n",
            "Image: 0386ce84b.jpg | Classes present: tensor([0])\n",
            "Image: 04072b39a.jpg | Classes present: tensor([0])\n",
            "Image: 04d49c95d.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.6%\n",
            "Image: 04e23e414.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.6%\n",
            "Processing batches:   2% 8/334 [00:00<00:27, 11.78it/s]Image: 056e34021.jpg | Classes present: tensor([0])\n",
            "Image: 068c6c4a9.jpg | Classes present: tensor([0])\n",
            "Image: 0696cfa05.jpg | Classes present: tensor([0, 2])\n",
            "Image: 05d6bccf8.jpg | Classes present: tensor([0, 2])\n",
            "Image: 060964105.jpg | Classes present: tensor([0])\n",
            "Image: 06ad83bac.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.6%\n",
            "Image: 06e7b157a.jpg | Classes present: tensor([0])\n",
            "Image: 06e6e7a8c.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.6%\n",
            "Processing batches:   3% 10/334 [00:00<00:27, 11.72it/s]Image: 06eb2151d.jpg | Classes present: tensor([0])\n",
            "Image: 0712fbd90.jpg | Classes present: tensor([0])\n",
            "Image: 06f52f4dd.jpg | Classes present: tensor([0])\n",
            "Image: 07ac7620c.jpg | Classes present: tensor([0])\n",
            "Image: 07c917711.jpg | Classes present: tensor([0])\n",
            "Image: 06fb3a6e5.jpg | Classes present: tensor([0])\n",
            "Image: 08193cfc8.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.6%\n",
            "Image: 0808a098b.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.6%\n",
            "Processing batches:   4% 12/334 [00:01<00:26, 12.11it/s]Image: 0841074c1.jpg | Classes present: tensor([0])\n",
            "Image: 08a1a079b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 085bcd104.jpg | Classes present: tensor([0, 2])\n",
            "Image: 08a1a079b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 088aee82e.jpg | Classes present: tensor([0, 2])\n",
            "Image: 08de8621d.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.6%\n",
            "Image: 08de8df60.jpg | Classes present: tensor([0])\n",
            "Image: 08de8df60.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.6%\n",
            "Processing batches:   4% 14/334 [00:01<00:25, 12.42it/s]Image: 08e3aadde.jpg | Classes present: tensor([0])\n",
            "Image: 092145f0c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 08f9c685f.jpg | Classes present: tensor([0])\n",
            "Image: 099e4e39a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 08f9c685f.jpg | Classes present: tensor([0])\n",
            "Image: 09f1605ee.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.6%\n",
            "Image: 0a37f0a29.jpg | Classes present: tensor([0])\n",
            "Image: 0a4ad45a5.jpg | Classes present: tensor([0])\n",
            "Image: 0aa4399a4.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.6%\n",
            "Processing batches:   5% 16/334 [00:01<00:24, 12.95it/s]Image: 0b56da4ff.jpg | Classes present: tensor([0])\n",
            "Image: 0af6b34a8.jpg | Classes present: tensor([0])\n",
            "Image: 0bfcf7a71.jpg | Classes present: tensor([0])\n",
            "Image: 0b1993a49.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0c59df320.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.7%\n",
            "Image: 0caf53aba.jpg | Classes present: tensor([0])\n",
            "Image: 0ce6ef153.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.7%\n",
            "Processing batches:   5% 18/334 [00:01<00:22, 13.74it/s]Image: 0ddbc9fb5.jpg | Classes present: tensor([0, 3])\n",
            "Image: 0db535c8c.jpg | Classes present: tensor([0])\n",
            "Image: 0e0d5004d.jpg | Classes present: tensor([0])\n",
            "Image: 0dc953a31.jpg | Classes present: tensor([0])\n",
            "Image: 0e1925eb6.jpg | Classes present: tensor([0])\n",
            "Image: 0dd8c9f61.jpg | Classes present: tensor([0])\n",
            "Image: 0e650e720.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.7%\n",
            "Memory usage: 42.7%\n",
            "Processing batches:   6% 20/334 [00:01<00:23, 13.61it/s]Image: 0e71cd651.jpg | Classes present: tensor([0])\n",
            "Image: 0eb09950a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0e71cd651.jpg | Classes present: tensor([0])\n",
            "Image: 0ef465b25.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0e86dea5b.jpg | Classes present: tensor([0])\n",
            "Image: 0f9f79a88.jpg | Classes present: tensor([0])\n",
            "Image: 0eae06feb.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.7%\n",
            "Image: 0fc3d194a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 0ff13bf69.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.7%\n",
            "Processing batches:   7% 22/334 [00:01<00:24, 12.58it/s]Image: 1082cfe08.jpg | Classes present: tensor([0])\n",
            "Image: 1013a0b6e.jpg | Classes present: tensor([0])\n",
            "Image: 1086196e1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 101bc8aa5.jpg | Classes present: tensor([0, 2])\n",
            "Image: 10d98c2be.jpg | Classes present: tensor([0, 2])\n",
            "Image: 106fd7aad.jpg | Classes present: tensor([0])\n",
            "Image: 10d9f85be.jpg | Classes present: tensor([0])\n",
            "Image: 11192bc94.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.6%\n",
            "Memory usage: 42.6%\n",
            "Processing batches:   7% 24/334 [00:02<00:26, 11.79it/s]Image: 11ff6a6f4.jpg | Classes present: tensor([0, 2])\n",
            "Image: 124204a30.jpg | Classes present: tensor([0])\n",
            "Image: 11418b1c5.jpg | Classes present: tensor([0])\n",
            "Image: 12d38a1d4.jpg | Classes present: tensor([0])\n",
            "Image: 118b71091.jpg | Classes present: tensor([0])\n",
            "Image: 12dd3899c.jpg | Classes present: tensor([0])\n",
            "Image: 11b37e4d7.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.8%\n",
            "Image: 1422b7da0.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.8%\n",
            "Processing batches:   8% 26/334 [00:02<00:28, 10.81it/s]Image: 135fe211d.jpg | Classes present: tensor([0])\n",
            "Image: 1435cd970.jpg | Classes present: tensor([0])\n",
            "Image: 137b5546d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1387583da.jpg | Classes present: tensor([0, 2])\n",
            "Image: 147ca5516.jpg | Classes present: tensor([0])\n",
            "Image: 140e212df.jpg | Classes present: tensor([0])\n",
            "Image: 14e4da366.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.7%\n",
            "Memory usage: 42.7%\n",
            "Processing batches:   8% 28/334 [00:02<00:30, 10.12it/s]Image: 159b43d49.jpg | Classes present: tensor([0])\n",
            "Image: 1501f53a2.jpg | Classes present: tensor([0])\n",
            "Image: 15ce9e5cf.jpg | Classes present: tensor([0])\n",
            "Image: 153b56c43.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1561eb657.jpg | Classes present: tensor([0])\n",
            "Image: 15e8d5e3d.jpg | Classes present: tensor([0])\n",
            "Image: 161ca82bf.jpg | Classes present: tensor([0])\n",
            "Image: 15796b4d5.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.8%\n",
            "Memory usage: 42.8%\n",
            "Processing batches:   9% 30/334 [00:03<00:43,  7.05it/s]Image: 163cc2750.jpg | Classes present: tensor([0, 3])\n",
            "Image: 16d0b11ff.jpg | Classes present: tensor([0])\n",
            "Image: 171c64a72.jpg | Classes present: tensor([0, 2])\n",
            "Image: 166818755.jpg | Classes present: tensor([0])\n",
            "Image: 172b72353.jpg | Classes present: tensor([0])\n",
            "Image: 167d6930a.jpg | Classes present: tensor([0])\n",
            "Image: 16d0b11ff.jpg | Classes present: tensor([0])\n",
            "Image: 174af9fd6.jpg | Classes present: tensor([0])\n",
            "Image: 180bb19f9.jpg | Classes present: tensor([0])\n",
            "Image: 17e7cd5c6.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:   9% 31/334 [00:03<01:27,  3.46it/s]Image: 17f611256.jpg | Classes present: tensor([0])\n",
            "Image: 189659389.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 17f9f952a.jpg | Classes present: tensor([0])\n",
            "Image: 18ace9a9a.jpg | Classes present: tensor([0, 3])\n",
            "Image: 1809bcad9.jpg | Classes present: tensor([0])\n",
            "Image: 18c14f720.jpg | Classes present: tensor([0])\n",
            "Image: 192e256ba.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  10% 33/334 [00:04<01:18,  3.83it/s]Memory usage: 42.3%\n",
            "Image: 19ab4c335.jpg | Classes present: tensor([0, 3])\n",
            "Image: 195e36565.jpg | Classes present: tensor([0])\n",
            "Image: 19ab4c335.jpg | Classes present: tensor([0, 3])\n",
            "Image: 196e624f5.jpg | Classes present: tensor([0])\n",
            "Image: 19c645c25.jpg | Classes present: tensor([0])\n",
            "Image: 198252b95.jpg | Classes present: tensor([0])\n",
            "Image: 19d892dd9.jpg | Classes present: tensor([0, 3])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  10% 35/334 [00:04<01:04,  4.64it/s]Image: 1a075e075.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 1b213d816.jpg | Classes present: tensor([0])\n",
            "Image: 1a4039711.jpg | Classes present: tensor([0])\n",
            "Image: 1b2c029b8.jpg | Classes present: tensor([0])\n",
            "Image: 1a9c38991.jpg | Classes present: tensor([0])\n",
            "Image: 1b4642fd5.jpg | Classes present: tensor([0])\n",
            "Image: 1abb621ee.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  11% 37/334 [00:04<00:55,  5.39it/s]Image: 1b52ec552.jpg | Classes present: tensor([0])\n",
            "Image: 1b7e426bc.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 1bdb7f26f.jpg | Classes present: tensor([0])\n",
            "Image: 1b8ef5392.jpg | Classes present: tensor([0])\n",
            "Image: 1be49cb6f.jpg | Classes present: tensor([0, 2])\n",
            "Image: 1bc37a6f4.jpg | Classes present: tensor([0])\n",
            "Image: 1c18acd30.jpg | Classes present: tensor([0])\n",
            "Image: 1bd394dd6.jpg | Classes present: tensor([0])\n",
            "Image: 1c97d1861.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  12% 39/334 [00:05<00:50,  5.85it/s]Memory usage: 42.3%\n",
            "Image: 1cac6e1f3.jpg | Classes present: tensor([0])\n",
            "Image: 1d71764d0.jpg | Classes present: tensor([0])\n",
            "Image: 1cac6e1f3.jpg | Classes present: tensor([0])\n",
            "Image: 1d718ddb9.jpg | Classes present: tensor([0])\n",
            "Image: 1d28002da.jpg | Classes present: tensor([0])\n",
            "Image: 1dd8107e9.jpg | Classes present: tensor([0])\n",
            "Image: 1d56ccf70.jpg | Classes present: tensor([0])\n",
            "Image: 1e0220d5c.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  12% 41/334 [00:05<00:46,  6.26it/s]Image: 1e0980950.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 1e7b96509.jpg | Classes present: tensor([0])\n",
            "Image: 1ea40df0e.jpg | Classes present: tensor([0])\n",
            "Image: 1e979fb66.jpg | Classes present: tensor([0])\n",
            "Image: 1f3e0b337.jpg | Classes present: tensor([0])\n",
            "Image: 1ea25d4fa.jpg | Classes present: tensor([0])\n",
            "Image: 1f8ea6702.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  13% 43/334 [00:05<00:42,  6.80it/s]Image: 1fd098a38.jpg | Classes present: tensor([0])\n",
            "Image: 1fc4c5a4b.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 1ff3214db.jpg | Classes present: tensor([0])\n",
            "Image: 207e88d4a.jpg | Classes present: tensor([0])\n",
            "Image: 2012a6d02.jpg | Classes present: tensor([0])\n",
            "Image: 207f33325.jpg | Classes present: tensor([0])\n",
            "Image: 206c8bb0c.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  13% 45/334 [00:05<00:40,  7.12it/s]Image: 20964a4f0.jpg | Classes present: tensor([0, 3])\n",
            "Image: 208825e67.jpg | Classes present: tensor([0])\n",
            "Image: 20a894ca5.jpg | Classes present: tensor([0])\n",
            "Image: 20964a4f0.jpg | Classes present: tensor([0, 3])\n",
            "Memory usage: 42.3%\n",
            "Image: 2122b99c0.jpg | Classes present: tensor([0])\n",
            "Image: 2188f5429.jpg | Classes present: tensor([0])\n",
            "Image: 214465021.jpg | Classes present: tensor([0])\n",
            "Image: 21af0ec58.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  14% 47/334 [00:06<00:35,  8.07it/s]Image: 21bf9d854.jpg | Classes present: tensor([0])\n",
            "Image: 2222a03b3.jpg | Classes present: tensor([0])\n",
            "Image: 22123f29f.jpg | Classes present: tensor([0])\n",
            "Image: 225ef7f0d.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 2395db536.jpg | Classes present: tensor([0])\n",
            "Image: 23c450c03.jpg | Classes present: tensor([0])\n",
            "Image: 23db57033.jpg | Classes present: tensor([0])\n",
            "Image: 23bb4d637.jpg | Classes present: tensor([0])\n",
            "Image: 23e4a530a.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  15% 49/334 [00:06<00:31,  9.17it/s]Image: 248220d45.jpg | Classes present: tensor([0, 2])\n",
            "Image: 242894fc4.jpg | Classes present: tensor([0])\n",
            "Image: 248585a26.jpg | Classes present: tensor([0, 3])\n",
            "Memory usage: 42.3%\n",
            "Image: 24a91d324.jpg | Classes present: tensor([0])\n",
            "Image: 248585a26.jpg | Classes present: tensor([0, 3])\n",
            "Image: 24debd5d7.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2491d607d.jpg | Classes present: tensor([0])\n",
            "Image: 24e21e85a.jpg | Classes present: tensor([0])\n",
            "Image: 2527831fa.jpg | Classes present: tensor([0])\n",
            "Image: 24e249331.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  15% 51/334 [00:06<00:29,  9.67it/s]Memory usage: 42.3%\n",
            "Image: 25c940a74.jpg | Classes present: tensor([0])\n",
            "Image: 25515c2f6.jpg | Classes present: tensor([0])\n",
            "Image: 25f9a8622.jpg | Classes present: tensor([0, 3])\n",
            "Image: 2558c43bf.jpg | Classes present: tensor([0, 2])\n",
            "Image: 25fc987a1.jpg | Classes present: tensor([0])\n",
            "Image: 2558c43bf.jpg | Classes present: tensor([0, 2])\n",
            "Image: 26272c2a7.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  16% 53/334 [00:06<00:26, 10.68it/s]Memory usage: 42.3%\n",
            "Image: 268446e17.jpg | Classes present: tensor([0])\n",
            "Image: 275e3bca6.jpg | Classes present: tensor([0])\n",
            "Image: 279af89c7.jpg | Classes present: tensor([0])\n",
            "Image: 26f6f4c72.jpg | Classes present: tensor([0])\n",
            "Image: 279b82aaf.jpg | Classes present: tensor([0])\n",
            "Image: 270f5361d.jpg | Classes present: tensor([0])\n",
            "Image: 27faa1de7.jpg | Classes present: tensor([0, 2])\n",
            "Image: 27207fb2e.jpg | Classes present: tensor([0])\n",
            "Image: 2930b4f52.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  16% 55/334 [00:06<00:24, 11.32it/s]Memory usage: 42.3%\n",
            "Image: 282cd397d.jpg | Classes present: tensor([0])\n",
            "Image: 2930b4f52.jpg | Classes present: tensor([0])\n",
            "Image: 282cd397d.jpg | Classes present: tensor([0])\n",
            "Image: 294d6d5f8.jpg | Classes present: tensor([0])\n",
            "Image: 29124169b.jpg | Classes present: tensor([0])\n",
            "Image: 299d06031.jpg | Classes present: tensor([0])\n",
            "Image: 2912df978.jpg | Classes present: tensor([0])\n",
            "Image: 2a6669d9a.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  17% 57/334 [00:06<00:23, 11.71it/s]Memory usage: 42.3%\n",
            "Image: 29c39b183.jpg | Classes present: tensor([0])\n",
            "Image: 2a74520ed.jpg | Classes present: tensor([0])\n",
            "Image: 29c39b183.jpg | Classes present: tensor([0])\n",
            "Image: 2a95756e7.jpg | Classes present: tensor([0])\n",
            "Image: 29d83d9ce.jpg | Classes present: tensor([0])\n",
            "Image: 2a9e93a87.jpg | Classes present: tensor([0])\n",
            "Image: 2a07798b5.jpg | Classes present: tensor([0])\n",
            "Image: 2b8dfbe0b.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  18% 59/334 [00:07<00:22, 11.97it/s]Memory usage: 42.1%\n",
            "Image: 2ae658a56.jpg | Classes present: tensor([0])\n",
            "Image: 2bdb48c91.jpg | Classes present: tensor([0])\n",
            "Image: 2b0055ed4.jpg | Classes present: tensor([0])\n",
            "Image: 2c56741a3.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2b15517b1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2c63f60e3.jpg | Classes present: tensor([0])\n",
            "Image: 2b449bdcf.jpg | Classes present: tensor([0])\n",
            "Image: 2e4fefc28.jpg | Classes present: tensor([0, 2])\n",
            "Image: 2c7e26f0d.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  18% 61/334 [00:07<00:23, 11.68it/s]Image: 2e55a1149.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.2%\n",
            "Image: 2d26b9dda.jpg | Classes present: tensor([0])\n",
            "Image: 2e84c0c34.jpg | Classes present: tensor([0])\n",
            "Image: 2d37a1ebe.jpg | Classes present: tensor([0])\n",
            "Image: 2e8733afa.jpg | Classes present: tensor([0])\n",
            "Image: 2e4da1fd1.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  19% 63/334 [00:07<00:21, 12.66it/s]Image: 2e8f2ddb8.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Image: 2eff528e8.jpg | Classes present: tensor([0])\n",
            "Image: 2e97e0251.jpg | Classes present: tensor([0])\n",
            "Image: 2f5690028.jpg | Classes present: tensor([0])\n",
            "Image: 2ede3bc01.jpg | Classes present: tensor([0])\n",
            "Image: 2f8cf11d3.jpg | Classes present: tensor([0])\n",
            "Image: 2ef5b3de1.jpg | Classes present: tensor([0])\n",
            "Image: 2fa3a9f3e.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  19% 65/334 [00:07<00:20, 12.91it/s]Image: 2fe9f78c9.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Image: 2fa996a4c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3071e65a5.jpg | Classes present: tensor([0])\n",
            "Image: 2fbdc1244.jpg | Classes present: tensor([0])\n",
            "Image: 2fcfb108a.jpg | Classes present: tensor([0])\n",
            "Image: 30799f11c.jpg | Classes present: tensor([0])\n",
            "Image: 2fcfb108a.jpg | Classes present: tensor([0])\n",
            "Image: 308c978a7.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  20% 67/334 [00:07<00:20, 13.29it/s]Image: 31262e8f9.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Image: 30ba0b89a.jpg | Classes present: tensor([0])\n",
            "Image: 31433d3b4.jpg | Classes present: tensor([0])\n",
            "Image: 30c2d753f.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3159ee27a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 30d00096d.jpg | Classes present: tensor([0])\n",
            "Image: 316f0cc50.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3116edfe6.jpg | Classes present: tensor([0])\n",
            "Image: 320557243.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  21% 69/334 [00:07<00:19, 13.26it/s]Memory usage: 42.2%\n",
            "Image: 31716f6ae.jpg | Classes present: tensor([0, 2])\n",
            "Image: 321975fb3.jpg | Classes present: tensor([0])\n",
            "Image: 31a43a534.jpg | Classes present: tensor([0, 2])\n",
            "Image: 32578d3e5.jpg | Classes present: tensor([0])\n",
            "Image: 31dee4189.jpg | Classes present: tensor([0])\n",
            "Image: 326d25e8c.jpg | Classes present: tensor([0])\n",
            "Image: 31eda6a87.jpg | Classes present: tensor([0])\n",
            "Image: 335be17fa.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  21% 71/334 [00:07<00:20, 12.84it/s]Image: 3294c9bd1.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 33754aa9b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3294c9bd1.jpg | Classes present: tensor([0])\n",
            "Image: 3377332c0.jpg | Classes present: tensor([0, 2])\n",
            "Image: 32eca38d5.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3385f9e14.jpg | Classes present: tensor([0])\n",
            "Image: 33514c0b1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 34a5114d6.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  22% 73/334 [00:08<00:20, 12.75it/s]Memory usage: 42.3%\n",
            "Image: 338d3b828.jpg | Classes present: tensor([0])\n",
            "Image: 34a5114d6.jpg | Classes present: tensor([0])\n",
            "Image: 34ee04d85.jpg | Classes present: tensor([0])\n",
            "Image: 338d3b828.jpg | Classes present: tensor([0])\n",
            "Image: 34f8faf6d.jpg | Classes present: tensor([0])\n",
            "Image: 33a4b4335.jpg | Classes present: tensor([0])\n",
            "Image: 345cf1dc3.jpg | Classes present: tensor([0])\n",
            "Image: 35d142883.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  22% 75/334 [00:08<00:20, 12.60it/s]Image: 35d142883.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 3520eaa6d.jpg | Classes present: tensor([0])\n",
            "Image: 36789516a.jpg | Classes present: tensor([0])\n",
            "Image: 35271f898.jpg | Classes present: tensor([0])\n",
            "Image: 369ac4b0a.jpg | Classes present: tensor([0])\n",
            "Image: 353e60eef.jpg | Classes present: tensor([0, 2])\n",
            "Image: 373ebde8b.jpg | Classes present: tensor([0])\n",
            "Image: 35a8b85a8.jpg | Classes present: tensor([0])\n",
            "Image: 374d9c63f.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  23% 77/334 [00:08<00:20, 12.30it/s]Memory usage: 42.1%\n",
            "Image: 36a804181.jpg | Classes present: tensor([0])\n",
            "Image: 37acd89d2.jpg | Classes present: tensor([0])\n",
            "Image: 36cd2cde0.jpg | Classes present: tensor([0, 2])\n",
            "Image: 380e3ba93.jpg | Classes present: tensor([0])\n",
            "Image: 3704cdfd6.jpg | Classes present: tensor([0])\n",
            "Image: 3964357cd.jpg | Classes present: tensor([0, 3])\n",
            "Image: 373c6898f.jpg | Classes present: tensor([0, 2])\n",
            "Image: 39b8cb37a.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  24% 79/334 [00:08<00:20, 12.71it/s]Image: 39e365d3b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 38698fd76.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: 3a03385b5.jpg | Classes present: tensor([0])\n",
            "Image: 3888ec2cd.jpg | Classes present: tensor([0])\n",
            "Image: 3af515180.jpg | Classes present: tensor([0])\n",
            "Image: 38a63550b.jpg | Classes present: tensor([0])\n",
            "Image: 3b3df8749.jpg | Classes present: tensor([0])\n",
            "Image: 391b766d3.jpg | Classes present: tensor([0])\n",
            "Image: 3b6f87aed.jpg | Classes present: tensor([0])\n",
            "Image: 3cb1c14c8.jpg | Classes present: tensor([0])\n",
            "Image: 3a4edbde9.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  24% 81/334 [00:08<00:21, 11.80it/s]Image: 3e519e65d.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Image: 3a5246d98.jpg | Classes present: tensor([0])\n",
            "Image: 3e59e0f17.jpg | Classes present: tensor([0])\n",
            "Image: 3a96940c6.jpg | Classes present: tensor([0])\n",
            "Image: 3ab1a7324.jpg | Classes present: tensor([0])\n",
            "Image: 3f0b1c635.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  25% 83/334 [00:08<00:19, 12.76it/s]Image: 3f272083c.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Image: 3da31ea30.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4029fea8e.jpg | Classes present: tensor([0])\n",
            "Image: 3de8f5d88.jpg | Classes present: tensor([0])\n",
            "Image: 40aae2e57.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3e185a3fe.jpg | Classes present: tensor([0])\n",
            "Image: 40b724998.jpg | Classes present: tensor([0, 2])\n",
            "Image: 3e1f5caa8.jpg | Classes present: tensor([0])\n",
            "Image: 40d766da8.jpg | Classes present: tensor([0, 3])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  25% 85/334 [00:09<00:18, 13.32it/s]Memory usage: 42.3%\n",
            "Image: 3f536622f.jpg | Classes present: tensor([0])\n",
            "Image: 41411378e.jpg | Classes present: tensor([0, 3])\n",
            "Image: 3fb68881e.jpg | Classes present: tensor([0])\n",
            "Image: 415252307.jpg | Classes present: tensor([0])\n",
            "Image: 3fdbbf305.jpg | Classes present: tensor([0])\n",
            "Image: 415dd1efd.jpg | Classes present: tensor([0])\n",
            "Image: 401de199f.jpg | Classes present: tensor([0])\n",
            "Image: 41716714b.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  26% 87/334 [00:09<00:18, 13.21it/s]Image: 411377ca3.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 427085ef4.jpg | Classes present: tensor([0])\n",
            "Image: 412fe7f70.jpg | Classes present: tensor([0])\n",
            "Image: 429650b38.jpg | Classes present: tensor([0])\n",
            "Image: 41333f13c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 429951ca7.jpg | Classes present: tensor([0, 2])\n",
            "Image: 41411378e.jpg | Classes present: tensor([0, 3])\n",
            "Image: 42af54b00.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  27% 89/334 [00:09<00:18, 13.18it/s]Memory usage: 42.3%\n",
            "Image: 418e47222.jpg | Classes present: tensor([0])\n",
            "Image: 4355ef39b.jpg | Classes present: tensor([0])\n",
            "Image: 419dc2472.jpg | Classes present: tensor([0])\n",
            "Image: 436398e3b.jpg | Classes present: tensor([0])\n",
            "Image: 4243c7476.jpg | Classes present: tensor([0])\n",
            "Image: 436e3f4a0.jpg | Classes present: tensor([0])\n",
            "Image: 42695cb60.jpg | Classes present: tensor([0])\n",
            "Image: 439f1a016.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  27% 91/334 [00:09<00:18, 13.12it/s]Image: 42caf4e12.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 441add89c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 42dd20db7.jpg | Classes present: tensor([0])\n",
            "Image: 4422bc417.jpg | Classes present: tensor([0])\n",
            "Image: 4340e1e42.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4422bc417.jpg | Classes present: tensor([0])\n",
            "Image: 4345c2b85.jpg | Classes present: tensor([0])\n",
            "Image: 445dfb2ce.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  28% 93/334 [00:09<00:18, 13.19it/s]Image: 43b6618bf.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 44ada0c0b.jpg | Classes present: tensor([0])\n",
            "Image: 43c6a30fa.jpg | Classes present: tensor([0])\n",
            "Image: 4529ee151.jpg | Classes present: tensor([0])\n",
            "Image: 43d7e6da0.jpg | Classes present: tensor([0])\n",
            "Image: 45612bd46.jpg | Classes present: tensor([0])\n",
            "Image: 44011d351.jpg | Classes present: tensor([0])\n",
            "Image: 459790d82.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  28% 95/334 [00:09<00:17, 13.39it/s]Memory usage: 42.3%\n",
            "Image: 446ba8f9b.jpg | Classes present: tensor([0])\n",
            "Image: 4613bc12c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 446c4efb5.jpg | Classes present: tensor([0])\n",
            "Image: 4613d520c.jpg | Classes present: tensor([0])\n",
            "Image: 4499aaa80.jpg | Classes present: tensor([0])\n",
            "Image: 4695c2d2a.jpg | Classes present: tensor([0])\n",
            "Image: 44a0d5b55.jpg | Classes present: tensor([0])\n",
            "Image: 472407235.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.4%\n",
            "Processing batches:  29% 97/334 [00:09<00:17, 13.35it/s]Image: 459cd013a.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.4%\n",
            "Image: 483e4b5f7.jpg | Classes present: tensor([0])\n",
            "Image: 45a4c0a58.jpg | Classes present: tensor([0])\n",
            "Image: 484439824.jpg | Classes present: tensor([0])\n",
            "Image: 45cca62e0.jpg | Classes present: tensor([0])\n",
            "Image: 48532e006.jpg | Classes present: tensor([0, 2])\n",
            "Image: 45d8e1473.jpg | Classes present: tensor([0])\n",
            "Image: 4854add54.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.4%\n",
            "Processing batches:  30% 99/334 [00:10<00:17, 13.44it/s]Image: 474c5f34e.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.4%\n",
            "Image: 48c466789.jpg | Classes present: tensor([0])\n",
            "Image: 47a18bd61.jpg | Classes present: tensor([0])\n",
            "Image: 49c035d7e.jpg | Classes present: tensor([0])\n",
            "Image: 47c24f230.jpg | Classes present: tensor([0])\n",
            "Image: 49cf406c7.jpg | Classes present: tensor([0, 2])\n",
            "Image: 47cee01b1.jpg | Classes present: tensor([0])\n",
            "Image: 4a662783b.jpg | Classes present: tensor([0])\n",
            "Image: 4857d0687.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.4%\n",
            "Processing batches:  30% 101/334 [00:10<00:18, 12.87it/s]Memory usage: 42.4%\n",
            "Image: 48626da29.jpg | Classes present: tensor([0])\n",
            "Image: 4b762b230.jpg | Classes present: tensor([0])\n",
            "Image: 4b902c994.jpg | Classes present: tensor([0, 2])\n",
            "Image: 48831ab9e.jpg | Classes present: tensor([0])\n",
            "Image: 4c12f034c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 488922ac2.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.4%\n",
            "Processing batches:  31% 103/334 [00:10<00:16, 13.81it/s]Image: 4c3100013.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.4%\n",
            "Image: 4aca6c4a7.jpg | Classes present: tensor([0])\n",
            "Image: 4ca64717c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4b56df46d.jpg | Classes present: tensor([0])\n",
            "Image: 4b56df46d.jpg | Classes present: tensor([0])\n",
            "Image: 4d1444a12.jpg | Classes present: tensor([0])\n",
            "Image: 4b712bf89.jpg | Classes present: tensor([0])\n",
            "Image: 4d1444a12.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.4%\n",
            "Processing batches:  31% 105/334 [00:10<00:16, 13.68it/s]Image: 4d6973926.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.4%\n",
            "Image: 4c770beb5.jpg | Classes present: tensor([0])\n",
            "Image: 4e1d262fb.jpg | Classes present: tensor([0])\n",
            "Image: 4c770beb5.jpg | Classes present: tensor([0])\n",
            "Image: 4e25cb8e7.jpg | Classes present: tensor([0])\n",
            "Image: 4c7ff2056.jpg | Classes present: tensor([0])\n",
            "Image: 4e6514402.jpg | Classes present: tensor([0])\n",
            "Image: 4c9245dcf.jpg | Classes present: tensor([0])\n",
            "Image: 4ec252808.jpg | Classes present: tensor([0, 3])\n",
            "Memory usage: 42.4%\n",
            "Processing batches:  32% 107/334 [00:10<00:16, 13.80it/s]Image: 4ef65d75b.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.4%\n",
            "Image: 4dbadaa3e.jpg | Classes present: tensor([0])\n",
            "Image: 4fe777e50.jpg | Classes present: tensor([0])\n",
            "Image: 4dbadaa3e.jpg | Classes present: tensor([0])\n",
            "Image: 4dd52fc23.jpg | Classes present: tensor([0, 3])\n",
            "Image: 504e47cce.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5064ecb6d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 4dd52fc23.jpg | Classes present: tensor([0, 3])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  33% 109/334 [00:10<00:16, 13.47it/s]Image: 4ecf05db6.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.2%\n",
            "Image: 51632c4a4.jpg | Classes present: tensor([0])\n",
            "Image: 4ee32c458.jpg | Classes present: tensor([0])\n",
            "Image: 51b211df9.jpg | Classes present: tensor([0])\n",
            "Image: 4eea878dd.jpg | Classes present: tensor([0])\n",
            "Image: 51d092947.jpg | Classes present: tensor([0])\n",
            "Image: 4ef21d9b7.jpg | Classes present: tensor([0])\n",
            "Image: 51d7bdfc2.jpg | Classes present: tensor([0, 2])\n",
            "Image: 509abf323.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  33% 111/334 [00:10<00:16, 13.48it/s]Memory usage: 42.2%\n",
            "Image: 5283b3138.jpg | Classes present: tensor([0])\n",
            "Image: 50bab4d98.jpg | Classes present: tensor([0, 2])\n",
            "Image: 52faeb955.jpg | Classes present: tensor([0])\n",
            "Image: 50ff24e6e.jpg | Classes present: tensor([0])\n",
            "Image: 53994e13b.jpg | Classes present: tensor([0])\n",
            "Image: 51097aa45.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  34% 113/334 [00:11<00:16, 13.67it/s]Image: 53f2e3c44.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 51d7bee0a.jpg | Classes present: tensor([0])\n",
            "Image: 54fc1f606.jpg | Classes present: tensor([0])\n",
            "Image: 51f9ccdd2.jpg | Classes present: tensor([0])\n",
            "Image: 5545e4b0f.jpg | Classes present: tensor([0])\n",
            "Image: 522d34082.jpg | Classes present: tensor([0])\n",
            "Image: 523fee62c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5545e4b0f.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  34% 115/334 [00:11<00:15, 13.93it/s]Image: 554710095.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 54738099a.jpg | Classes present: tensor([0])\n",
            "Image: 56553f422.jpg | Classes present: tensor([0])\n",
            "Image: 549613483.jpg | Classes present: tensor([0])\n",
            "Image: 54bdb0ccf.jpg | Classes present: tensor([0])\n",
            "Image: 567578f1b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 567578f1b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 54c3ce6f0.jpg | Classes present: tensor([0])\n",
            "Image: 567e1f981.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  35% 117/334 [00:11<00:16, 13.05it/s]Memory usage: 42.3%\n",
            "Image: 57a71495a.jpg | Classes present: tensor([0])\n",
            "Image: 554ee47b6.jpg | Classes present: tensor([0])\n",
            "Image: 5562229c3.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5810e2d40.jpg | Classes present: tensor([0, 2])\n",
            "Image: 559bcc411.jpg | Classes present: tensor([0, 2])\n",
            "Image: 582f0666f.jpg | Classes present: tensor([0])\n",
            "Image: 55c30f544.jpg | Classes present: tensor([0, 2])\n",
            "Image: 585904c94.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  36% 119/334 [00:11<00:16, 12.93it/s]Memory usage: 42.3%\n",
            "Image: 56cc8fb98.jpg | Classes present: tensor([0])\n",
            "Image: 59a2887fd.jpg | Classes present: tensor([0])\n",
            "Image: 59b20349b.jpg | Classes present: tensor([0])\n",
            "Image: 5787b6262.jpg | Classes present: tensor([0, 2])\n",
            "Image: 579a51c1b.jpg | Classes present: tensor([0])\n",
            "Image: 59bcf1693.jpg | Classes present: tensor([0])\n",
            "Image: 5a188bcf6.jpg | Classes present: tensor([0])\n",
            "Image: 57a71495a.jpg | Classes present: tensor([0])\n",
            "Image: 58f11e1cb.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.4%\n",
            "Processing batches:  36% 121/334 [00:11<00:17, 12.07it/s]Memory usage: 42.4%\n",
            "Image: 594e2b83f.jpg | Classes present: tensor([0])\n",
            "Image: 5b470a696.jpg | Classes present: tensor([0])\n",
            "Image: 595373657.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5b5543800.jpg | Classes present: tensor([0])\n",
            "Image: 59a1733a9.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5b5ad8482.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.4%\n",
            "Processing batches:  37% 123/334 [00:11<00:16, 13.18it/s]Memory usage: 42.4%\n",
            "Image: 5b615bff0.jpg | Classes present: tensor([0])\n",
            "Image: 5a8203514.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5c801ba0c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5ad654fc4.jpg | Classes present: tensor([0])\n",
            "Image: 5adb00ee3.jpg | Classes present: tensor([0])\n",
            "Image: 5ca03f4fb.jpg | Classes present: tensor([0])\n",
            "Image: 5b13aedd6.jpg | Classes present: tensor([0])\n",
            "Image: 5ca2ccd75.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.4%\n",
            "Processing batches:  37% 125/334 [00:12<00:15, 13.13it/s]Image: 5cbfcc4dd.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.4%\n",
            "Image: 5b88d9e1a.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5e29012ca.jpg | Classes present: tensor([0])\n",
            "Image: 5baeac055.jpg | Classes present: tensor([0])\n",
            "Image: 5e570da14.jpg | Classes present: tensor([0])\n",
            "Image: 5c36982d0.jpg | Classes present: tensor([0])\n",
            "Image: 5c3e81694.jpg | Classes present: tensor([0])\n",
            "Image: 5e92f8e11.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.4%\n",
            "Processing batches:  38% 127/334 [00:12<00:15, 13.23it/s]Image: 5f121bfff.jpg | Classes present: tensor([0, 2])\n",
            "Image: 5cc07468d.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.4%\n",
            "Image: 5cf1cb974.jpg | Classes present: tensor([0])\n",
            "Image: 60bc48f6b.jpg | Classes present: tensor([0])\n",
            "Image: 61204ded5.jpg | Classes present: tensor([0])\n",
            "Image: 5cf4adf72.jpg | Classes present: tensor([0])\n",
            "Image: 61835d07a.jpg | Classes present: tensor([0])\n",
            "Image: 5d3cbe1fe.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.4%\n",
            "Processing batches:  39% 129/334 [00:12<00:15, 13.52it/s]Image: 61f22bd01.jpg | Classes present: tensor([0])\n",
            "Image: 5fa81f2b5.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.4%\n",
            "Image: 6308e03ad.jpg | Classes present: tensor([0])\n",
            "Image: 604e200e1.jpg | Classes present: tensor([0])\n",
            "Image: 633701ae3.jpg | Classes present: tensor([0])\n",
            "Image: 6057916d4.jpg | Classes present: tensor([0])\n",
            "Image: 605ed0050.jpg | Classes present: tensor([0])\n",
            "Image: 636700b91.jpg | Classes present: tensor([0])\n",
            "Image: 636bad9bd.jpg | Classes present: tensor([0])\n",
            "Image: 622086df1.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.4%\n",
            "Processing batches:  39% 131/334 [00:12<00:16, 11.98it/s]Memory usage: 42.4%\n",
            "Image: 63cf275e8.jpg | Classes present: tensor([0])\n",
            "Image: 624b76e5c.jpg | Classes present: tensor([0])\n",
            "Image: 642cfbe74.jpg | Classes present: tensor([0])\n",
            "Image: 6276bd13c.jpg | Classes present: tensor([0])\n",
            "Image: 6430ea237.jpg | Classes present: tensor([0])\n",
            "Image: 62f84c877.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6430ea237.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.4%\n",
            "Processing batches:  40% 133/334 [00:12<00:15, 12.64it/s]Memory usage: 42.4%\n",
            "Image: 65bb052e9.jpg | Classes present: tensor([0, 2])\n",
            "Image: 639c7495a.jpg | Classes present: tensor([0])\n",
            "Image: 63adb88f1.jpg | Classes present: tensor([0])\n",
            "Image: 66574a641.jpg | Classes present: tensor([0])\n",
            "Image: 63c46a774.jpg | Classes present: tensor([0, 2])\n",
            "Image: 66849c8bd.jpg | Classes present: tensor([0])\n",
            "Image: 63c46a774.jpg | Classes present: tensor([0, 2])\n",
            "Image: 66ac60af4.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  40% 135/334 [00:12<00:15, 12.67it/s]Image: 644f9c71d.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.2%\n",
            "Image: 67741aee6.jpg | Classes present: tensor([0])\n",
            "Image: 644f9c71d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 677828765.jpg | Classes present: tensor([0])\n",
            "Image: 649890305.jpg | Classes present: tensor([0])\n",
            "Image: 67a5a06f1.jpg | Classes present: tensor([0])\n",
            "Image: 64b571a9a.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  41% 137/334 [00:12<00:14, 13.56it/s]Memory usage: 42.2%\n",
            "Image: 67ffa0fc7.jpg | Classes present: tensor([0])\n",
            "Image: 670dc6f72.jpg | Classes present: tensor([0, 3])\n",
            "Image: 69365fabd.jpg | Classes present: tensor([0])\n",
            "Image: 670dc6f72.jpg | Classes present: tensor([0, 3])\n",
            "Image: 69403726e.jpg | Classes present: tensor([0])\n",
            "Image: 6714ba056.jpg | Classes present: tensor([0])\n",
            "Image: 695a460be.jpg | Classes present: tensor([0])\n",
            "Image: 6753759e0.jpg | Classes present: tensor([0])\n",
            "Image: 697427d70.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  42% 139/334 [00:13<00:14, 13.49it/s]Memory usage: 42.3%\n",
            "Image: 6812ce51c.jpg | Classes present: tensor([0])\n",
            "Image: 6a06e0328.jpg | Classes present: tensor([0])\n",
            "Image: 68a931b71.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6a567df0b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 68d3c7be2.jpg | Classes present: tensor([0])\n",
            "Image: 6a9ff4b0c.jpg | Classes present: tensor([0, 1])\n",
            "Image: 68ebc581e.jpg | Classes present: tensor([0])\n",
            "Image: 6abf76aad.jpg | Classes present: tensor([0])\n",
            "Image: 69d546af3.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  42% 141/334 [00:13<00:15, 12.49it/s]Image: 6b4d25284.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 69d95aeea.jpg | Classes present: tensor([0])\n",
            "Image: 6b634bbe9.jpg | Classes present: tensor([0])\n",
            "Image: 69df9d97b.jpg | Classes present: tensor([0])\n",
            "Image: 6b7387486.jpg | Classes present: tensor([0])\n",
            "Image: 69f723ceb.jpg | Classes present: tensor([0])\n",
            "Image: 6b7e04658.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  43% 143/334 [00:13<00:15, 12.56it/s]Memory usage: 42.3%\n",
            "Image: 6ac1c730f.jpg | Classes present: tensor([0])\n",
            "Image: 6c8b1519e.jpg | Classes present: tensor([0])\n",
            "Image: 6b226dec1.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6ca387398.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6b3cdd9d1.jpg | Classes present: tensor([0])\n",
            "Image: 6caa89d4e.jpg | Classes present: tensor([0])\n",
            "Image: 6b3d02bce.jpg | Classes present: tensor([0])\n",
            "Image: 6cad486d2.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  43% 145/334 [00:13<00:14, 13.09it/s]Image: 6b9b11301.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 6d8835463.jpg | Classes present: tensor([0])\n",
            "Image: 6bc7c35cd.jpg | Classes present: tensor([0])\n",
            "Image: 6de495da5.jpg | Classes present: tensor([0])\n",
            "Image: 6c43d55eb.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6e18bef6b.jpg | Classes present: tensor([0])\n",
            "Image: 6c43d55eb.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6e30e4696.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  44% 147/334 [00:13<00:13, 13.50it/s]Image: 6ce9bf7f7.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 6eb8690cd.jpg | Classes present: tensor([0])\n",
            "Image: 6ce9ef450.jpg | Classes present: tensor([0])\n",
            "Image: 6ec88b7f7.jpg | Classes present: tensor([0])\n",
            "Image: 6d6280d5e.jpg | Classes present: tensor([0])\n",
            "Image: 6f0cd5095.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6f2357894.jpg | Classes present: tensor([0])\n",
            "Image: 6d8835463.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  45% 149/334 [00:13<00:14, 12.97it/s]Image: 6e3f85bb9.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 7045c2a55.jpg | Classes present: tensor([0])\n",
            "Image: 6e4a7cca6.jpg | Classes present: tensor([0])\n",
            "Image: 7095dc41e.jpg | Classes present: tensor([0, 2])\n",
            "Image: 6e6f1adb8.jpg | Classes present: tensor([0])\n",
            "Image: 70b0fb0cd.jpg | Classes present: tensor([0])\n",
            "Image: 6e994b366.jpg | Classes present: tensor([0])\n",
            "Image: 70ce9b55b.jpg | Classes present: tensor([0])\n",
            "Image: 6f490117c.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  45% 151/334 [00:14<00:14, 12.55it/s]Memory usage: 42.3%\n",
            "Image: 722df0394.jpg | Classes present: tensor([0])\n",
            "Image: 6fabaf589.jpg | Classes present: tensor([0])\n",
            "Image: 72a7ff0db.jpg | Classes present: tensor([0])\n",
            "Image: 6fd1ed5aa.jpg | Classes present: tensor([0])\n",
            "Image: 6ff11b744.jpg | Classes present: tensor([0])\n",
            "Image: 72a7ff0db.jpg | Classes present: tensor([0])\n",
            "Image: 72b465391.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  46% 153/334 [00:14<00:13, 13.79it/s]Memory usage: 42.3%\n",
            "Image: 739a0aa20.jpg | Classes present: tensor([0, 1])\n",
            "Image: 713e97c97.jpg | Classes present: tensor([0])\n",
            "Image: 73a4c6d1f.jpg | Classes present: tensor([0])\n",
            "Image: 714256911.jpg | Classes present: tensor([0])\n",
            "Image: 73cdb1d89.jpg | Classes present: tensor([0])\n",
            "Image: 714256911.jpg | Classes present: tensor([0])\n",
            "Image: 73d4dae19.jpg | Classes present: tensor([0])\n",
            "Image: 7149874c8.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  46% 155/334 [00:14<00:12, 13.93it/s]Image: 72bb7c7bc.jpg | Classes present: tensor([0])\n",
            "Image: 74ac88f43.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Image: 73472d296.jpg | Classes present: tensor([0])\n",
            "Image: 74bb2c5ff.jpg | Classes present: tensor([0])\n",
            "Image: 7365300fe.jpg | Classes present: tensor([0, 2])\n",
            "Image: 75361926d.jpg | Classes present: tensor([0])\n",
            "Image: 737ae5c95.jpg | Classes present: tensor([0])\n",
            "Image: 763871334.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.4%\n",
            "Processing batches:  47% 157/334 [00:14<00:13, 13.54it/s]Memory usage: 42.4%\n",
            "Image: 73d4dae19.jpg | Classes present: tensor([0])\n",
            "Image: 76c20b5af.jpg | Classes present: tensor([0])\n",
            "Image: 73e1969d4.jpg | Classes present: tensor([0])\n",
            "Image: 773948ca6.jpg | Classes present: tensor([0])\n",
            "Image: 74048991c.jpg | Classes present: tensor([0])\n",
            "Image: 7740cc61d.jpg | Classes present: tensor([0])\n",
            "Image: 74443f387.jpg | Classes present: tensor([0])\n",
            "Image: 778bde2b8.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.4%\n",
            "Processing batches:  48% 159/334 [00:14<00:12, 13.57it/s]Memory usage: 42.4%\n",
            "Image: 7806aa75f.jpg | Classes present: tensor([0])\n",
            "Image: 76a7e1815.jpg | Classes present: tensor([0])\n",
            "Image: 78416c3d0.jpg | Classes present: tensor([0])\n",
            "Image: 76adc6361.jpg | Classes present: tensor([0])\n",
            "Image: 7843767e9.jpg | Classes present: tensor([0])\n",
            "Image: 76b119e36.jpg | Classes present: tensor([0])\n",
            "Image: 786faedc1.jpg | Classes present: tensor([0])\n",
            "Image: 76c165a4f.jpg | Classes present: tensor([0])\n",
            "Image: 77dc1cea6.jpg | Classes present: tensor([0])\n",
            "Image: 77e5c398e.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  48% 161/334 [00:14<00:15, 11.04it/s]Memory usage: 42.2%\n",
            "Image: 79550304c.jpg | Classes present: tensor([0])\n",
            "Image: 77e5c398e.jpg | Classes present: tensor([0])\n",
            "Image: 795907727.jpg | Classes present: tensor([0])\n",
            "Image: 77ed43ae9.jpg | Classes present: tensor([0])\n",
            "Image: 7970f0008.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  49% 164/334 [00:15<00:11, 14.49it/s]Image: 788a675e7.jpg | Classes present: tensor([0])\n",
            "Image: 7970f0008.jpg | Classes present: tensor([0])\n",
            "Image: 78b5bc846.jpg | Classes present: tensor([0])\n",
            "Image: 7a2908c51.jpg | Classes present: tensor([0])\n",
            "Image: 78be7465f.jpg | Classes present: tensor([0])\n",
            "Image: 7a5fae002.jpg | Classes present: tensor([0])\n",
            "Image: 78d2258f2.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Image: 7a92f8486.jpg | Classes present: tensor([0])\n",
            "Image: 7971e089f.jpg | Classes present: tensor([0])\n",
            "Image: 7abb5b1b7.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Processing batches:  50% 166/334 [00:15<00:12, 13.88it/s]Image: 79bac6aca.jpg | Classes present: tensor([0])\n",
            "Image: 7ba0bbe30.jpg | Classes present: tensor([0])\n",
            "Image: 79c106c42.jpg | Classes present: tensor([0])\n",
            "Image: 7bb3640ce.jpg | Classes present: tensor([0])\n",
            "Image: 79dc6e410.jpg | Classes present: tensor([0])\n",
            "Image: 7bde96c82.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Memory usage: 42.0%\n",
            "Processing batches:  50% 168/334 [00:15<00:11, 14.32it/s]Image: 7c00478a3.jpg | Classes present: tensor([0])\n",
            "Image: 7b4bcde18.jpg | Classes present: tensor([0])\n",
            "Image: 7b4e8c0d9.jpg | Classes present: tensor([0])\n",
            "Image: 7de37a671.jpg | Classes present: tensor([0])\n",
            "Image: 7b547b234.jpg | Classes present: tensor([0])\n",
            "Image: 7e0e39e4c.jpg | Classes present: tensor([0])\n",
            "Image: 7b5dbe34d.jpg | Classes present: tensor([0])\n",
            "Image: 7e57b31f7.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Memory usage: 42.0%\n",
            "Processing batches:  51% 170/334 [00:15<00:11, 14.45it/s]Image: 7c95cddba.jpg | Classes present: tensor([0])\n",
            "Image: 7e6015fc5.jpg | Classes present: tensor([0])\n",
            "Image: 7cf7e0fa6.jpg | Classes present: tensor([0])\n",
            "Image: 7f777ba81.jpg | Classes present: tensor([0])\n",
            "Image: 7da7fdfca.jpg | Classes present: tensor([0, 2])\n",
            "Image: 7f8594d4b.jpg | Classes present: tensor([0])\n",
            "Image: 7dd4d0f90.jpg | Classes present: tensor([0])\n",
            "Image: 7f8d10098.jpg | Classes present: tensor([0])\n",
            "Image: 7e9c7f52d.jpg | Classes present: tensor([0])\n",
            "Image: 7efadd1c6.jpg | Classes present: tensor([0])\n",
            "Image: 7fc9cb824.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.0%\n",
            "Image: 7f25edc7a.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Processing batches:  51% 172/334 [00:15<00:13, 12.29it/s]Image: 81ab8f502.jpg | Classes present: tensor([0])\n",
            "Image: 7f4bbb940.jpg | Classes present: tensor([0])\n",
            "Image: 81b6f3cca.jpg | Classes present: tensor([0])\n",
            "Image: 81b6f3cca.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: 7fd3d58a5.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  52% 174/334 [00:15<00:11, 13.64it/s]Image: 81fa665da.jpg | Classes present: tensor([0, 2])\n",
            "Image: 801d299ac.jpg | Classes present: tensor([0, 2])\n",
            "Image: 846a8ccab.jpg | Classes present: tensor([0])\n",
            "Image: 810f96801.jpg | Classes present: tensor([0])\n",
            "Image: 847b7640a.jpg | Classes present: tensor([0])\n",
            "Image: 817c6c7a8.jpg | Classes present: tensor([0, 2])\n",
            "Image: 848a1b795.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.1%\n",
            "Image: 85294cff9.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  53% 176/334 [00:15<00:11, 14.06it/s]Image: 8266cca81.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8600decb6.jpg | Classes present: tensor([0])\n",
            "Image: 82e11b4e4.jpg | Classes present: tensor([0])\n",
            "Image: 8611deb61.jpg | Classes present: tensor([0])\n",
            "Image: 82e32c810.jpg | Classes present: tensor([0])\n",
            "Image: 8344ef24d.jpg | Classes present: tensor([0])\n",
            "Image: 862bcc9c0.jpg | Classes present: tensor([0])\n",
            "Image: 863b300cb.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: 85294cff9.jpg | Classes present: tensor([0])\n",
            "Image: 86cbb2d1f.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  53% 178/334 [00:16<00:13, 11.91it/s]Image: 854baa70c.jpg | Classes present: tensor([0])\n",
            "Image: 86e80375f.jpg | Classes present: tensor([0])\n",
            "Image: 8709ea899.jpg | Classes present: tensor([0])\n",
            "Image: 856f0b6bd.jpg | Classes present: tensor([0])\n",
            "Image: 873e04ca8.jpg | Classes present: tensor([0])\n",
            "Image: 857400707.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: 8645f73f1.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  54% 180/334 [00:16<00:14, 10.88it/s]Image: 8847458a0.jpg | Classes present: tensor([0])\n",
            "Image: 8648b2010.jpg | Classes present: tensor([0])\n",
            "Image: 865574894.jpg | Classes present: tensor([0])\n",
            "Image: 886eebf8c.jpg | Classes present: tensor([0])\n",
            "Image: 86aae8998.jpg | Classes present: tensor([0])\n",
            "Image: 8872fe6db.jpg | Classes present: tensor([0, 2])\n",
            "Image: 87754d760.jpg | Classes present: tensor([0])\n",
            "Image: 88e1122cb.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  54% 182/334 [00:16<00:16,  9.47it/s]Image: 87754d760.jpg | Classes present: tensor([0])\n",
            "Image: 8a87b9578.jpg | Classes present: tensor([0])\n",
            "Image: 87ae117e9.jpg | Classes present: tensor([0])\n",
            "Image: 8a88f573c.jpg | Classes present: tensor([0, 2])\n",
            "Image: 87f74731f.jpg | Classes present: tensor([0])\n",
            "Image: 8a993359d.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  55% 184/334 [00:16<00:15,  9.71it/s]Image: 8a2a8a476.jpg | Classes present: tensor([0])\n",
            "Image: 8aa3af3da.jpg | Classes present: tensor([0])\n",
            "Image: 8a35c59f9.jpg | Classes present: tensor([0])\n",
            "Image: 8b9c035ec.jpg | Classes present: tensor([0])\n",
            "Image: 8a485f766.jpg | Classes present: tensor([0])\n",
            "Image: 8bab4626b.jpg | Classes present: tensor([0])\n",
            "Image: 8a75d73d9.jpg | Classes present: tensor([0])\n",
            "Image: 8bb208f36.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  56% 186/334 [00:17<00:15,  9.62it/s]Image: 8afa2aa27.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8bb5ada5c.jpg | Classes present: tensor([0])\n",
            "Image: 8b495e389.jpg | Classes present: tensor([0])\n",
            "Image: 8d36899b1.jpg | Classes present: tensor([0])\n",
            "Image: 8b4b4d618.jpg | Classes present: tensor([0])\n",
            "Image: 8d4206f2a.jpg | Classes present: tensor([0])\n",
            "Image: 8b4e90080.jpg | Classes present: tensor([0, 2])\n",
            "Image: 8d5dde91c.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  56% 188/334 [00:17<00:16,  8.60it/s]Image: 8bdf6cee5.jpg | Classes present: tensor([0])\n",
            "Image: 8d5f90317.jpg | Classes present: tensor([0])\n",
            "Image: 8c732ade1.jpg | Classes present: tensor([0])\n",
            "Image: 8e6f1eb4f.jpg | Classes present: tensor([0])\n",
            "Image: 8cc65d1f7.jpg | Classes present: tensor([0])\n",
            "Image: 8e933231b.jpg | Classes present: tensor([0])\n",
            "Image: 8ceba5ea5.jpg | Classes present: tensor([0])\n",
            "Image: 8ebc9cadc.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  57% 189/334 [00:17<00:19,  7.36it/s]Memory usage: 42.2%\n",
            "Image: 8d67593de.jpg | Classes present: tensor([0])\n",
            "Image: 8ec0d428d.jpg | Classes present: tensor([0])\n",
            "Image: 8d938b3e7.jpg | Classes present: tensor([0])\n",
            "Image: 8f0dcad21.jpg | Classes present: tensor([0])\n",
            "Image: 8d9b43515.jpg | Classes present: tensor([0])\n",
            "Image: 8f6b07e84.jpg | Classes present: tensor([0])\n",
            "Image: 8e1fb6f5a.jpg | Classes present: tensor([0])\n",
            "Image: 8f8a23f39.jpg | Classes present: tensor([0])\n",
            "Image: 8ed31effd.jpg | Classes present: tensor([0])\n",
            "Image: 8fb4575f3.jpg | Classes present: tensor([0])\n",
            "Image: 8ed6b8054.jpg | Classes present: tensor([0, 1])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  57% 191/334 [00:17<00:20,  6.82it/s]Memory usage: 42.2%\n",
            "Image: 8f0a7e8af.jpg | Classes present: tensor([0])\n",
            "Image: 90cd42d5b.jpg | Classes present: tensor([0])\n",
            "Image: 910540b7d.jpg | Classes present: tensor([0])\n",
            "Image: 8f0a7e8af.jpg | Classes present: tensor([0])\n",
            "Image: 9121da7fe.jpg | Classes present: tensor([0])\n",
            "Image: 8fbd70ddf.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Processing batches:  58% 193/334 [00:18<00:18,  7.46it/s]Memory usage: 42.0%\n",
            "Image: 913e2221d.jpg | Classes present: tensor([0])\n",
            "Image: 904584541.jpg | Classes present: tensor([0, 3])\n",
            "Image: 918c32419.jpg | Classes present: tensor([0])\n",
            "Image: 905964016.jpg | Classes present: tensor([0, 2])\n",
            "Image: 92057aa8a.jpg | Classes present: tensor([0])\n",
            "Image: 9087518f1.jpg | Classes present: tensor([0])\n",
            "Image: 9236f984c.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Processing batches:  58% 195/334 [00:18<00:18,  7.58it/s]Memory usage: 42.0%\n",
            "Image: 9163ec76b.jpg | Classes present: tensor([0])\n",
            "Image: 9253b216e.jpg | Classes present: tensor([0, 2])\n",
            "Image: 91696aaca.jpg | Classes present: tensor([0])\n",
            "Image: 9341d848d.jpg | Classes present: tensor([0])\n",
            "Image: 9378a6f12.jpg | Classes present: tensor([0])\n",
            "Image: 91696aaca.jpg | Classes present: tensor([0])\n",
            "Image: 9169b4f3a.jpg | Classes present: tensor([0])\n",
            "Image: 9426ce32a.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  59% 197/334 [00:18<00:18,  7.50it/s]Memory usage: 42.1%\n",
            "Image: 930391b64.jpg | Classes present: tensor([0])\n",
            "Image: 94753d945.jpg | Classes present: tensor([0])\n",
            "Image: 930fe8fc7.jpg | Classes present: tensor([0])\n",
            "Image: 9557969ee.jpg | Classes present: tensor([0])\n",
            "Image: 93126606c.jpg | Classes present: tensor([0])\n",
            "Image: 955feead2.jpg | Classes present: tensor([0])\n",
            "Image: 933a9dc8b.jpg | Classes present: tensor([0])\n",
            "Image: 95eaae02e.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  60% 199/334 [00:18<00:18,  7.27it/s]Memory usage: 42.2%\n",
            "Image: 94bf15000.jpg | Classes present: tensor([0, 3])\n",
            "Image: 96279bbc2.jpg | Classes present: tensor([0, 2])\n",
            "Image: 94c910b08.jpg | Classes present: tensor([0])\n",
            "Image: 967802d76.jpg | Classes present: tensor([0])\n",
            "Image: 954d4296b.jpg | Classes present: tensor([0])\n",
            "Image: 974f00b13.jpg | Classes present: tensor([0])\n",
            "Image: 9553974f4.jpg | Classes present: tensor([0])\n",
            "Image: 975b2e5fa.jpg | Classes present: tensor([0])\n",
            "Image: 9789423c2.jpg | Classes present: tensor([0, 2])\n",
            "Image: 963b7a441.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  60% 201/334 [00:19<00:19,  6.91it/s]Memory usage: 42.3%\n",
            "Image: 963b7a441.jpg | Classes present: tensor([0])\n",
            "Image: 98c0127d3.jpg | Classes present: tensor([0])\n",
            "Image: 963f946a9.jpg | Classes present: tensor([0])\n",
            "Image: 98c634937.jpg | Classes present: tensor([0])\n",
            "Image: 9663d6a79.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  61% 203/334 [00:19<00:17,  7.56it/s]Memory usage: 42.3%\n",
            "Image: 991e0dfdf.jpg | Classes present: tensor([0])\n",
            "Image: 97b77f9e6.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9962acd22.jpg | Classes present: tensor([0])\n",
            "Image: 97eb88e35.jpg | Classes present: tensor([0])\n",
            "Image: 99d47e124.jpg | Classes present: tensor([0])\n",
            "Image: 982193e49.jpg | Classes present: tensor([0, 3])\n",
            "Image: 9a064450d.jpg | Classes present: tensor([0, 2])\n",
            "Image: 982193e49.jpg | Classes present: tensor([0, 3])\n",
            "Memory usage: 42.0%\n",
            "Processing batches:  61% 205/334 [00:19<00:18,  7.11it/s]Image: 9aa721852.jpg | Classes present: tensor([0])\n",
            "Image: 99855ae32.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Image: 9aa721852.jpg | Classes present: tensor([0])\n",
            "Image: 99a9163bc.jpg | Classes present: tensor([0])\n",
            "Image: 9b72243dc.jpg | Classes present: tensor([0])\n",
            "Image: 99d359803.jpg | Classes present: tensor([0])\n",
            "Image: 9ba68fdaa.jpg | Classes present: tensor([0])\n",
            "Image: 99d359803.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  62% 207/334 [00:20<00:17,  7.37it/s]Image: 9bc62ca61.jpg | Classes present: tensor([0])\n",
            "Image: 9ab57a2fa.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.1%\n",
            "Image: 9bd5122c0.jpg | Classes present: tensor([0])\n",
            "Image: 9ad1ad629.jpg | Classes present: tensor([0])\n",
            "Image: 9af9dc45b.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9c7a6cf21.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9b09b2a38.jpg | Classes present: tensor([0])\n",
            "Image: 9cfa7be25.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  63% 209/334 [00:20<00:15,  8.25it/s]Image: 9d0b3a0f7.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: 9c005a770.jpg | Classes present: tensor([0])\n",
            "Image: 9c1c7f69c.jpg | Classes present: tensor([0])\n",
            "Image: 9d22ddbf2.jpg | Classes present: tensor([0])\n",
            "Image: 9c42e727c.jpg | Classes present: tensor([0])\n",
            "Image: 9ead58088.jpg | Classes present: tensor([0, 2])\n",
            "Image: 9c4ed4726.jpg | Classes present: tensor([0])\n",
            "Image: 9ec897b68.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  63% 211/334 [00:20<00:13,  9.03it/s]Image: 9d9020e1d.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.1%\n",
            "Image: 9ed6f9c81.jpg | Classes present: tensor([0])\n",
            "Image: 9dbb7b85c.jpg | Classes present: tensor([0])\n",
            "Image: 9eed09712.jpg | Classes present: tensor([0])\n",
            "Image: 9e1f9aaaf.jpg | Classes present: tensor([0, 2])\n",
            "Image: a02fe46b6.jpg | Classes present: tensor([0])\n",
            "Image: 9ea3ea37b.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  64% 213/334 [00:20<00:11, 10.30it/s]Image: a056c104a.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: 9eed09712.jpg | Classes present: tensor([0])\n",
            "Image: a05708135.jpg | Classes present: tensor([0])\n",
            "Image: a0709a1e6.jpg | Classes present: tensor([0])\n",
            "Image: 9ef683a79.jpg | Classes present: tensor([0])\n",
            "Image: 9fed72af4.jpg | Classes present: tensor([0])\n",
            "Image: a13c52c08.jpg | Classes present: tensor([0])\n",
            "Image: a0155346d.jpg | Classes present: tensor([0])\n",
            "Image: a14e96726.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  64% 215/334 [00:20<00:10, 11.32it/s]Image: a09a889b2.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: a14eeb75d.jpg | Classes present: tensor([0, 2])\n",
            "Image: a0de93374.jpg | Classes present: tensor([0])\n",
            "Image: a10c18895.jpg | Classes present: tensor([0])\n",
            "Image: a152690b6.jpg | Classes present: tensor([0])\n",
            "Image: a135808ff.jpg | Classes present: tensor([0])\n",
            "Image: a1982cad5.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  65% 217/334 [00:20<00:09, 12.28it/s]Image: a152690b6.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: a1bede9b1.jpg | Classes present: tensor([0, 2])\n",
            "Image: a154fdcfd.jpg | Classes present: tensor([0])\n",
            "Image: a1f5481df.jpg | Classes present: tensor([0])\n",
            "Image: a187d1897.jpg | Classes present: tensor([0])\n",
            "Image: a21bfa25a.jpg | Classes present: tensor([0])\n",
            "Image: a18bdb241.jpg | Classes present: tensor([0])\n",
            "Image: a2889c2fa.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  66% 219/334 [00:20<00:09, 12.46it/s]Image: a21fa9b86.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: a2889c2fa.jpg | Classes present: tensor([0])\n",
            "Image: a22639daa.jpg | Classes present: tensor([0])\n",
            "Image: a28a7b7be.jpg | Classes present: tensor([0])\n",
            "Image: a231b46ec.jpg | Classes present: tensor([0])\n",
            "Image: a239718e1.jpg | Classes present: tensor([0])\n",
            "Image: a28a7b7be.jpg | Classes present: tensor([0])\n",
            "Image: a2bdcd021.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  66% 221/334 [00:21<00:09, 12.22it/s]Image: a33d86440.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: a2e328f50.jpg | Classes present: tensor([0])\n",
            "Image: a37447f04.jpg | Classes present: tensor([0, 2])\n",
            "Image: a316898ca.jpg | Classes present: tensor([0])\n",
            "Image: a37447f04.jpg | Classes present: tensor([0, 2])\n",
            "Image: a335fc5cc.jpg | Classes present: tensor([0])\n",
            "Image: a3d5e7319.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  67% 223/334 [00:21<00:08, 13.28it/s]Image: a4c93ac65.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.1%\n",
            "Image: a471d7877.jpg | Classes present: tensor([0, 2])\n",
            "Image: a4d9a97f6.jpg | Classes present: tensor([0])\n",
            "Image: a485b97e7.jpg | Classes present: tensor([0])\n",
            "Image: a4d9a97f6.jpg | Classes present: tensor([0])\n",
            "Image: a485d538c.jpg | Classes present: tensor([0])\n",
            "Image: a4a648cf6.jpg | Classes present: tensor([0, 3])\n",
            "Image: a4dff615e.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  67% 225/334 [00:21<00:08, 13.01it/s]Image: a5092043e.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: a52f36666.jpg | Classes present: tensor([0])\n",
            "Image: a56c8f958.jpg | Classes present: tensor([0])\n",
            "Image: a559091c5.jpg | Classes present: tensor([0])\n",
            "Image: a56df9123.jpg | Classes present: tensor([0])\n",
            "Image: a56c8f958.jpg | Classes present: tensor([0])\n",
            "Image: a5b23c751.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  68% 227/334 [00:21<00:07, 13.70it/s]Image: a5cb0256f.jpg | Classes present: tensor([0, 3])\n",
            "Image: a67df9196.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: a753532d6.jpg | Classes present: tensor([0, 2])\n",
            "Image: a68dcc7d2.jpg | Classes present: tensor([0])\n",
            "Image: a753532d6.jpg | Classes present: tensor([0, 2])\n",
            "Image: a6b00abd7.jpg | Classes present: tensor([0])\n",
            "Image: a7655a8d3.jpg | Classes present: tensor([0])\n",
            "Image: a6b3d554a.jpg | Classes present: tensor([0])\n",
            "Image: a76b26d44.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  69% 229/334 [00:21<00:07, 13.26it/s]Memory usage: 42.1%\n",
            "Image: a7d5ae972.jpg | Classes present: tensor([0])\n",
            "Image: a9a5ac063.jpg | Classes present: tensor([0])\n",
            "Image: a9b1abf48.jpg | Classes present: tensor([0])\n",
            "Image: a835a0e50.jpg | Classes present: tensor([0])\n",
            "Image: a9c5e9f1e.jpg | Classes present: tensor([0, 2])\n",
            "Image: a9378655a.jpg | Classes present: tensor([0])\n",
            "Image: a9e2530ed.jpg | Classes present: tensor([0])\n",
            "Image: a94abfda7.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  69% 231/334 [00:21<00:07, 12.93it/s]Image: a9f5f9806.jpg | Classes present: tensor([0])\n",
            "Image: aa9a7363b.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: aae6bc5be.jpg | Classes present: tensor([0, 2])\n",
            "Image: aa394081e.jpg | Classes present: tensor([0])\n",
            "Image: aa4b29d91.jpg | Classes present: tensor([0])\n",
            "Image: aaf12ddee.jpg | Classes present: tensor([0])\n",
            "Image: aa7a0bcf3.jpg | Classes present: tensor([0])\n",
            "Image: ab13f368e.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  70% 233/334 [00:21<00:07, 12.69it/s]Image: ab4fab99e.jpg | Classes present: tensor([0, 3])\n",
            "Memory usage: 42.2%\n",
            "Image: ab16f0e09.jpg | Classes present: tensor([0])\n",
            "Image: ab6530468.jpg | Classes present: tensor([0])\n",
            "Image: ab1dda536.jpg | Classes present: tensor([0])\n",
            "Image: ab70f8ba6.jpg | Classes present: tensor([0, 2])\n",
            "Image: ab2300506.jpg | Classes present: tensor([0])\n",
            "Image: abe8e7faf.jpg | Classes present: tensor([0])\n",
            "Image: ab2b3d3d9.jpg | Classes present: tensor([0])\n",
            "Image: acd30bd6a.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  70% 235/334 [00:22<00:07, 13.09it/s]Image: ad6506c7b.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.2%\n",
            "Image: ac15719f1.jpg | Classes present: tensor([0, 2])\n",
            "Image: ad6aed3f4.jpg | Classes present: tensor([0])\n",
            "Image: ac461b596.jpg | Classes present: tensor([0])\n",
            "Image: ad6fb4fab.jpg | Classes present: tensor([0])\n",
            "Image: ac504079d.jpg | Classes present: tensor([0])\n",
            "Image: adff445fd.jpg | Classes present: tensor([0, 2])\n",
            "Image: ac9c592aa.jpg | Classes present: tensor([0])\n",
            "Image: ae4555b5b.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  71% 237/334 [00:22<00:07, 12.93it/s]Memory usage: 42.2%\n",
            "Image: ad9ad21f4.jpg | Classes present: tensor([0])\n",
            "Image: aea51e93f.jpg | Classes present: tensor([0])\n",
            "Image: add980018.jpg | Classes present: tensor([0, 2])\n",
            "Image: aeb34560d.jpg | Classes present: tensor([0])\n",
            "Image: adf5fdfe2.jpg | Classes present: tensor([0])\n",
            "Image: adf93f9bf.jpg | Classes present: tensor([0])\n",
            "Image: af4d2ee24.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  72% 239/334 [00:22<00:06, 13.80it/s]Memory usage: 42.2%\n",
            "Image: aebbc40a6.jpg | Classes present: tensor([0, 2])\n",
            "Image: af5c06a20.jpg | Classes present: tensor([0])\n",
            "Image: aeda5b216.jpg | Classes present: tensor([0])\n",
            "Image: af7c08f36.jpg | Classes present: tensor([0])\n",
            "Image: aee116071.jpg | Classes present: tensor([0])\n",
            "Image: af7c08f36.jpg | Classes present: tensor([0])\n",
            "Image: af4cdefaa.jpg | Classes present: tensor([0])\n",
            "Image: b0bd510db.jpg | Classes present: tensor([0])\n",
            "Image: af7db8470.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  72% 241/334 [00:22<00:07, 12.78it/s]Image: b107bf5bd.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Image: afb854388.jpg | Classes present: tensor([0, 2])\n",
            "Image: b10ca1dc4.jpg | Classes present: tensor([0])\n",
            "Image: b147f0f0f.jpg | Classes present: tensor([0])\n",
            "Image: afd3f856d.jpg | Classes present: tensor([0])\n",
            "Image: b1c4d3872.jpg | Classes present: tensor([0])\n",
            "Image: b04b907b2.jpg | Classes present: tensor([0, 2])\n",
            "Image: b1d3f12b6.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  73% 243/334 [00:22<00:06, 13.18it/s]Image: b1d3f12b6.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Image: b162a9cb2.jpg | Classes present: tensor([0])\n",
            "Image: b1f5ce725.jpg | Classes present: tensor([0])\n",
            "Image: b1639af61.jpg | Classes present: tensor([0])\n",
            "Image: b2cbd553f.jpg | Classes present: tensor([0])\n",
            "Image: b17fcb164.jpg | Classes present: tensor([0, 2])\n",
            "Image: b2e59bdaa.jpg | Classes present: tensor([0])\n",
            "Image: b1bbea81b.jpg | Classes present: tensor([0])\n",
            "Image: b37a57736.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  73% 245/334 [00:22<00:07, 12.38it/s]Memory usage: 42.2%\n",
            "Image: b3920826e.jpg | Classes present: tensor([0])\n",
            "Image: b20fb15ff.jpg | Classes present: tensor([0])\n",
            "Image: b23e854e8.jpg | Classes present: tensor([0])\n",
            "Image: b442ff31d.jpg | Classes present: tensor([0])\n",
            "Image: b2854eaff.jpg | Classes present: tensor([0])\n",
            "Image: b44cfa5ba.jpg | Classes present: tensor([0])\n",
            "Image: b2c9fde17.jpg | Classes present: tensor([0])\n",
            "Image: b46dafae2.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Image: b4cc6a4ed.jpg | Classes present: tensor([0])\n",
            "Processing batches:  74% 247/334 [00:23<00:06, 12.89it/s]Image: b5b48f9f3.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Image: b3b8f0c9e.jpg | Classes present: tensor([0, 2])\n",
            "Image: b5b99c878.jpg | Classes present: tensor([0, 2])\n",
            "Image: b3f7ae992.jpg | Classes present: tensor([0])\n",
            "Image: b5b99c878.jpg | Classes present: tensor([0, 2])\n",
            "Image: b40abdab2.jpg | Classes present: tensor([0])\n",
            "Image: b5cda37bc.jpg | Classes present: tensor([0])\n",
            "Image: b41747a10.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  75% 249/334 [00:23<00:06, 12.68it/s]Image: b54038841.jpg | Classes present: tensor([0])\n",
            "Image: b68c95b87.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Image: b56de2940.jpg | Classes present: tensor([0])\n",
            "Image: b69aaf096.jpg | Classes present: tensor([0])\n",
            "Image: b5804f43f.jpg | Classes present: tensor([0, 2])\n",
            "Image: b6b66ca8c.jpg | Classes present: tensor([0, 2])\n",
            "Image: b58132808.jpg | Classes present: tensor([0, 2])\n",
            "Image: b6f61c6b0.jpg | Classes present: tensor([0])\n",
            "Image: b64b9969e.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  75% 251/334 [00:23<00:06, 12.65it/s]Memory usage: 42.2%\n",
            "Image: b733d1672.jpg | Classes present: tensor([0])\n",
            "Image: b64b9969e.jpg | Classes present: tensor([0, 2])\n",
            "Image: b799d56cd.jpg | Classes present: tensor([0])\n",
            "Image: b64f0985f.jpg | Classes present: tensor([0])\n",
            "Image: b7a1d89ae.jpg | Classes present: tensor([0])\n",
            "Image: b66721b1f.jpg | Classes present: tensor([0])\n",
            "Image: b7b6fd4ed.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  76% 253/334 [00:23<00:06, 12.67it/s]Memory usage: 42.0%\n",
            "Image: b6fc52f4e.jpg | Classes present: tensor([0])\n",
            "Image: b933f4591.jpg | Classes present: tensor([0])\n",
            "Image: b71ee7bd0.jpg | Classes present: tensor([0, 3])\n",
            "Image: b93f5fdc0.jpg | Classes present: tensor([0, 2])\n",
            "Image: b941eeaa7.jpg | Classes present: tensor([0, 2])\n",
            "Image: b72d341bf.jpg | Classes present: tensor([0])\n",
            "Image: b733d1672.jpg | Classes present: tensor([0])\n",
            "Image: b9752d783.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Processing batches:  76% 255/334 [00:23<00:06, 12.43it/s]Image: b87571cc4.jpg | Classes present: tensor([0])\n",
            "Image: b8b03dcfe.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.0%\n",
            "Image: ba4284649.jpg | Classes present: tensor([0])\n",
            "Image: b8ba151b1.jpg | Classes present: tensor([0, 2])\n",
            "Image: ba4ac3636.jpg | Classes present: tensor([0])\n",
            "Image: b925ef3b7.jpg | Classes present: tensor([0])\n",
            "Image: ba4ac3636.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Processing batches:  77% 257/334 [00:23<00:05, 13.19it/s]Image: bab5271b6.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Image: b99b4abea.jpg | Classes present: tensor([0])\n",
            "Image: bb2975da4.jpg | Classes present: tensor([0])\n",
            "Image: b99b4abea.jpg | Classes present: tensor([0])\n",
            "Image: bb3421ee8.jpg | Classes present: tensor([0])\n",
            "Image: b9b5cb6f5.jpg | Classes present: tensor([0])\n",
            "Image: bb371f33d.jpg | Classes present: tensor([0, 2])\n",
            "Image: b9fa8b135.jpg | Classes present: tensor([0])\n",
            "Image: bb4e89121.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  78% 259/334 [00:24<00:05, 12.91it/s]Image: bab5271b6.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: bc72a7548.jpg | Classes present: tensor([0])\n",
            "Image: bc751c15d.jpg | Classes present: tensor([0])\n",
            "Image: bac68f2c3.jpg | Classes present: tensor([0, 2])\n",
            "Image: bacb738d3.jpg | Classes present: tensor([0])\n",
            "Image: bc7ce8f4d.jpg | Classes present: tensor([0])\n",
            "Image: bcb794eed.jpg | Classes present: tensor([0])\n",
            "Image: badc586ae.jpg | Classes present: tensor([0])\n",
            "Image: bbb96273d.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  78% 261/334 [00:24<00:06, 11.71it/s]Image: bbec1ee47.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: bea7ff137.jpg | Classes present: tensor([0])\n",
            "Image: bbfdbc490.jpg | Classes present: tensor([0])\n",
            "Image: bf3db21e9.jpg | Classes present: tensor([0])\n",
            "Image: bc0a90164.jpg | Classes present: tensor([0, 3])\n",
            "Memory usage: 42.1%\n",
            "Image: bfa17327e.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  79% 264/334 [00:24<00:04, 14.78it/s]Image: bd0e26062.jpg | Classes present: tensor([0])\n",
            "Image: bfa249587.jpg | Classes present: tensor([0])\n",
            "Image: bdbf5535f.jpg | Classes present: tensor([0])\n",
            "Image: c038c0588.jpg | Classes present: tensor([0])\n",
            "Image: bdce84e23.jpg | Classes present: tensor([0])\n",
            "Image: c04b0d160.jpg | Classes present: tensor([0])\n",
            "Image: be65d7bb7.jpg | Classes present: tensor([0, 2])\n",
            "Image: c0e34b64b.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  80% 266/334 [00:24<00:04, 14.12it/s]Image: c12bbdec9.jpg | Classes present: tensor([0])\n",
            "Image: bfd24be30.jpg | Classes present: tensor([0, 2])\n",
            "Image: bfd24be30.jpg | Classes present: tensor([0, 2])\n",
            "Image: c2760fc1a.jpg | Classes present: tensor([0, 3])\n",
            "Image: bfd56c3d2.jpg | Classes present: tensor([0])\n",
            "Image: c27ce861d.jpg | Classes present: tensor([0])\n",
            "Image: c01fd972f.jpg | Classes present: tensor([0])\n",
            "Image: c2b446019.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  80% 268/334 [00:24<00:04, 13.75it/s]Image: c232eea0c.jpg | Classes present: tensor([0])\n",
            "Image: c30805f9e.jpg | Classes present: tensor([0])\n",
            "Image: c24caa9be.jpg | Classes present: tensor([0])\n",
            "Image: c34fc79b6.jpg | Classes present: tensor([0])\n",
            "Image: c25e12747.jpg | Classes present: tensor([0])\n",
            "Image: c37633c03.jpg | Classes present: tensor([0])\n",
            "Image: c2760fc1a.jpg | Classes present: tensor([0, 3])\n",
            "Image: c3c091454.jpg | Classes present: tensor([0, 3])\n",
            "Memory usage: 42.2%\n",
            "Image: c3cae8972.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  81% 270/334 [00:24<00:04, 13.61it/s]Image: c319a0d11.jpg | Classes present: tensor([0, 2])\n",
            "Image: c495e234e.jpg | Classes present: tensor([0])\n",
            "Image: c319a0d11.jpg | Classes present: tensor([0, 2])\n",
            "Image: c4aeca424.jpg | Classes present: tensor([0])\n",
            "Image: c34f14586.jpg | Classes present: tensor([0])\n",
            "Image: c4dc92ef9.jpg | Classes present: tensor([0])\n",
            "Image: c34f14586.jpg | Classes present: tensor([0])\n",
            "Image: c4dc92ef9.jpg | Classes present: tensor([0])\n",
            "Image: c3ff6937c.jpg | Classes present: tensor([0])\n",
            "Image: c40a05198.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  81% 272/334 [00:25<00:05, 12.08it/s]Image: c5af9872c.jpg | Classes present: tensor([0])\n",
            "Image: c44c93192.jpg | Classes present: tensor([0])\n",
            "Image: c5b08d4e3.jpg | Classes present: tensor([0])\n",
            "Image: c46065903.jpg | Classes present: tensor([0])\n",
            "Image: c5b08d4e3.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Memory usage: 42.2%\n",
            "Image: c4f5ebbb2.jpg | Classes present: tensor([0])\n",
            "Image: c5da9e8c7.jpg | Classes present: tensor([0])\n",
            "Image: c53423923.jpg | Classes present: tensor([0, 2])\n",
            "Image: c6afe1599.jpg | Classes present: tensor([0])\n",
            "Image: c6d3371a8.jpg | Classes present: tensor([0])\n",
            "Image: c54db71af.jpg | Classes present: tensor([0, 3])\n",
            "Image: c746f473d.jpg | Classes present: tensor([0, 2])\n",
            "Image: c5a41d53c.jpg | Classes present: tensor([0])\n",
            "Image: c5e69fd8f.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Processing batches:  82% 275/334 [00:25<00:05, 11.27it/s]Image: c5fa2923b.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Image: c63e60886.jpg | Classes present: tensor([0])\n",
            "Image: c74abe00a.jpg | Classes present: tensor([0])\n",
            "Image: c63e60886.jpg | Classes present: tensor([0])\n",
            "Image: c7f93d8bd.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Processing batches:  83% 277/334 [00:25<00:04, 12.06it/s]Memory usage: 42.0%\n",
            "Image: c795455ba.jpg | Classes present: tensor([0])\n",
            "Image: c7fb9db8c.jpg | Classes present: tensor([0])\n",
            "Image: c7aeb9c82.jpg | Classes present: tensor([0, 3])\n",
            "Image: c8216657a.jpg | Classes present: tensor([0])\n",
            "Image: c7aeb9c82.jpg | Classes present: tensor([0, 3])\n",
            "Image: c85251430.jpg | Classes present: tensor([0])\n",
            "Image: c94bd179c.jpg | Classes present: tensor([0])\n",
            "Image: c7d002c29.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  84% 279/334 [00:25<00:04, 11.92it/s]Image: c94f78afa.jpg | Classes present: tensor([0])\n",
            "Image: c89e96115.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: c8c0e5b9d.jpg | Classes present: tensor([0])\n",
            "Image: c9ae4cb29.jpg | Classes present: tensor([0, 2])\n",
            "Image: c8ed5e8ab.jpg | Classes present: tensor([0, 2])\n",
            "Image: c9ae4cb29.jpg | Classes present: tensor([0, 2])\n",
            "Image: c916658f1.jpg | Classes present: tensor([0])\n",
            "Image: ca9d7749b.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  84% 281/334 [00:25<00:04, 11.76it/s]Image: c9cd221c5.jpg | Classes present: tensor([0])\n",
            "Image: cac001c04.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: c9d24ef83.jpg | Classes present: tensor([0])\n",
            "Image: cb094c2cb.jpg | Classes present: tensor([0])\n",
            "Image: ca492d6f1.jpg | Classes present: tensor([0])\n",
            "Image: cb37fc190.jpg | Classes present: tensor([0])\n",
            "Image: ca82d646f.jpg | Classes present: tensor([0])\n",
            "Image: cbd27127f.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  85% 283/334 [00:25<00:04, 12.34it/s]Memory usage: 42.1%\n",
            "Image: cc0bf97cf.jpg | Classes present: tensor([0])\n",
            "Image: cb383b2f7.jpg | Classes present: tensor([0])\n",
            "Image: cc3b99f17.jpg | Classes present: tensor([0])\n",
            "Image: cb43d7be5.jpg | Classes present: tensor([0])\n",
            "Image: cb53b96ce.jpg | Classes present: tensor([0])\n",
            "Image: cc5bae861.jpg | Classes present: tensor([0])\n",
            "Image: cb9fe5699.jpg | Classes present: tensor([0])\n",
            "Image: cd0c2417f.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  85% 285/334 [00:26<00:03, 12.64it/s]Image: ccbd751f2.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: cd14c73db.jpg | Classes present: tensor([0])\n",
            "Image: ccd94dc85.jpg | Classes present: tensor([0])\n",
            "Image: cd14c73db.jpg | Classes present: tensor([0])\n",
            "Image: ccf39a604.jpg | Classes present: tensor([0])\n",
            "Image: cd04164a0.jpg | Classes present: tensor([0])\n",
            "Image: cd23d4841.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  86% 287/334 [00:26<00:03, 13.23it/s]Image: ce11ffd78.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: cd465dc7d.jpg | Classes present: tensor([0])\n",
            "Image: ce43bdd06.jpg | Classes present: tensor([0, 2])\n",
            "Image: cd475d2a3.jpg | Classes present: tensor([0, 2])\n",
            "Image: ce7b7ac0b.jpg | Classes present: tensor([0])\n",
            "Image: ce02c322e.jpg | Classes present: tensor([0])\n",
            "Image: cea2ea962.jpg | Classes present: tensor([0])\n",
            "Image: ce05c2c3f.jpg | Classes present: tensor([0])\n",
            "Image: cef5ff47d.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  87% 289/334 [00:26<00:03, 13.48it/s]Memory usage: 42.1%\n",
            "Image: ceba9dc16.jpg | Classes present: tensor([0])\n",
            "Image: cf0641053.jpg | Classes present: tensor([0])\n",
            "Image: ceba9dc16.jpg | Classes present: tensor([0])\n",
            "Image: cf0641053.jpg | Classes present: tensor([0])\n",
            "Image: ced4439da.jpg | Classes present: tensor([0])\n",
            "Image: cf1f3345c.jpg | Classes present: tensor([0])\n",
            "Image: cede14189.jpg | Classes present: tensor([0])\n",
            "Image: d02f1b229.jpg | Classes present: tensor([0])\n",
            "Image: cf5231a23.jpg | Classes present: tensor([0])\n",
            "Image: d04e02d1f.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  87% 291/334 [00:26<00:03, 11.85it/s]Image: cf8e21964.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: d0578ca87.jpg | Classes present: tensor([0])\n",
            "Image: cff387e60.jpg | Classes present: tensor([0])\n",
            "Image: d0befd683.jpg | Classes present: tensor([0])\n",
            "Image: d000d7ef5.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  88% 293/334 [00:26<00:03, 13.34it/s]Memory usage: 42.1%\n",
            "Image: d1886af80.jpg | Classes present: tensor([0])\n",
            "Image: d1023fa39.jpg | Classes present: tensor([0, 2])\n",
            "Image: d11130898.jpg | Classes present: tensor([0])\n",
            "Image: d1e1bf13e.jpg | Classes present: tensor([0])\n",
            "Image: d1ed49385.jpg | Classes present: tensor([0])\n",
            "Image: d129fe51e.jpg | Classes present: tensor([0])\n",
            "Image: d2291de5c.jpg | Classes present: tensor([0])\n",
            "Image: d169e1b81.jpg | Classes present: tensor([0, 3])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  88% 295/334 [00:26<00:02, 13.25it/s]Memory usage: 42.1%\n",
            "Image: d25356a51.jpg | Classes present: tensor([0])\n",
            "Image: d2291de5c.jpg | Classes present: tensor([0])\n",
            "Image: d2670190d.jpg | Classes present: tensor([0])\n",
            "Image: d239a83c4.jpg | Classes present: tensor([0])\n",
            "Image: d283f3744.jpg | Classes present: tensor([0])\n",
            "Image: d2454fd68.jpg | Classes present: tensor([0])\n",
            "Image: d2a854e69.jpg | Classes present: tensor([0])\n",
            "Image: d245c4e7f.jpg | Classes present: tensor([0])\n",
            "Image: d4387afd3.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  89% 297/334 [00:26<00:02, 12.87it/s]Memory usage: 42.1%\n",
            "Image: d46866225.jpg | Classes present: tensor([0])\n",
            "Image: d2bbde0a4.jpg | Classes present: tensor([0, 2])\n",
            "Image: d31e0200c.jpg | Classes present: tensor([0])\n",
            "Image: d4af6d206.jpg | Classes present: tensor([0])\n",
            "Image: d52b35e0e.jpg | Classes present: tensor([0])\n",
            "Image: d37c88411.jpg | Classes present: tensor([0])\n",
            "Image: d3d6d9b6a.jpg | Classes present: tensor([0])\n",
            "Image: d5bdfa378.jpg | Classes present: tensor([0])\n",
            "Image: d5f7cde8a.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  90% 299/334 [00:27<00:02, 12.17it/s]Memory usage: 42.1%\n",
            "Image: d5353adfc.jpg | Classes present: tensor([0, 2])\n",
            "Image: d60ae28dc.jpg | Classes present: tensor([0])\n",
            "Image: d535c41bf.jpg | Classes present: tensor([0])\n",
            "Image: d66e4eb3f.jpg | Classes present: tensor([0, 2])\n",
            "Image: d57629343.jpg | Classes present: tensor([0])\n",
            "Image: d6ff87222.jpg | Classes present: tensor([0, 3])\n",
            "Image: d59b4476a.jpg | Classes present: tensor([0])\n",
            "Image: d70e75dca.jpg | Classes present: tensor([0])\n",
            "Image: d7221e8ce.jpg | Classes present: tensor([0])\n",
            "Image: d6777d642.jpg | Classes present: tensor([0, 3])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  90% 301/334 [00:27<00:02, 11.38it/s]Image: d6d71b8ec.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.1%\n",
            "Image: d7686d307.jpg | Classes present: tensor([0])\n",
            "Image: d6ef360e3.jpg | Classes present: tensor([0, 3])\n",
            "Image: d7e3d3784.jpg | Classes present: tensor([0])\n",
            "Image: d6ef360e3.jpg | Classes present: tensor([0, 3])\n",
            "Image: d7e693160.jpg | Classes present: tensor([0, 3])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  91% 303/334 [00:27<00:02, 12.79it/s]Image: d81eb8a93.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.1%\n",
            "Image: d77e9ff45.jpg | Classes present: tensor([0])\n",
            "Image: d849d7a48.jpg | Classes present: tensor([0])\n",
            "Image: d78e97810.jpg | Classes present: tensor([0])\n",
            "Image: d9bfea1ea.jpg | Classes present: tensor([0, 2])\n",
            "Image: d7a43c6f6.jpg | Classes present: tensor([0, 2])\n",
            "Image: da20fe743.jpg | Classes present: tensor([0])\n",
            "Image: d7ae2c9be.jpg | Classes present: tensor([0])\n",
            "Image: da6fb7dc1.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  91% 305/334 [00:27<00:02, 12.47it/s]Image: dac8bf38a.jpg | Classes present: tensor([0])\n",
            "Image: d860da430.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: db3d85bc9.jpg | Classes present: tensor([0])\n",
            "Image: d8d851749.jpg | Classes present: tensor([0])\n",
            "Image: db5aabcb0.jpg | Classes present: tensor([0, 2])\n",
            "Image: d8e21a2ae.jpg | Classes present: tensor([0])\n",
            "Image: db62a970a.jpg | Classes present: tensor([0])\n",
            "Image: d96baa2ce.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  92% 307/334 [00:27<00:02, 12.91it/s]Memory usage: 42.1%\n",
            "Image: db6b86601.jpg | Classes present: tensor([0])\n",
            "Image: daeea39b1.jpg | Classes present: tensor([0, 2])\n",
            "Image: dd2c992b2.jpg | Classes present: tensor([0])\n",
            "Image: db0547371.jpg | Classes present: tensor([0])\n",
            "Image: db064ce4a.jpg | Classes present: tensor([0])\n",
            "Image: dd441d6a0.jpg | Classes present: tensor([0])\n",
            "Image: db17f3e99.jpg | Classes present: tensor([0])\n",
            "Image: dd441d6a0.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  93% 309/334 [00:27<00:01, 12.95it/s]Memory usage: 42.1%\n",
            "Image: dc46bd374.jpg | Classes present: tensor([0, 2])\n",
            "Image: dd8af6471.jpg | Classes present: tensor([0])\n",
            "Image: dc499be11.jpg | Classes present: tensor([0])\n",
            "Image: de85c63cb.jpg | Classes present: tensor([0])\n",
            "Image: dc58fa33b.jpg | Classes present: tensor([0])\n",
            "Image: de85c63cb.jpg | Classes present: tensor([0])\n",
            "Image: dc636ab48.jpg | Classes present: tensor([0])\n",
            "Image: dd97d4b45.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  93% 311/334 [00:28<00:01, 12.80it/s]Image: de9ce7271.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: ddf1692c2.jpg | Classes present: tensor([0])\n",
            "Image: dea277f4a.jpg | Classes present: tensor([0, 2])\n",
            "Image: de1983d54.jpg | Classes present: tensor([0, 2])\n",
            "Image: de5a08726.jpg | Classes present: tensor([0])\n",
            "Image: df656b199.jpg | Classes present: tensor([0])\n",
            "Image: df70a7e07.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  94% 313/334 [00:28<00:01, 13.43it/s]Memory usage: 42.1%\n",
            "Image: df983abed.jpg | Classes present: tensor([0, 2])\n",
            "Image: def2e3f57.jpg | Classes present: tensor([0, 2])\n",
            "Image: defee8509.jpg | Classes present: tensor([0])\n",
            "Image: dfc4b8d29.jpg | Classes present: tensor([0])\n",
            "Image: deff23782.jpg | Classes present: tensor([0])\n",
            "Image: e055a603c.jpg | Classes present: tensor([0])\n",
            "Image: e07c94229.jpg | Classes present: tensor([0])\n",
            "Image: df0168063.jpg | Classes present: tensor([0])\n",
            "Image: e0ad8fed3.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  94% 315/334 [00:28<00:01, 13.28it/s]Image: e003d691f.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Image: e0b3e7b3f.jpg | Classes present: tensor([0])\n",
            "Image: e29d6c141.jpg | Classes present: tensor([0])\n",
            "Image: e03bf53d8.jpg | Classes present: tensor([0])\n",
            "Image: e2c4275d6.jpg | Classes present: tensor([0])\n",
            "Image: e0490b7cf.jpg | Classes present: tensor([0, 2])\n",
            "Image: e2d02393b.jpg | Classes present: tensor([0, 2])\n",
            "Image: e04f5c163.jpg | Classes present: tensor([0, 2])\n",
            "Image: e2d64c010.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.1%\n",
            "Processing batches:  95% 317/334 [00:28<00:01, 12.22it/s]Memory usage: 42.1%\n",
            "Image: e0b3e7b3f.jpg | Classes present: tensor([0])\n",
            "Image: e36a70d40.jpg | Classes present: tensor([0])\n",
            "Image: e0cc2a416.jpg | Classes present: tensor([0])\n",
            "Image: e401b6539.jpg | Classes present: tensor([0])\n",
            "Image: e1662a8c3.jpg | Classes present: tensor([0])\n",
            "Image: e45010a6a.jpg | Classes present: tensor([0])\n",
            "Image: e21fd95ad.jpg | Classes present: tensor([0, 3])\n",
            "Image: e461fe709.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  96% 319/334 [00:28<00:01, 12.81it/s]Memory usage: 42.2%\n",
            "Image: e2d64c010.jpg | Classes present: tensor([0])\n",
            "Image: e51c76beb.jpg | Classes present: tensor([0])\n",
            "Image: e2f004578.jpg | Classes present: tensor([0])\n",
            "Image: e55bc715f.jpg | Classes present: tensor([0])\n",
            "Image: e56c928ee.jpg | Classes present: tensor([0])\n",
            "Image: e30ea20d9.jpg | Classes present: tensor([0, 2])\n",
            "Image: e56d5dfde.jpg | Classes present: tensor([0])\n",
            "Image: e32bb7b41.jpg | Classes present: tensor([0])\n",
            "Image: e479a2e88.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  96% 321/334 [00:28<00:01, 12.11it/s]Memory usage: 42.2%\n",
            "Image: e5b65b5ec.jpg | Classes present: tensor([0])\n",
            "Image: e4911993d.jpg | Classes present: tensor([0])\n",
            "Image: e5c50b997.jpg | Classes present: tensor([0])\n",
            "Image: e495d5456.jpg | Classes present: tensor([0])\n",
            "Image: e5cc898b6.jpg | Classes present: tensor([0])\n",
            "Image: e495d5456.jpg | Classes present: tensor([0])\n",
            "Image: e5e0fe470.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  97% 323/334 [00:29<00:00, 13.39it/s]Memory usage: 42.2%\n",
            "Image: e667de6f9.jpg | Classes present: tensor([0])\n",
            "Image: e56f52c1e.jpg | Classes present: tensor([0])\n",
            "Image: e6a44cda3.jpg | Classes present: tensor([0])\n",
            "Image: e573ac857.jpg | Classes present: tensor([0])\n",
            "Image: e6bf58db7.jpg | Classes present: tensor([0])\n",
            "Image: e573ac857.jpg | Classes present: tensor([0])\n",
            "Image: e6c32de72.jpg | Classes present: tensor([0])\n",
            "Image: e57efd4b4.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  97% 325/334 [00:29<00:00, 12.74it/s]Image: e5ea04944.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.2%\n",
            "Image: e91814529.jpg | Classes present: tensor([0])\n",
            "Image: e5f1d5a38.jpg | Classes present: tensor([0])\n",
            "Image: e9463eb04.jpg | Classes present: tensor([0])\n",
            "Image: e658a2891.jpg | Classes present: tensor([0, 2])\n",
            "Image: e9b77950e.jpg | Classes present: tensor([0])\n",
            "Image: e665a434f.jpg | Classes present: tensor([0])\n",
            "Image: e9b77950e.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.2%\n",
            "Processing batches:  98% 327/334 [00:29<00:00, 13.71it/s]Memory usage: 42.3%\n",
            "Image: eae840b74.jpg | Classes present: tensor([0])\n",
            "Image: e70c4768b.jpg | Classes present: tensor([0])\n",
            "Image: eb4225311.jpg | Classes present: tensor([0])\n",
            "Image: eb6983d21.jpg | Classes present: tensor([0])\n",
            "Image: e7268620b.jpg | Classes present: tensor([0, 2])\n",
            "Image: eb7ec1f85.jpg | Classes present: tensor([0, 2])\n",
            "Image: e77d57652.jpg | Classes present: tensor([0])\n",
            "Image: e7c915edc.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.3%\n",
            "Processing batches:  99% 329/334 [00:29<00:00, 13.02it/s]Image: ea13e9557.jpg | Classes present: tensor([0])\n",
            "Image: ed22af554.jpg | Classes present: tensor([0, 2])\n",
            "Memory usage: 42.3%\n",
            "Image: ea8acd661.jpg | Classes present: tensor([0])\n",
            "Image: ed861754e.jpg | Classes present: tensor([0])\n",
            "Image: eaaa61b15.jpg | Classes present: tensor([0])\n",
            "Image: eab9d667f.jpg | Classes present: tensor([0])\n",
            "Image: ec52fac2d.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Processing batches:  99% 331/334 [00:29<00:00, 13.60it/s]Image: ec6a951ba.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Image: eca0aa4ff.jpg | Classes present: tensor([0])\n",
            "Image: ed1c6be8d.jpg | Classes present: tensor([0])\n",
            "Memory usage: 42.0%\n",
            "Memory usage: 42.0%\n",
            "Processing batches: 100% 334/334 [00:29<00:00, 11.21it/s]\n",
            "\n",
            "=== Evaluation Metrics ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    defect_1       0.00      0.00      0.00      5040\n",
            "    defect_2       0.06      1.00      0.11       296\n",
            "    defect_3       0.00      0.00      0.00         0\n",
            "    defect_4       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.06      5336\n",
            "   macro avg       0.01      0.25      0.03      5336\n",
            "weighted avg       0.00      0.06      0.01      5336\n",
            "\n",
            "Balanced Accuracy: 0.5\n",
            "\n",
            "=== Pipeline completed in 153.08 seconds ===\n"
          ]
        }
      ],
      "source": [
        "!python run_reproduction.py --severstal_path /content/drive/MyDrive/severstal-steel-defect-detection --test_only --test_samples 0 --img_size 160"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}